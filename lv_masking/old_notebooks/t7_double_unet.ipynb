{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Double UNet\n",
    "\n",
    "The idea here is to train a new UNet that learns to convert the \"raw\" masks from the first UNet into the actual masks. I'll be using the model trained in the `t6_better_3dUNet` notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "import monai\n",
    "from monai.networks.nets import UNet\n",
    "from monai.transforms import (\n",
    "    Compose,\n",
    "    LoadNiftid,\n",
    "    ScaleIntensityd,\n",
    "    NormalizeIntensityd,\n",
    "    AddChanneld,\n",
    "    ToTensord,\n",
    "    RandSpatialCropd,\n",
    "    RandCropByPosNegLabeld,\n",
    "    CropForegroundd,\n",
    "    Identityd,\n",
    ")\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNet_DF(pl.LightningModule):\n",
    "    def __init__(self, hparams):\n",
    "        super().__init__()\n",
    "        self.hparams = hparams\n",
    "        \n",
    "        self.unet = UNet(\n",
    "            dimensions=3,\n",
    "            in_channels=1,\n",
    "            out_channels=2,\n",
    "            channels=(64, 128, 258, 512, 1024),\n",
    "            strides=(2, 2, 2, 2),\n",
    "            norm=monai.networks.layers.Norm.BATCH,\n",
    "            dropout=0,\n",
    "        )\n",
    "        self.sample_masks = []\n",
    "    \n",
    "    # Data setup\n",
    "    def setup(self, stage):\n",
    "        data_dir = 'data/'\n",
    "        \n",
    "        # Train imgs/masks\n",
    "        train_imgs = []\n",
    "        with open(data_dir + 'train_imgs.txt', 'r') as f:\n",
    "            train_imgs = [image.rstrip() for image in f.readlines()]\n",
    "\n",
    "        train_masks = []\n",
    "        with open(data_dir + 'train_masks.txt', 'r') as f:\n",
    "            train_masks = [mask.rstrip() for mask in f.readlines()]\n",
    "        \n",
    "        train_dicts = [{'image': image, 'mask': mask} for (image, mask) in zip(train_imgs, train_masks)]\n",
    "        \n",
    "        train_dicts, val_dicts = train_test_split(train_dicts, test_size=0.2)\n",
    "        \n",
    "        # Basic transforms\n",
    "        data_keys = [\"image\", \"mask\"]\n",
    "        data_transforms = Compose(\n",
    "            [\n",
    "                LoadNiftid(keys=data_keys),\n",
    "                AddChanneld(keys=data_keys),\n",
    "                NormalizeIntensityd(keys=\"image\"),\n",
    "                RandCropByPosNegLabeld(\n",
    "                    keys=data_keys,\n",
    "                    label_key=\"mask\",\n",
    "                    spatial_size=self.hparams.patch_size,\n",
    "                    num_samples=4,\n",
    "                    image_key=\"image\"\n",
    "                ),\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "        self.train_dataset = monai.data.CacheDataset(\n",
    "            data=train_dicts,\n",
    "            transform=Compose(\n",
    "                [\n",
    "                    data_transforms,\n",
    "                    ToTensord(keys=data_keys)\n",
    "                ]\n",
    "            ),\n",
    "            cache_rate=1.0\n",
    "        )\n",
    "        \n",
    "        self.val_dataset = monai.data.CacheDataset(\n",
    "            data=val_dicts,\n",
    "            transform=Compose(\n",
    "                [\n",
    "                    data_transforms,\n",
    "                    ToTensord(keys=data_keys)\n",
    "                ]\n",
    "            ),\n",
    "            cache_rate=1.0\n",
    "        )\n",
    "        \n",
    "    def train_dataloader(self):\n",
    "        return monai.data.DataLoader(\n",
    "            self.train_dataset, batch_size=self.hparams.batch_size, shuffle=True, num_workers=hparams.num_workers\n",
    "        )\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return monai.data.DataLoader(\n",
    "            self.val_dataset, batch_size=self.hparams.batch_size, num_workers=hparams.num_workers\n",
    "        )\n",
    "    \n",
    "    # Training setup\n",
    "    def forward(self, image):\n",
    "        return self.unet(image)\n",
    "    \n",
    "    def criterion(self, y_hat, y):\n",
    "        dice_loss = monai.losses.DiceLoss(\n",
    "            to_onehot_y=True,\n",
    "            softmax=True\n",
    "        )\n",
    "        focal_loss = monai.losses.FocalLoss()\n",
    "        return dice_loss(y_hat, y) + focal_loss(y_hat, y)\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        inputs, labels = batch['image'], batch['mask']\n",
    "        outputs = self(inputs)\n",
    "        loss = self.criterion(outputs, labels)\n",
    "\n",
    "        self.logger.log_metrics({\"loss/train\": loss}, self.global_step)\n",
    "\n",
    "        return {'loss': loss}\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        lr = self.hparams.lr\n",
    "        optimizer = torch.optim.Adam(self.unet.parameters(), lr=lr)\n",
    "        return optimizer\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        inputs, labels = (\n",
    "            batch[\"image\"],\n",
    "            batch[\"mask\"],\n",
    "        )\n",
    "        outputs = self(inputs)\n",
    "        \n",
    "        # Sample masks\n",
    "        if self.current_epoch != 0:\n",
    "            image = outputs[0].argmax(0)[:, :, 8].unsqueeze(0).detach()\n",
    "            self.sample_masks.append(image)\n",
    "        \n",
    "        loss = self.criterion(outputs, labels)\n",
    "        return {\"val_loss\": loss}\n",
    "\n",
    "    def validation_epoch_end(self, outputs):\n",
    "        avg_loss = torch.stack([x[\"val_loss\"] for x in outputs]).mean()\n",
    "        self.logger.log_metrics({\"val/loss\": avg_loss}, self.current_epoch)\n",
    "        \n",
    "        if self.current_epoch != 0:\n",
    "            grid = torchvision.utils.make_grid(self.sample_masks)\n",
    "            self.logger.experiment.add_image('sample_masks', grid, self.current_epoch)\n",
    "            self.sample_masks = []\n",
    "        \n",
    "        return {\"val_loss\": avg_loss}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['models/7-8-2020_dicefocal/_ckpt_epoch_119.ckpt']\n"
     ]
    }
   ],
   "source": [
    "model_ckpts = glob.glob('models/7-8-2020_dicefocal/*.ckpt')\n",
    "print(model_ckpts)\n",
    "generator_model = UNet_DF.load_from_checkpoint(model_ckpts[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaskUNet(pl.LightningModule):\n",
    "    def __init__(self, hparams):\n",
    "        super().__init__()\n",
    "        self.hparams = hparams\n",
    "        \n",
    "        self.generator = hparams['generator']\n",
    "        \n",
    "        self.unet = UNet(\n",
    "            dimensions=3,\n",
    "            in_channels=1,\n",
    "            out_channels=1,\n",
    "            channels=(64, 128, 258, 512, 1024),\n",
    "            strides=(2, 2, 2, 2),\n",
    "            norm=monai.networks.layers.Norm.BATCH,\n",
    "            dropout=0,\n",
    "        )\n",
    "        self.sample_masks = []\n",
    "    \n",
    "    # Data setup\n",
    "    def setup(self, stage):\n",
    "        data_dir = 'data/'\n",
    "        \n",
    "        # Train imgs/masks\n",
    "        train_imgs = []\n",
    "        with open(data_dir + 'train_imgs.txt', 'r') as f:\n",
    "            train_imgs = [image.rstrip() for image in f.readlines()]\n",
    "\n",
    "        train_masks = []\n",
    "        with open(data_dir + 'train_masks.txt', 'r') as f:\n",
    "            train_masks = [mask.rstrip() for mask in f.readlines()]\n",
    "            \n",
    "        train_dicts = [{'image': image, 'mask': mask} for (image, mask) in zip(train_imgs, train_masks)]\n",
    "        \n",
    "        train_dicts, val_dicts = train_test_split(train_dicts, test_size=0.2)\n",
    "        \n",
    "        # Basic transforms\n",
    "        data_keys = [\"image\", \"mask\"]\n",
    "        data_transforms = Compose(\n",
    "            [\n",
    "                LoadNiftid(keys=data_keys),\n",
    "                AddChanneld(keys=data_keys),\n",
    "                NormalizeIntensityd(keys=\"image\"),\n",
    "                RandCropByPosNegLabeld(\n",
    "                    keys=data_keys,\n",
    "                    label_key=\"mask\",\n",
    "                    spatial_size=self.hparams.patch_size,\n",
    "                    num_samples=4,\n",
    "                    image_key=\"image\"\n",
    "                ),\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "        self.train_dataset = monai.data.CacheDataset(\n",
    "            data=train_dicts,\n",
    "            transform=Compose(\n",
    "                [\n",
    "                    data_transforms,\n",
    "                    ToTensord(keys=data_keys)\n",
    "                ]\n",
    "            ),\n",
    "            cache_rate=1.0\n",
    "        )\n",
    "        \n",
    "        self.val_dataset = monai.data.CacheDataset(\n",
    "            data=val_dicts,\n",
    "            transform=Compose(\n",
    "                [\n",
    "                    data_transforms,\n",
    "                    ToTensord(keys=data_keys)\n",
    "                ]\n",
    "            ),\n",
    "            cache_rate=1.0\n",
    "        )\n",
    "    \n",
    "    def train_dataloader(self):\n",
    "        return monai.data.DataLoader(\n",
    "            self.train_dataset, batch_size=self.hparams.batch_size, shuffle=True, num_workers=hparams.num_workers\n",
    "        )\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return monai.data.DataLoader(\n",
    "            self.val_dataset, batch_size=self.hparams.batch_size, num_workers=hparams.num_workers\n",
    "        )\n",
    "    def forward(self, image):\n",
    "        return self.unet(image)\n",
    "    \n",
    "    def criterion(self, y_hat, y):\n",
    "        dice_loss = monai.losses.DiceLoss(\n",
    "            to_onehot_y=False,\n",
    "            softmax=False\n",
    "        )\n",
    "        return dice_loss(y_hat, y)\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        images, targets = batch['image'], batch['mask']\n",
    "        inputs = self.generator(images).argmax(1).unsqueeze(1).type(torch.FloatTensor).cuda(images.device.index)\n",
    "        outputs = self(inputs)\n",
    "        loss = self.criterion(outputs, targets)\n",
    "\n",
    "        self.logger.log_metrics({\"loss/train\": loss}, self.global_step)\n",
    "\n",
    "        return {'loss': loss}\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        lr = self.hparams.lr\n",
    "        optimizer = torch.optim.Adam(self.unet.parameters(), lr=lr)\n",
    "        return optimizer\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        images, targets = batch['image'], batch['mask']\n",
    "        inputs = self.generator(images).argmax(1).unsqueeze(1).type(torch.FloatTensor).cuda(images.device.index)\n",
    "        outputs = self(inputs)\n",
    "        \n",
    "        # Sample masks\n",
    "        if self.current_epoch != 0:\n",
    "            image = torch.round(outputs[0][0][:, :, 8].unsqueeze(0).detach())\n",
    "            self.sample_masks.append(image)\n",
    "        \n",
    "        loss = self.criterion(outputs, targets)\n",
    "        return {\"val_loss\": loss}\n",
    "    \n",
    "    def validation_epoch_end(self, outputs):\n",
    "        avg_loss = torch.stack([x[\"val_loss\"] for x in outputs]).mean()\n",
    "        self.logger.log_metrics({\"val/loss\": avg_loss}, self.current_epoch)\n",
    "        \n",
    "        if self.current_epoch != 0:\n",
    "            grid = torchvision.utils.make_grid(self.sample_masks)\n",
    "            self.logger.experiment.add_image('sample_masks', grid, self.current_epoch)\n",
    "            self.sample_masks = []\n",
    "        \n",
    "        return {\"val_loss\": avg_loss}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from argparse import Namespace\n",
    "\n",
    "args = {\n",
    "    'name': '7-9-2020_double_unet',\n",
    "    'batch_size': 2,\n",
    "    'lr': 0.001,\n",
    "    'patch_size': [256, 256, 16],\n",
    "    'num_workers': 6,\n",
    "    'generator': generator_model,\n",
    "}\n",
    "\n",
    "hparams = Namespace(**args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MaskUNet(hparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 18780), started 20:02:32 ago. (Use '!kill 18780' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-f2c58951a831bac2\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-f2c58951a831bac2\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          url.port = 6006;\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%reload_ext tensorboard\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir models/7-9-2020_double_unet/tb_logs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "CUDA_VISIBLE_DEVICES: [0,1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/115 Load and cache transformed data:  [                              ]\r",
      "2/115 Load and cache transformed data:  [                              ]\r",
      "3/115 Load and cache transformed data:  [                              ]\r",
      "4/115 Load and cache transformed data:  [=                             ]\r",
      "5/115 Load and cache transformed data:  [=                             ]\r",
      "6/115 Load and cache transformed data:  [=                             ]\r",
      "7/115 Load and cache transformed data:  [=                             ]\r",
      "8/115 Load and cache transformed data:  [==                            ]\r",
      "9/115 Load and cache transformed data:  [==                            ]\r",
      "10/115 Load and cache transformed data:  [==                            ]\r",
      "11/115 Load and cache transformed data:  [==                            ]\r",
      "12/115 Load and cache transformed data:  [===                           ]\r",
      "13/115 Load and cache transformed data:  [===                           ]\r",
      "14/115 Load and cache transformed data:  [===                           ]\r",
      "15/115 Load and cache transformed data:  [===                           ]\r",
      "16/115 Load and cache transformed data:  [====                          ]\r",
      "17/115 Load and cache transformed data:  [====                          ]\r",
      "18/115 Load and cache transformed data:  [====                          ]\r",
      "19/115 Load and cache transformed data:  [====                          ]\r",
      "20/115 Load and cache transformed data:  [=====                         ]\r",
      "21/115 Load and cache transformed data:  [=====                         ]\r",
      "22/115 Load and cache transformed data:  [=====                         ]\r",
      "23/115 Load and cache transformed data:  [======                        ]\r",
      "24/115 Load and cache transformed data:  [======                        ]\r",
      "25/115 Load and cache transformed data:  [======                        ]\r",
      "26/115 Load and cache transformed data:  [======                        ]\r",
      "27/115 Load and cache transformed data:  [=======                       ]\r",
      "28/115 Load and cache transformed data:  [=======                       ]\r",
      "29/115 Load and cache transformed data:  [=======                       ]\r",
      "30/115 Load and cache transformed data:  [=======                       ]\r",
      "31/115 Load and cache transformed data:  [========                      ]\r",
      "32/115 Load and cache transformed data:  [========                      ]\r",
      "33/115 Load and cache transformed data:  [========                      ]\r",
      "34/115 Load and cache transformed data:  [========                      ]\r",
      "35/115 Load and cache transformed data:  [=========                     ]\r",
      "36/115 Load and cache transformed data:  [=========                     ]\r",
      "37/115 Load and cache transformed data:  [=========                     ]\r",
      "38/115 Load and cache transformed data:  [=========                     ]\r",
      "39/115 Load and cache transformed data:  [==========                    ]\r",
      "40/115 Load and cache transformed data:  [==========                    ]\r",
      "41/115 Load and cache transformed data:  [==========                    ]\r",
      "42/115 Load and cache transformed data:  [==========                    ]\r",
      "43/115 Load and cache transformed data:  [===========                   ]\r",
      "44/115 Load and cache transformed data:  [===========                   ]\r",
      "45/115 Load and cache transformed data:  [===========                   ]\r",
      "46/115 Load and cache transformed data:  [============                  ]\r",
      "47/115 Load and cache transformed data:  [============                  ]\r",
      "48/115 Load and cache transformed data:  [============                  ]\r",
      "49/115 Load and cache transformed data:  [============                  ]\r",
      "50/115 Load and cache transformed data:  [=============                 ]\r",
      "51/115 Load and cache transformed data:  [=============                 ]\r",
      "52/115 Load and cache transformed data:  [=============                 ]\r",
      "53/115 Load and cache transformed data:  [=============                 ]\r",
      "54/115 Load and cache transformed data:  [==============                ]\r",
      "55/115 Load and cache transformed data:  [==============                ]\r",
      "56/115 Load and cache transformed data:  [==============                ]\r",
      "57/115 Load and cache transformed data:  [==============                ]\r",
      "58/115 Load and cache transformed data:  [===============               ]\r",
      "59/115 Load and cache transformed data:  [===============               ]\r",
      "60/115 Load and cache transformed data:  [===============               ]\r",
      "61/115 Load and cache transformed data:  [===============               ]\r",
      "62/115 Load and cache transformed data:  [================              ]\r",
      "63/115 Load and cache transformed data:  [================              ]\r",
      "64/115 Load and cache transformed data:  [================              ]\r",
      "65/115 Load and cache transformed data:  [================              ]\r",
      "66/115 Load and cache transformed data:  [=================             ]\r",
      "67/115 Load and cache transformed data:  [=================             ]\r",
      "68/115 Load and cache transformed data:  [=================             ]\r",
      "69/115 Load and cache transformed data:  [==================            ]\r",
      "70/115 Load and cache transformed data:  [==================            ]\r",
      "71/115 Load and cache transformed data:  [==================            ]\r",
      "72/115 Load and cache transformed data:  [==================            ]\r",
      "73/115 Load and cache transformed data:  [===================           ]\r",
      "74/115 Load and cache transformed data:  [===================           ]\r",
      "75/115 Load and cache transformed data:  [===================           ]\r",
      "76/115 Load and cache transformed data:  [===================           ]\r",
      "77/115 Load and cache transformed data:  [====================          ]\r",
      "78/115 Load and cache transformed data:  [====================          ]\r",
      "79/115 Load and cache transformed data:  [====================          ]\r",
      "80/115 Load and cache transformed data:  [====================          ]\r",
      "81/115 Load and cache transformed data:  [=====================         ]\r",
      "82/115 Load and cache transformed data:  [=====================         ]\r",
      "83/115 Load and cache transformed data:  [=====================         ]\r",
      "84/115 Load and cache transformed data:  [=====================         ]\r",
      "85/115 Load and cache transformed data:  [======================        ]\r",
      "86/115 Load and cache transformed data:  [======================        ]\r",
      "87/115 Load and cache transformed data:  [======================        ]\r",
      "88/115 Load and cache transformed data:  [======================        ]\r",
      "89/115 Load and cache transformed data:  [=======================       ]\r",
      "90/115 Load and cache transformed data:  [=======================       ]\r",
      "91/115 Load and cache transformed data:  [=======================       ]\r",
      "92/115 Load and cache transformed data:  [========================      ]\r",
      "93/115 Load and cache transformed data:  [========================      ]\r",
      "94/115 Load and cache transformed data:  [========================      ]\r",
      "95/115 Load and cache transformed data:  [========================      ]\r",
      "96/115 Load and cache transformed data:  [=========================     ]\r",
      "97/115 Load and cache transformed data:  [=========================     ]\r",
      "98/115 Load and cache transformed data:  [=========================     ]\r",
      "99/115 Load and cache transformed data:  [=========================     ]\r",
      "100/115 Load and cache transformed data:  [==========================    ]\r",
      "101/115 Load and cache transformed data:  [==========================    ]\r",
      "102/115 Load and cache transformed data:  [==========================    ]\r",
      "103/115 Load and cache transformed data:  [==========================    ]\r",
      "104/115 Load and cache transformed data:  [===========================   ]\r",
      "105/115 Load and cache transformed data:  [===========================   ]\r",
      "106/115 Load and cache transformed data:  [===========================   ]\r",
      "107/115 Load and cache transformed data:  [===========================   ]\r",
      "108/115 Load and cache transformed data:  [============================  ]\r",
      "109/115 Load and cache transformed data:  [============================  ]\r",
      "110/115 Load and cache transformed data:  [============================  ]\r",
      "111/115 Load and cache transformed data:  [============================  ]\r",
      "112/115 Load and cache transformed data:  [============================= ]\r",
      "113/115 Load and cache transformed data:  [============================= ]\r",
      "114/115 Load and cache transformed data:  [============================= ]\r",
      "115/115 Load and cache transformed data:  [==============================]\r\n",
      "1/29 Load and cache transformed data:  [=                             ]\r",
      "2/29 Load and cache transformed data:  [==                            ]\r",
      "3/29 Load and cache transformed data:  [===                           ]\r",
      "4/29 Load and cache transformed data:  [====                          ]\r",
      "5/29 Load and cache transformed data:  [=====                         ]\r",
      "6/29 Load and cache transformed data:  [======                        ]\r",
      "7/29 Load and cache transformed data:  [=======                       ]\r",
      "8/29 Load and cache transformed data:  [========                      ]\r",
      "9/29 Load and cache transformed data:  [=========                     ]\r",
      "10/29 Load and cache transformed data:  [==========                    ]\r",
      "11/29 Load and cache transformed data:  [===========                   ]\r",
      "12/29 Load and cache transformed data:  [============                  ]\r",
      "13/29 Load and cache transformed data:  [=============                 ]\r",
      "14/29 Load and cache transformed data:  [==============                ]\r",
      "15/29 Load and cache transformed data:  [===============               ]\r",
      "16/29 Load and cache transformed data:  [================              ]\r",
      "17/29 Load and cache transformed data:  [=================             ]\r",
      "18/29 Load and cache transformed data:  [==================            ]\r",
      "19/29 Load and cache transformed data:  [===================           ]\r",
      "20/29 Load and cache transformed data:  [====================          ]\r",
      "21/29 Load and cache transformed data:  [=====================         ]\r",
      "22/29 Load and cache transformed data:  [======================        ]\r",
      "23/29 Load and cache transformed data:  [=======================       ]\r",
      "24/29 Load and cache transformed data:  [========================      ]\r",
      "25/29 Load and cache transformed data:  [=========================     ]\r",
      "26/29 Load and cache transformed data:  [==========================    ]\r",
      "27/29 Load and cache transformed data:  [===========================   ]\r",
      "28/29 Load and cache transformed data:  [============================  ]\r",
      "29/29 Load and cache transformed data:  [==============================]\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name      | Type    | Params\n",
      "--------------------------------------\n",
      "0 | generator | UNet_DF | 31 M  \n",
      "1 | unet      | UNet    | 31 M  \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validation sanity check', layout=Layout…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "164210c33d9b42f2b8b41ca9193cfee2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Training', layout=Layout(flex='2'), max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NAME = 'models/' + hparams.name\n",
    "logger = pl.loggers.TensorBoardLogger(NAME + \"/tb_logs/\", name='')\n",
    "\n",
    "# Callbacks\n",
    "early_stopping = pl.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=5\n",
    ")\n",
    "\n",
    "checkpoint_callback = pl.callbacks.ModelCheckpoint(filepath=NAME + '/checkpoints/')\n",
    "\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "#     auto_scale_batch_size='binsearch',\n",
    "    checkpoint_callback=checkpoint_callback,\n",
    "    early_stop_callback=early_stopping,\n",
    "    check_val_every_n_epoch=5,\n",
    "    gpus=1,\n",
    "    max_epochs=1000,\n",
    "    logger=logger,\n",
    ")\n",
    "\n",
    "trainer.fit(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import random\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['models/7-9-2020_double_unet/_ckpt_epoch_4.ckpt']\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'generator'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-bd474ec59952>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel_ckpts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'models/'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mhparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/*.ckpt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_ckpts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m model = MaskUNet.load_from_checkpoint(\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mmodel_ckpts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mhparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data3/johnkim/environments/env_pytorch/lib/python3.8/site-packages/pytorch_lightning/core/saving.py\u001b[0m in \u001b[0;36mload_from_checkpoint\u001b[0;34m(cls, checkpoint_path, map_location, hparams_file, tags_csv, *args, **kwargs)\u001b[0m\n\u001b[1;32m    167\u001b[0m         \u001b[0mcheckpoint\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCHECKPOINT_HYPER_PARAMS_KEY\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 169\u001b[0;31m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load_model_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data3/johnkim/environments/env_pytorch/lib/python3.8/site-packages/pytorch_lightning/core/saving.py\u001b[0m in \u001b[0;36m_load_model_state\u001b[0;34m(cls, checkpoint, *cls_args, **cls_kwargs)\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcls_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkwonlyargs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m             \u001b[0mcls_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 205\u001b[0;31m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mcls_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcls_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    206\u001b[0m         \u001b[0;31m# load the state_dict on the model automatically\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'state_dict'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-26-28d016d5cfdd>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, hparams)\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhparams\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'generator'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         self.unet = UNet(\n",
      "\u001b[0;31mKeyError\u001b[0m: 'generator'"
     ]
    }
   ],
   "source": [
    "model_ckpts = glob.glob('models/' + hparams.name + '/*.ckpt')\n",
    "print(model_ckpts)\n",
    "model = MaskUNet.load_from_checkpoint(\n",
    "    model_ckpts[0],\n",
    "    hparams=vars(hparams)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': '7-9-2020_double_unet',\n",
       " 'batch_size': 2,\n",
       " 'lr': 0.001,\n",
       " 'patch_size': [256, 256, 16],\n",
       " 'num_workers': 6,\n",
       " 'generator': UNet_DF(\n",
       "   (unet): UNet(\n",
       "     (model): Sequential(\n",
       "       (0): Convolution(\n",
       "         (conv): Conv3d(1, 64, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
       "         (norm): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "         (act): PReLU(num_parameters=1)\n",
       "       )\n",
       "       (1): SkipConnection(\n",
       "         (submodule): Sequential(\n",
       "           (0): Convolution(\n",
       "             (conv): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
       "             (norm): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "             (act): PReLU(num_parameters=1)\n",
       "           )\n",
       "           (1): SkipConnection(\n",
       "             (submodule): Sequential(\n",
       "               (0): Convolution(\n",
       "                 (conv): Conv3d(128, 258, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
       "                 (norm): BatchNorm3d(258, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                 (act): PReLU(num_parameters=1)\n",
       "               )\n",
       "               (1): SkipConnection(\n",
       "                 (submodule): Sequential(\n",
       "                   (0): Convolution(\n",
       "                     (conv): Conv3d(258, 512, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
       "                     (norm): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                     (act): PReLU(num_parameters=1)\n",
       "                   )\n",
       "                   (1): SkipConnection(\n",
       "                     (submodule): Convolution(\n",
       "                       (conv): Conv3d(512, 1024, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "                       (norm): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                       (act): PReLU(num_parameters=1)\n",
       "                     )\n",
       "                   )\n",
       "                   (2): Convolution(\n",
       "                     (conv): ConvTranspose3d(1536, 258, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), output_padding=(1, 1, 1))\n",
       "                     (norm): BatchNorm3d(258, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                     (act): PReLU(num_parameters=1)\n",
       "                   )\n",
       "                 )\n",
       "               )\n",
       "               (2): Convolution(\n",
       "                 (conv): ConvTranspose3d(516, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), output_padding=(1, 1, 1))\n",
       "                 (norm): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                 (act): PReLU(num_parameters=1)\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (2): Convolution(\n",
       "             (conv): ConvTranspose3d(256, 64, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), output_padding=(1, 1, 1))\n",
       "             (norm): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "             (act): PReLU(num_parameters=1)\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (2): Convolution(\n",
       "         (conv): ConvTranspose3d(128, 2, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), output_padding=(1, 1, 1))\n",
       "       )\n",
       "     )\n",
       "   )\n",
       " )}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vars(hparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
