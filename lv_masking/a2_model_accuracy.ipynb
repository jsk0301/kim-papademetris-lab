{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Accuracy\n",
    "\n",
    "Up until now, I've been using mostly qualitative, visual assessment to determine how well a model performed. I want to create a better metric. I'm thinking that a good metric will be the percentage of pixels correctly labelled; let's see how well it works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "import monai\n",
    "from monai.transforms import (\n",
    "    Compose,\n",
    "    LoadNiftid,\n",
    "    NormalizeIntensityd,\n",
    "    AddChanneld,\n",
    "    ToTensord,\n",
    "    CenterSpatialCropd,\n",
    ")\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_accuracy(model):\n",
    "    # Get data from test file doc\n",
    "    data_dir = 'data/'\n",
    "    test_imgs = []\n",
    "    with open(data_dir + 'test_imgs.txt', 'r') as f:\n",
    "        test_imgs = [image.rstrip() for image in f.readlines()]\n",
    "\n",
    "    test_masks = []\n",
    "    with open(data_dir + 'test_masks.txt', 'r') as f:\n",
    "        test_masks = [mask.rstrip() for mask in f.readlines()]\n",
    "\n",
    "    test_dicts = [{'image': image, 'mask': mask} for (image, mask) in zip(test_imgs, test_masks)]\n",
    "    \n",
    "    data_keys = ['image', 'mask']\n",
    "\n",
    "    test_transforms = Compose(\n",
    "        [\n",
    "            LoadNiftid(keys=data_keys),\n",
    "            AddChanneld(keys=data_keys),\n",
    "            NormalizeIntensityd(keys=\"image\"),\n",
    "            CenterSpatialCropd(\n",
    "                keys=data_keys,\n",
    "                roi_size=(256, 256, 16),\n",
    "            ),\n",
    "            ToTensord(keys=data_keys),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    test_dataset = monai.data.Dataset(\n",
    "        data=test_dicts,\n",
    "        transform=test_transforms,\n",
    "    )\n",
    "        \n",
    "    accuracies = np.array([])\n",
    "    for sample in test_dataset:\n",
    "        test_image = sample['image'].unsqueeze(0)\n",
    "        test_mask = model(test_image)\n",
    "        test_mask = test_mask.argmax(1).detach()\n",
    "        \n",
    "        accuracy = 1 - torch.sum(torch.abs(sample['mask'] - test_mask)) / (256 * 256 * 16)\n",
    "        accuracies = np.append(accuracies, accuracy)\n",
    "        \n",
    "    avg_accuracy = np.average(accuracies)\n",
    "    median_accuracy = np.median(accuracies)\n",
    "    return {\n",
    "        'average': avg_accuracy,\n",
    "        'median': median_accuracy\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import CustomModels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_acc_metrics(model_class, checkpoint_path):\n",
    "    model = model_class.load_from_checkpoint(checkpoint_path)\n",
    "    print(model.hparams.name)\n",
    "    accuracy = get_model_accuracy(model)\n",
    "    print('Average Accuracy: ', accuracy['average'])\n",
    "    print('Median Accuracy: ', accuracy['median'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3D UNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7-8-2020_3dremastered\n",
      "Average Accuracy:  0.978900655110677\n",
      "Median Accuracy:  0.9790596961975098\n"
     ]
    }
   ],
   "source": [
    "print_acc_metrics(CustomModels.UNet_3D, 'models/7-15-2020_3dremastered/_ckpt_epoch_99.ckpt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dice + Focal Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7-8-2020_dicefocal\n",
      "Average Accuracy:  0.9767536799112956\n",
      "Median Accuracy:  0.9764394760131836\n"
     ]
    }
   ],
   "source": [
    "print_acc_metrics(CustomModels.UNet_DF, 'models/7-8-2020_dicefocal/_ckpt_epoch_119.ckpt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MaskGAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7-16-2020_MaskGAN2\n",
      "Average Accuracy:  0.9758198738098145\n",
      "Median Accuracy:  0.9759783744812012\n"
     ]
    }
   ],
   "source": [
    "print_acc_metrics(CustomModels.MaskGAN, 'models/7-16-2020_MaskGAN2/_ckpt_epoch_234.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
