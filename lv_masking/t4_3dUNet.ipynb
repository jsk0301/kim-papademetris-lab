{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3D Unet\n",
    "\n",
    "In this notebook, I'm going to be exploring variations in preprocessing steps/hyperparameters in the 3D UNet structure with 256x256x16 patches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implemented with PyTorch Lightning\n",
    "### Imports\n",
    "\n",
    "# PyTorch imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# MONAI imports\n",
    "import monai\n",
    "from monai.transforms import (\n",
    "    Compose,\n",
    "    LoadNiftid,\n",
    "    ScaleIntensityd,\n",
    "    NormalizeIntensityd,\n",
    "    AddChanneld,\n",
    "    ToTensord,\n",
    "    RandSpatialCropd,\n",
    "    RandCropByPosNegLabeld,\n",
    "    CropForegroundd,\n",
    "    Identityd,\n",
    ")\n",
    "from monai.networks.blocks.convolutions import Convolution, ResidualUnit\n",
    "from monai.networks.layers.factories import Norm, Act\n",
    "from monai.networks.layers.simplelayers import SkipConnection\n",
    "from monai.utils import export\n",
    "from monai.utils.aliases import alias\n",
    "\n",
    "# PyTorch Lightning imports\n",
    "from pytorch_lightning.core.lightning import LightningModule\n",
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from pytorch_lightning.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### UNet Model\n",
    "\n",
    "# Most of the code is copied from MONAI's implenetation of a UNet\n",
    "class UNet(LightningModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        data_dir,\n",
    "        dimensions,\n",
    "        in_channels,\n",
    "        out_channels,\n",
    "        channels,\n",
    "        strides,\n",
    "        criterion,\n",
    "        augmentations,\n",
    "        kernel_size=3,\n",
    "        up_kernel_size=3,\n",
    "        num_res_units=0,\n",
    "        act=Act.PRELU,\n",
    "        norm=Norm.INSTANCE,\n",
    "        dropout=0,\n",
    "        batch_size=1,\n",
    "        lr=0.01,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        assert len(channels) == (len(strides) + 1)\n",
    "        self.data_dir = data_dir\n",
    "        self.dimensions = dimensions\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.channels = channels\n",
    "        self.strides = strides\n",
    "        self.criterion = criterion\n",
    "        self.kernel_size = kernel_size\n",
    "        self.up_kernel_size = up_kernel_size\n",
    "        self.num_res_units = num_res_units\n",
    "        self.act = act\n",
    "        self.norm = norm\n",
    "        self.dropout = dropout\n",
    "        self.augmentations = augmentations\n",
    "        self.batch_size = batch_size\n",
    "        self.lr = lr\n",
    "        \n",
    "        self.save_hyperparameters(\n",
    "            'dimensions',\n",
    "            'channels',\n",
    "            'criterion',\n",
    "            'num_res_units',\n",
    "            'dropout',\n",
    "            'augmentations',\n",
    "            'batch_size',\n",
    "            'lr'\n",
    "        )\n",
    "\n",
    "        def _create_block(inc, outc, channels, strides, is_top):\n",
    "            \"\"\"\n",
    "            Builds the UNet structure from the bottom up by recursing down to the bottom block, then creating sequential\n",
    "            blocks containing the downsample path, a skip connection around the previous block, and the upsample path.\n",
    "            \"\"\"\n",
    "            c = channels[0]\n",
    "            s = strides[0]\n",
    "\n",
    "            if len(channels) > 2:\n",
    "                subblock = _create_block(\n",
    "                    c, c, channels[1:], strides[1:], False\n",
    "                )  # continue recursion down\n",
    "                upc = c * 2\n",
    "            else:\n",
    "                # the next layer is the bottom so stop recursion, create the bottom layer as the sublock for this layer\n",
    "                subblock = self._get_bottom_layer(c, channels[1])\n",
    "                upc = c + channels[1]\n",
    "\n",
    "            down = self._get_down_layer(\n",
    "                inc, c, s, is_top\n",
    "            )  # create layer in downsampling path\n",
    "            up = self._get_up_layer(\n",
    "                upc, outc, s, is_top\n",
    "            )  # create layer in upsampling path\n",
    "\n",
    "            return nn.Sequential(down, SkipConnection(subblock), up)\n",
    "\n",
    "        self.model = _create_block(\n",
    "            in_channels, out_channels, self.channels, self.strides, True\n",
    "        )\n",
    "\n",
    "    def _get_down_layer(self, in_channels, out_channels, strides, is_top):\n",
    "        if self.num_res_units > 0:\n",
    "            return ResidualUnit(\n",
    "                self.dimensions,\n",
    "                in_channels,\n",
    "                out_channels,\n",
    "                strides,\n",
    "                self.kernel_size,\n",
    "                self.num_res_units,\n",
    "                self.act,\n",
    "                self.norm,\n",
    "                self.dropout,\n",
    "            )\n",
    "        else:\n",
    "            return Convolution(\n",
    "                self.dimensions,\n",
    "                in_channels,\n",
    "                out_channels,\n",
    "                strides,\n",
    "                self.kernel_size,\n",
    "                self.act,\n",
    "                self.norm,\n",
    "                self.dropout,\n",
    "            )\n",
    "\n",
    "    def _get_bottom_layer(self, in_channels, out_channels):\n",
    "        return self._get_down_layer(in_channels, out_channels, 1, False)\n",
    "\n",
    "    def _get_up_layer(self, in_channels, out_channels, strides, is_top):\n",
    "        conv = Convolution(\n",
    "            self.dimensions,\n",
    "            in_channels,\n",
    "            out_channels,\n",
    "            strides,\n",
    "            self.up_kernel_size,\n",
    "            self.act,\n",
    "            self.norm,\n",
    "            self.dropout,\n",
    "            conv_only=is_top and self.num_res_units == 0,\n",
    "            is_transposed=True,\n",
    "        )\n",
    "\n",
    "        if self.num_res_units > 0:\n",
    "            ru = ResidualUnit(\n",
    "                self.dimensions,\n",
    "                out_channels,\n",
    "                out_channels,\n",
    "                1,\n",
    "                self.kernel_size,\n",
    "                1,\n",
    "                self.act,\n",
    "                self.norm,\n",
    "                self.dropout,\n",
    "                last_conv_only=is_top,\n",
    "            )\n",
    "            return nn.Sequential(conv, ru)\n",
    "        else:\n",
    "            return conv\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "    # Lightning training\n",
    "    def setup(self, stage):\n",
    "        data_dir = 'data/'\n",
    "        \n",
    "        # Train imgs/masks\n",
    "        train_imgs = []\n",
    "        with open(data_dir + 'train_imgs.txt', 'r') as f:\n",
    "            train_imgs = [image.rstrip() for image in f.readlines()]\n",
    "\n",
    "        train_masks = []\n",
    "        with open(data_dir + 'train_masks.txt', 'r') as f:\n",
    "            train_masks = [mask.rstrip() for mask in f.readlines()]\n",
    "        \n",
    "        train_dicts = [{'image': image, 'mask': mask} for (image, mask) in zip(train_imgs, train_masks)]\n",
    "        \n",
    "        train_dicts, val_dicts = train_test_split(train_dicts, test_size=0.2)\n",
    "        \n",
    "        # Basic transforms\n",
    "        data_keys = [\"image\", \"mask\"]\n",
    "        data_transforms = Compose(\n",
    "            [\n",
    "                LoadNiftid(keys=data_keys),\n",
    "                AddChanneld(keys=data_keys),\n",
    "                NormalizeIntensityd(keys=\"image\"),\n",
    "                RandCropByPosNegLabeld(\n",
    "                    keys=data_keys, label_key=\"mask\", size=(256, 256, 16), num_samples=4, image_key=\"image\"\n",
    "                ),\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "        self.train_dataset = monai.data.CacheDataset(\n",
    "            data=train_dicts,\n",
    "            transform=Compose(\n",
    "                [\n",
    "                    data_transforms,\n",
    "                    self.augmentations,\n",
    "                    ToTensord(keys=data_keys)\n",
    "                ]\n",
    "            ),\n",
    "            cache_rate=1.0\n",
    "        )\n",
    "        \n",
    "        self.val_dataset = monai.data.CacheDataset(\n",
    "            data=val_dicts,\n",
    "            transform=Compose(\n",
    "                [\n",
    "                    data_transforms,\n",
    "                    ToTensord(keys=data_keys)\n",
    "                ]\n",
    "            ),\n",
    "            cache_rate=1.0\n",
    "        )\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=self.lr)\n",
    "        \n",
    "    def train_dataloader(self):\n",
    "        return monai.data.DataLoader(\n",
    "            self.train_dataset, batch_size=self.batch_size, shuffle=True, num_workers=8\n",
    "        )\n",
    "    \n",
    "    def val_dataloader(self):\n",
    "        return monai.data.DataLoader(\n",
    "            self.val_dataset, batch_size=self.batch_size, num_workers=8\n",
    "        )\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        inputs, labels = (\n",
    "            batch[\"image\"],\n",
    "            batch[\"mask\"],\n",
    "        )\n",
    "        outputs = self(inputs)\n",
    "        loss = self.criterion(outputs, labels)\n",
    "        tensorboard_logs = {\"loss/train\": loss}\n",
    "        return {\"loss\": loss, \"log\": tensorboard_logs}\n",
    "\n",
    "    # Lightning validation\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        inputs, labels = (\n",
    "            batch[\"image\"],\n",
    "            batch[\"mask\"],\n",
    "        )\n",
    "        outputs = self(inputs)\n",
    "        loss = self.criterion(outputs, labels)\n",
    "        return {\"val_loss\": loss}\n",
    "\n",
    "    def validation_epoch_end(self, outputs):\n",
    "        avg_loss = torch.stack([x[\"val_loss\"] for x in outputs]).mean()\n",
    "        tensorboard_logs = {\"loss/val\": avg_loss}\n",
    "        return {\"val_loss\": avg_loss, \"log\": tensorboard_logs}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "CUDA_VISIBLE_DEVICES: [0,1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load and cache transformed data...\n",
      "115/115 [==============================]  \n",
      "Load and cache transformed data...\n",
      "29/29 [==============================]  \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b9eee0b2e8248d78179841ef823095f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Finding best initial lr', style=ProgressStyle(descriptionâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-12:\n",
      "Process Process-10:\n",
      "Process Process-14:\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f01673dbe50>\n",
      "Traceback (most recent call last):\n",
      "  File \"/data3/johnkim/environments/env_pytorch/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 962, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/data3/johnkim/environments/env_pytorch/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 942, in _shutdown_workers\n",
      "    w.join()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 149, in join\n",
      "    res = self._popen.wait(timeout)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/popen_fork.py\", line 47, in wait\n",
      "    return self.poll(os.WNOHANG if timeout == 0.0 else 0)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/popen_fork.py\", line 27, in poll\n",
      "    pid, sts = os.waitpid(self.pid, flag)\n",
      "KeyboardInterrupt: \n",
      "Process Process-13:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "/data3/johnkim/environments/env_pytorch/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:25: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
      "  warnings.warn(*args, **kwargs)\n",
      "LR finder stopped early due to diverging loss.\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 318, in _bootstrap\n",
      "    util._exit_function()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 318, in _bootstrap\n",
      "    util._exit_function()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 318, in _bootstrap\n",
      "    util._exit_function()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 318, in _bootstrap\n",
      "    util._exit_function()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/util.py\", line 360, in _exit_function\n",
      "    _run_finalizers()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/util.py\", line 360, in _exit_function\n",
      "    _run_finalizers()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/util.py\", line 360, in _exit_function\n",
      "    _run_finalizers()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/util.py\", line 360, in _exit_function\n",
      "    _run_finalizers()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/util.py\", line 300, in _run_finalizers\n",
      "    finalizer()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/util.py\", line 300, in _run_finalizers\n",
      "    finalizer()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/util.py\", line 300, in _run_finalizers\n",
      "    finalizer()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/util.py\", line 300, in _run_finalizers\n",
      "    finalizer()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/util.py\", line 224, in __call__\n",
      "    res = self._callback(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/util.py\", line 224, in __call__\n",
      "    res = self._callback(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/util.py\", line 224, in __call__\n",
      "    res = self._callback(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/util.py\", line 224, in __call__\n",
      "    res = self._callback(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 195, in _finalize_join\n",
      "    thread.join()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 195, in _finalize_join\n",
      "    thread.join()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 195, in _finalize_join\n",
      "    thread.join()\n",
      "  File \"/usr/lib/python3.8/threading.py\", line 1011, in join\n",
      "    self._wait_for_tstate_lock()\n",
      "  File \"/usr/lib/python3.8/threading.py\", line 1011, in join\n",
      "    self._wait_for_tstate_lock()\n",
      "  File \"/usr/lib/python3.8/threading.py\", line 1011, in join\n",
      "    self._wait_for_tstate_lock()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 195, in _finalize_join\n",
      "    thread.join()\n",
      "  File \"/usr/lib/python3.8/threading.py\", line 1027, in _wait_for_tstate_lock\n",
      "    elif lock.acquire(block, timeout):\n",
      "  File \"/usr/lib/python3.8/threading.py\", line 1027, in _wait_for_tstate_lock\n",
      "    elif lock.acquire(block, timeout):\n",
      "  File \"/usr/lib/python3.8/threading.py\", line 1011, in join\n",
      "    self._wait_for_tstate_lock()\n",
      "  File \"/usr/lib/python3.8/threading.py\", line 1027, in _wait_for_tstate_lock\n",
      "    elif lock.acquire(block, timeout):\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.8/threading.py\", line 1027, in _wait_for_tstate_lock\n",
      "    elif lock.acquire(block, timeout):\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "Failed to compute suggesting for `lr`. There might not be enough points.\n",
      "Traceback (most recent call last):\n",
      "  File \"/data3/johnkim/environments/env_pytorch/lib/python3.8/site-packages/pytorch_lightning/trainer/lr_finder.py\", line 336, in suggestion\n",
      "    min_grad = np.gradient(loss).argmin()\n",
      "  File \"<__array_function__ internals>\", line 5, in gradient\n",
      "  File \"/data3/johnkim/environments/env_pytorch/lib/python3.8/site-packages/numpy/lib/function_base.py\", line 1041, in gradient\n",
      "    raise ValueError(\n",
      "ValueError: Shape of array too small to calculate a numerical gradient, at least (edge_order + 1) elements are required.\n",
      "Learning rate set to None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load and cache transformed data...\n",
      "115/115 [==============================]  \n",
      "Load and cache transformed data...\n",
      "29/29 [==============================]  \n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'<=' not supported between instances of 'float' and 'NoneType'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-68048e15df14>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     39\u001b[0m )\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/data3/johnkim/environments/env_pytorch/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, train_dataloader, val_dataloaders)\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_scale_batch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    873\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_scale_batch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'power'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 874\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale_batch_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_scale_batch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    875\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogger\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogger\u001b[0m  \u001b[0;31m# reset logger binding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    876\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data3/johnkim/environments/env_pytorch/lib/python3.8/site-packages/pytorch_lightning/trainer/training_tricks.py\u001b[0m in \u001b[0;36mscale_batch_size\u001b[0;34m(self, model, mode, steps_per_trial, init_val, max_trials, batch_arg_name)\u001b[0m\n\u001b[1;32m    162\u001b[0m             \u001b[0mnew_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_run_power_scaling\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_arg_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_trials\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'binsearch'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m             \u001b[0mnew_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_run_binsearch_scaling\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_arg_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_trials\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    165\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'mode in method `scale_batch_size` can only be `power` or `binsearch'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data3/johnkim/environments/env_pytorch/lib/python3.8/site-packages/pytorch_lightning/trainer/training_tricks.py\u001b[0m in \u001b[0;36m_run_binsearch_scaling\u001b[0;34m(trainer, model, new_size, batch_arg_name, max_trials)\u001b[0m\n\u001b[1;32m    291\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m             \u001b[0;31m# Try fit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 293\u001b[0;31m             \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    294\u001b[0m             \u001b[0mcount\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mcount\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mmax_trials\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data3/johnkim/environments/env_pytorch/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, train_dataloader, val_dataloaders)\u001b[0m\n\u001b[1;32m    926\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    927\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msingle_gpu\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 928\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msingle_gpu_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    929\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    930\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_tpu\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pragma: no-cover\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data3/johnkim/environments/env_pytorch/lib/python3.8/site-packages/pytorch_lightning/trainer/distrib_parts.py\u001b[0m in \u001b[0;36msingle_gpu_train\u001b[0;34m(self, model)\u001b[0m\n\u001b[1;32m    172\u001b[0m         \u001b[0;31m# CHOOSE OPTIMIZER\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m         \u001b[0;31m# allow for lr schedulers as well\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 174\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr_schedulers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer_frequencies\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_optimizers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    175\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m         \u001b[0;31m# TODO: remove with dropping NVIDIA AMP support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data3/johnkim/environments/env_pytorch/lib/python3.8/site-packages/pytorch_lightning/trainer/optimizers.py\u001b[0m in \u001b[0;36minit_optimizers\u001b[0;34m(self, model)\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mLightningModule\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     ) -> Tuple[List, List, List]:\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0moptim_conf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfigure_optimizers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0moptim_conf\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-2209d700e138>\u001b[0m in \u001b[0;36mconfigure_optimizers\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mconfigure_optimizers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data3/johnkim/environments/env_pytorch/lib/python3.8/site-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, params, lr, betas, eps, weight_decay, amsgrad)\u001b[0m\n\u001b[1;32m     30\u001b[0m     def __init__(self, params, lr=1e-3, betas=(0.9, 0.999), eps=1e-8,\n\u001b[1;32m     31\u001b[0m                  weight_decay=0, amsgrad=False):\n\u001b[0;32m---> 32\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;36m0.0\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid learning rate: {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;36m0.0\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: '<=' not supported between instances of 'float' and 'NoneType'"
     ]
    }
   ],
   "source": [
    "NAME = 'models/6-29-2020/'\n",
    "NUM_EPOCHS = 1000\n",
    "\n",
    "criterion = monai.losses.DiceLoss(to_onehot_y=True, softmax=True)\n",
    "\n",
    "model = UNet(\n",
    "    data_dir='data/',\n",
    "    dimensions=3,\n",
    "    in_channels=1,\n",
    "    out_channels=2,\n",
    "    channels=(64, 128, 258, 512, 1024),\n",
    "    strides=(2, 2, 2, 2),\n",
    "    norm=monai.networks.layers.Norm.BATCH,\n",
    "    criterion=criterion,\n",
    "    augmentations=Identityd(keys=[\"image\", \"mask\"]),\n",
    "    dropout=0,\n",
    ")\n",
    "\n",
    "logger = TensorBoardLogger(NAME + \"tb_logs/\", name='')\n",
    "\n",
    "# Callbacks\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=10\n",
    ")\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(filepath=NAME + 'checkpoints/')\n",
    "\n",
    "\n",
    "trainer = Trainer(\n",
    "    auto_lr_find=True,\n",
    "    auto_scale_batch_size='binsearch',\n",
    "    checkpoint_callback=checkpoint_callback,\n",
    "    early_stop_callback=early_stopping,\n",
    "    check_val_every_n_epoch=5,\n",
    "    gpus=1,\n",
    "    max_epochs=NUM_EPOCHS,\n",
    "    logger=logger,\n",
    ")\n",
    "\n",
    "trainer.fit(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
