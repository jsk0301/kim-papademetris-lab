{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3D Unet\n",
    "\n",
    "In this notebook, I'm going to be exploring variations in preprocessing steps/hyperparameters in the 3D UNet structure with 256x256x16 patches.\n",
    "\n",
    "Remastered 7-15-2020."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "import monai\n",
    "from monai.networks.nets import UNet\n",
    "from monai.transforms import (\n",
    "    Compose,\n",
    "    LoadNiftid,\n",
    "    ScaleIntensityd,\n",
    "    NormalizeIntensityd,\n",
    "    AddChanneld,\n",
    "    ToTensord,\n",
    "    RandSpatialCropd,\n",
    "    RandCropByPosNegLabeld,\n",
    "    CropForegroundd,\n",
    "    Identityd,\n",
    ")\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNet_3D(pl.LightningModule):\n",
    "    def __init__(self, hparams):\n",
    "        super().__init__()\n",
    "        self.hparams = hparams\n",
    "        \n",
    "        self.unet = UNet(\n",
    "            dimensions=3,\n",
    "            in_channels=1,\n",
    "            out_channels=2,\n",
    "            channels=(64, 128, 258, 512, 1024),\n",
    "            strides=(2, 2, 2, 2),\n",
    "            norm=monai.networks.layers.Norm.BATCH,\n",
    "            dropout=0,\n",
    "        )\n",
    "        self.sample_masks = []\n",
    "    \n",
    "    # Data setup\n",
    "    def setup(self, stage):\n",
    "        data_dir = 'data/'\n",
    "        \n",
    "        # Train imgs/masks\n",
    "        train_imgs = []\n",
    "        with open(data_dir + 'train_imgs.txt', 'r') as f:\n",
    "            train_imgs = [image.rstrip() for image in f.readlines()]\n",
    "\n",
    "        train_masks = []\n",
    "        with open(data_dir + 'train_masks.txt', 'r') as f:\n",
    "            train_masks = [mask.rstrip() for mask in f.readlines()]\n",
    "        \n",
    "        train_dicts = [{'image': image, 'mask': mask} for (image, mask) in zip(train_imgs, train_masks)]\n",
    "        \n",
    "        train_dicts, val_dicts = train_test_split(train_dicts, test_size=0.2)\n",
    "        \n",
    "        # Basic transforms\n",
    "        data_keys = [\"image\", \"mask\"]\n",
    "        data_transforms = Compose(\n",
    "            [\n",
    "                LoadNiftid(keys=data_keys),\n",
    "                AddChanneld(keys=data_keys),\n",
    "                NormalizeIntensityd(keys=\"image\"),\n",
    "                RandCropByPosNegLabeld(\n",
    "                    keys=data_keys,\n",
    "                    label_key=\"mask\",\n",
    "                    spatial_size=self.hparams.patch_size,\n",
    "                    num_samples=4,\n",
    "                    image_key=\"image\"\n",
    "                ),\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "        self.train_dataset = monai.data.CacheDataset(\n",
    "            data=train_dicts,\n",
    "            transform=Compose(\n",
    "                [\n",
    "                    data_transforms,\n",
    "                    ToTensord(keys=data_keys)\n",
    "                ]\n",
    "            ),\n",
    "            cache_rate=1.0\n",
    "        )\n",
    "        \n",
    "        self.val_dataset = monai.data.CacheDataset(\n",
    "            data=val_dicts,\n",
    "            transform=Compose(\n",
    "                [\n",
    "                    data_transforms,\n",
    "                    ToTensord(keys=data_keys)\n",
    "                ]\n",
    "            ),\n",
    "            cache_rate=1.0\n",
    "        )\n",
    "        \n",
    "    def train_dataloader(self):\n",
    "        return monai.data.DataLoader(\n",
    "            self.train_dataset, batch_size=self.hparams.batch_size, shuffle=True, num_workers=hparams.num_workers\n",
    "        )\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return monai.data.DataLoader(\n",
    "            self.val_dataset, batch_size=self.hparams.batch_size, num_workers=hparams.num_workers\n",
    "        )\n",
    "    \n",
    "    # Training setup\n",
    "    def forward(self, image):\n",
    "        return self.unet(image)\n",
    "    \n",
    "    def criterion(self, y_hat, y):\n",
    "        dice_loss = monai.losses.DiceLoss(\n",
    "            to_onehot_y=True,\n",
    "            softmax=True\n",
    "        )\n",
    "        return dice_loss(y_hat, y)\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        inputs, labels = batch['image'], batch['mask']\n",
    "        outputs = self(inputs)\n",
    "        loss = self.criterion(outputs, labels)\n",
    "\n",
    "        self.logger.log_metrics({\"loss/train\": loss}, self.global_step)\n",
    "\n",
    "        return {'loss': loss}\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        lr = self.hparams.lr\n",
    "        optimizer = torch.optim.Adam(self.unet.parameters(), lr=lr)\n",
    "        return optimizer\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        inputs, labels = (\n",
    "            batch[\"image\"],\n",
    "            batch[\"mask\"],\n",
    "        )\n",
    "        outputs = self(inputs)\n",
    "        \n",
    "        # Sample masks\n",
    "        if self.current_epoch != 0:\n",
    "            image = outputs[0].argmax(0)[:, :, 8].unsqueeze(0).detach()\n",
    "            self.sample_masks.append(image)\n",
    "        \n",
    "        loss = self.criterion(outputs, labels)\n",
    "        return {\"val_loss\": loss}\n",
    "\n",
    "    def validation_epoch_end(self, outputs):\n",
    "        avg_loss = torch.stack([x[\"val_loss\"] for x in outputs]).mean()\n",
    "        self.logger.log_metrics({\"val/loss\": avg_loss}, self.current_epoch)\n",
    "        \n",
    "        if self.current_epoch != 0:\n",
    "            grid = torchvision.utils.make_grid(self.sample_masks)\n",
    "            self.logger.experiment.add_image('sample_masks', grid, self.current_epoch)\n",
    "            self.sample_masks = []\n",
    "        \n",
    "        return {\"val_loss\": avg_loss}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from argparse import Namespace\n",
    "\n",
    "args = {\n",
    "    'name': '7-15-2020_3dremastered',\n",
    "    'batch_size': 2,\n",
    "    'lr': 0.001,\n",
    "    'patch_size': [256, 256, 16],\n",
    "    'num_workers': 6,\n",
    "}\n",
    "\n",
    "hparams = Namespace(**args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = UNet_3D(hparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "CUDA_VISIBLE_DEVICES: [0,1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/115 Load and cache transformed data:  [                              ]\r",
      "2/115 Load and cache transformed data:  [                              ]\r",
      "3/115 Load and cache transformed data:  [                              ]\r",
      "4/115 Load and cache transformed data:  [=                             ]\r",
      "5/115 Load and cache transformed data:  [=                             ]\r",
      "6/115 Load and cache transformed data:  [=                             ]\r",
      "7/115 Load and cache transformed data:  [=                             ]\r",
      "8/115 Load and cache transformed data:  [==                            ]\r",
      "9/115 Load and cache transformed data:  [==                            ]\r",
      "10/115 Load and cache transformed data:  [==                            ]\r",
      "11/115 Load and cache transformed data:  [==                            ]\r",
      "12/115 Load and cache transformed data:  [===                           ]\r",
      "13/115 Load and cache transformed data:  [===                           ]\r",
      "14/115 Load and cache transformed data:  [===                           ]\r",
      "15/115 Load and cache transformed data:  [===                           ]\r",
      "16/115 Load and cache transformed data:  [====                          ]\r",
      "17/115 Load and cache transformed data:  [====                          ]\r",
      "18/115 Load and cache transformed data:  [====                          ]\r",
      "19/115 Load and cache transformed data:  [====                          ]\r",
      "20/115 Load and cache transformed data:  [=====                         ]\r",
      "21/115 Load and cache transformed data:  [=====                         ]\r",
      "22/115 Load and cache transformed data:  [=====                         ]\r",
      "23/115 Load and cache transformed data:  [======                        ]\r",
      "24/115 Load and cache transformed data:  [======                        ]\r",
      "25/115 Load and cache transformed data:  [======                        ]\r",
      "26/115 Load and cache transformed data:  [======                        ]\r",
      "27/115 Load and cache transformed data:  [=======                       ]\r",
      "28/115 Load and cache transformed data:  [=======                       ]\r",
      "29/115 Load and cache transformed data:  [=======                       ]\r",
      "30/115 Load and cache transformed data:  [=======                       ]\r",
      "31/115 Load and cache transformed data:  [========                      ]\r",
      "32/115 Load and cache transformed data:  [========                      ]\r",
      "33/115 Load and cache transformed data:  [========                      ]\r",
      "34/115 Load and cache transformed data:  [========                      ]\r",
      "35/115 Load and cache transformed data:  [=========                     ]\r",
      "36/115 Load and cache transformed data:  [=========                     ]\r",
      "37/115 Load and cache transformed data:  [=========                     ]\r",
      "38/115 Load and cache transformed data:  [=========                     ]\r",
      "39/115 Load and cache transformed data:  [==========                    ]\r",
      "40/115 Load and cache transformed data:  [==========                    ]\r",
      "41/115 Load and cache transformed data:  [==========                    ]\r",
      "42/115 Load and cache transformed data:  [==========                    ]\r",
      "43/115 Load and cache transformed data:  [===========                   ]\r",
      "44/115 Load and cache transformed data:  [===========                   ]\r",
      "45/115 Load and cache transformed data:  [===========                   ]\r",
      "46/115 Load and cache transformed data:  [============                  ]\r",
      "47/115 Load and cache transformed data:  [============                  ]\r",
      "48/115 Load and cache transformed data:  [============                  ]\r",
      "49/115 Load and cache transformed data:  [============                  ]\r",
      "50/115 Load and cache transformed data:  [=============                 ]\r",
      "51/115 Load and cache transformed data:  [=============                 ]\r",
      "52/115 Load and cache transformed data:  [=============                 ]\r",
      "53/115 Load and cache transformed data:  [=============                 ]\r",
      "54/115 Load and cache transformed data:  [==============                ]\r",
      "55/115 Load and cache transformed data:  [==============                ]\r",
      "56/115 Load and cache transformed data:  [==============                ]\r",
      "57/115 Load and cache transformed data:  [==============                ]\r",
      "58/115 Load and cache transformed data:  [===============               ]\r",
      "59/115 Load and cache transformed data:  [===============               ]\r",
      "60/115 Load and cache transformed data:  [===============               ]\r",
      "61/115 Load and cache transformed data:  [===============               ]\r",
      "62/115 Load and cache transformed data:  [================              ]\r",
      "63/115 Load and cache transformed data:  [================              ]\r",
      "64/115 Load and cache transformed data:  [================              ]\r",
      "65/115 Load and cache transformed data:  [================              ]\r",
      "66/115 Load and cache transformed data:  [=================             ]\r",
      "67/115 Load and cache transformed data:  [=================             ]\r",
      "68/115 Load and cache transformed data:  [=================             ]\r",
      "69/115 Load and cache transformed data:  [==================            ]\r",
      "70/115 Load and cache transformed data:  [==================            ]\r",
      "71/115 Load and cache transformed data:  [==================            ]\r",
      "72/115 Load and cache transformed data:  [==================            ]\r",
      "73/115 Load and cache transformed data:  [===================           ]\r",
      "74/115 Load and cache transformed data:  [===================           ]\r",
      "75/115 Load and cache transformed data:  [===================           ]\r",
      "76/115 Load and cache transformed data:  [===================           ]\r",
      "77/115 Load and cache transformed data:  [====================          ]\r",
      "78/115 Load and cache transformed data:  [====================          ]\r",
      "79/115 Load and cache transformed data:  [====================          ]\r",
      "80/115 Load and cache transformed data:  [====================          ]\r",
      "81/115 Load and cache transformed data:  [=====================         ]\r",
      "82/115 Load and cache transformed data:  [=====================         ]\r",
      "83/115 Load and cache transformed data:  [=====================         ]\r",
      "84/115 Load and cache transformed data:  [=====================         ]\r",
      "85/115 Load and cache transformed data:  [======================        ]\r",
      "86/115 Load and cache transformed data:  [======================        ]\r",
      "87/115 Load and cache transformed data:  [======================        ]\r",
      "88/115 Load and cache transformed data:  [======================        ]\r",
      "89/115 Load and cache transformed data:  [=======================       ]\r",
      "90/115 Load and cache transformed data:  [=======================       ]\r",
      "91/115 Load and cache transformed data:  [=======================       ]\r",
      "92/115 Load and cache transformed data:  [========================      ]\r",
      "93/115 Load and cache transformed data:  [========================      ]\r",
      "94/115 Load and cache transformed data:  [========================      ]\r",
      "95/115 Load and cache transformed data:  [========================      ]\r",
      "96/115 Load and cache transformed data:  [=========================     ]\r",
      "97/115 Load and cache transformed data:  [=========================     ]\r",
      "98/115 Load and cache transformed data:  [=========================     ]\r",
      "99/115 Load and cache transformed data:  [=========================     ]\r",
      "100/115 Load and cache transformed data:  [==========================    ]\r",
      "101/115 Load and cache transformed data:  [==========================    ]\r",
      "102/115 Load and cache transformed data:  [==========================    ]\r",
      "103/115 Load and cache transformed data:  [==========================    ]\r",
      "104/115 Load and cache transformed data:  [===========================   ]\r",
      "105/115 Load and cache transformed data:  [===========================   ]\r",
      "106/115 Load and cache transformed data:  [===========================   ]\r",
      "107/115 Load and cache transformed data:  [===========================   ]\r",
      "108/115 Load and cache transformed data:  [============================  ]\r",
      "109/115 Load and cache transformed data:  [============================  ]\r",
      "110/115 Load and cache transformed data:  [============================  ]\r",
      "111/115 Load and cache transformed data:  [============================  ]\r",
      "112/115 Load and cache transformed data:  [============================= ]\r",
      "113/115 Load and cache transformed data:  [============================= ]\r",
      "114/115 Load and cache transformed data:  [============================= ]\r",
      "115/115 Load and cache transformed data:  [==============================]\r\n",
      "1/29 Load and cache transformed data:  [=                             ]\r",
      "2/29 Load and cache transformed data:  [==                            ]\r",
      "3/29 Load and cache transformed data:  [===                           ]\r",
      "4/29 Load and cache transformed data:  [====                          ]\r",
      "5/29 Load and cache transformed data:  [=====                         ]\r",
      "6/29 Load and cache transformed data:  [======                        ]\r",
      "7/29 Load and cache transformed data:  [=======                       ]\r",
      "8/29 Load and cache transformed data:  [========                      ]\r",
      "9/29 Load and cache transformed data:  [=========                     ]\r",
      "10/29 Load and cache transformed data:  [==========                    ]\r",
      "11/29 Load and cache transformed data:  [===========                   ]\r",
      "12/29 Load and cache transformed data:  [============                  ]\r",
      "13/29 Load and cache transformed data:  [=============                 ]\r",
      "14/29 Load and cache transformed data:  [==============                ]\r",
      "15/29 Load and cache transformed data:  [===============               ]\r",
      "16/29 Load and cache transformed data:  [================              ]\r",
      "17/29 Load and cache transformed data:  [=================             ]\r",
      "18/29 Load and cache transformed data:  [==================            ]\r",
      "19/29 Load and cache transformed data:  [===================           ]\r",
      "20/29 Load and cache transformed data:  [====================          ]\r",
      "21/29 Load and cache transformed data:  [=====================         ]\r",
      "22/29 Load and cache transformed data:  [======================        ]\r",
      "23/29 Load and cache transformed data:  [=======================       ]\r",
      "24/29 Load and cache transformed data:  [========================      ]\r",
      "25/29 Load and cache transformed data:  [=========================     ]\r",
      "26/29 Load and cache transformed data:  [==========================    ]\r",
      "27/29 Load and cache transformed data:  [===========================   ]\r",
      "28/29 Load and cache transformed data:  [============================  ]\r",
      "29/29 Load and cache transformed data:  [==============================]\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name | Type | Params\n",
      "------------------------------\n",
      "0 | unet | UNet | 31 M  \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validation sanity check', layout=Layout…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7628446743f14e5ab9f5362ba4243f9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Training', layout=Layout(flex='2'), max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data3/johnkim/environments/env_pytorch/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:25: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NAME = 'models/' + hparams.name\n",
    "logger = pl.loggers.TensorBoardLogger(NAME + \"/tb_logs/\", name='')\n",
    "\n",
    "# Callbacks\n",
    "early_stopping = pl.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=10\n",
    ")\n",
    "\n",
    "checkpoint_callback = pl.callbacks.ModelCheckpoint(filepath=NAME + '/checkpoints/')\n",
    "\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    checkpoint_callback=checkpoint_callback,\n",
    "    early_stop_callback=early_stopping,\n",
    "    check_val_every_n_epoch=5,\n",
    "    gpus=1,\n",
    "    max_epochs=1000,\n",
    "    logger=logger,\n",
    ")\n",
    "\n",
    "trainer.fit(model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
