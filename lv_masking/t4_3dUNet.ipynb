{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3D Unet\n",
    "\n",
    "In this notebook, I'm going to be exploring variations in preprocessing steps/hyperparameters in the 3D UNet structure with 256x256x16 patches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implemented with PyTorch Lightning\n",
    "### Imports\n",
    "import numpy as np\n",
    "from skimage import measure\n",
    "\n",
    "# PyTorch imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# MONAI imports\n",
    "import monai\n",
    "from monai.transforms import (\n",
    "    Compose,\n",
    "    LoadNiftid,\n",
    "    ScaleIntensityd,\n",
    "    NormalizeIntensityd,\n",
    "    AddChanneld,\n",
    "    ToTensord,\n",
    "    RandSpatialCropd,\n",
    "    RandCropByPosNegLabeld,\n",
    "    CropForegroundd,\n",
    "    Identityd,\n",
    ")\n",
    "from monai.networks.blocks.convolutions import Convolution, ResidualUnit\n",
    "from monai.networks.layers.factories import Norm, Act\n",
    "from monai.networks.layers.simplelayers import SkipConnection\n",
    "from monai.utils import export\n",
    "from monai.utils.aliases import alias\n",
    "\n",
    "# PyTorch Lightning imports\n",
    "from pytorch_lightning.core.lightning import LightningModule\n",
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from pytorch_lightning.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### UNet Model\n",
    "\n",
    "# Most of the code is copied from MONAI's implenetation of a UNet\n",
    "class UNet(LightningModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        data_dir,\n",
    "        dimensions,\n",
    "        in_channels,\n",
    "        out_channels,\n",
    "        channels,\n",
    "        strides,\n",
    "        criterion,\n",
    "        augmentations,\n",
    "        kernel_size=3,\n",
    "        up_kernel_size=3,\n",
    "        num_res_units=0,\n",
    "        act=Act.PRELU,\n",
    "        norm=Norm.INSTANCE,\n",
    "        dropout=0,\n",
    "        batch_size=1,\n",
    "        lr=0.01,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        assert len(channels) == (len(strides) + 1)\n",
    "        self.data_dir = data_dir\n",
    "        self.dimensions = dimensions\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.channels = channels\n",
    "        self.strides = strides\n",
    "        self.criterion = criterion\n",
    "        self.kernel_size = kernel_size\n",
    "        self.up_kernel_size = up_kernel_size\n",
    "        self.num_res_units = num_res_units\n",
    "        self.act = act\n",
    "        self.norm = norm\n",
    "        self.dropout = dropout\n",
    "        self.augmentations = augmentations\n",
    "        self.batch_size = batch_size\n",
    "        self.lr = lr\n",
    "        \n",
    "        self.save_hyperparameters(\n",
    "            'dimensions',\n",
    "            'channels',\n",
    "            'criterion',\n",
    "            'num_res_units',\n",
    "            'dropout',\n",
    "            'augmentations',\n",
    "            'batch_size',\n",
    "            'lr'\n",
    "        )\n",
    "\n",
    "        def _create_block(inc, outc, channels, strides, is_top):\n",
    "            \"\"\"\n",
    "            Builds the UNet structure from the bottom up by recursing down to the bottom block, then creating sequential\n",
    "            blocks containing the downsample path, a skip connection around the previous block, and the upsample path.\n",
    "            \"\"\"\n",
    "            c = channels[0]\n",
    "            s = strides[0]\n",
    "\n",
    "            if len(channels) > 2:\n",
    "                subblock = _create_block(\n",
    "                    c, c, channels[1:], strides[1:], False\n",
    "                )  # continue recursion down\n",
    "                upc = c * 2\n",
    "            else:\n",
    "                # the next layer is the bottom so stop recursion, create the bottom layer as the sublock for this layer\n",
    "                subblock = self._get_bottom_layer(c, channels[1])\n",
    "                upc = c + channels[1]\n",
    "\n",
    "            down = self._get_down_layer(\n",
    "                inc, c, s, is_top\n",
    "            )  # create layer in downsampling path\n",
    "            up = self._get_up_layer(\n",
    "                upc, outc, s, is_top\n",
    "            )  # create layer in upsampling path\n",
    "\n",
    "            return nn.Sequential(down, SkipConnection(subblock), up)\n",
    "\n",
    "        self.model = _create_block(\n",
    "            in_channels, out_channels, self.channels, self.strides, True\n",
    "        )\n",
    "\n",
    "    def _get_down_layer(self, in_channels, out_channels, strides, is_top):\n",
    "        if self.num_res_units > 0:\n",
    "            return ResidualUnit(\n",
    "                self.dimensions,\n",
    "                in_channels,\n",
    "                out_channels,\n",
    "                strides,\n",
    "                self.kernel_size,\n",
    "                self.num_res_units,\n",
    "                self.act,\n",
    "                self.norm,\n",
    "                self.dropout,\n",
    "            )\n",
    "        else:\n",
    "            return Convolution(\n",
    "                self.dimensions,\n",
    "                in_channels,\n",
    "                out_channels,\n",
    "                strides,\n",
    "                self.kernel_size,\n",
    "                self.act,\n",
    "                self.norm,\n",
    "                self.dropout,\n",
    "            )\n",
    "\n",
    "    def _get_bottom_layer(self, in_channels, out_channels):\n",
    "        return self._get_down_layer(in_channels, out_channels, 1, False)\n",
    "\n",
    "    def _get_up_layer(self, in_channels, out_channels, strides, is_top):\n",
    "        conv = Convolution(\n",
    "            self.dimensions,\n",
    "            in_channels,\n",
    "            out_channels,\n",
    "            strides,\n",
    "            self.up_kernel_size,\n",
    "            self.act,\n",
    "            self.norm,\n",
    "            self.dropout,\n",
    "            conv_only=is_top and self.num_res_units == 0,\n",
    "            is_transposed=True,\n",
    "        )\n",
    "\n",
    "        if self.num_res_units > 0:\n",
    "            ru = ResidualUnit(\n",
    "                self.dimensions,\n",
    "                out_channels,\n",
    "                out_channels,\n",
    "                1,\n",
    "                self.kernel_size,\n",
    "                1,\n",
    "                self.act,\n",
    "                self.norm,\n",
    "                self.dropout,\n",
    "                last_conv_only=is_top,\n",
    "            )\n",
    "            return nn.Sequential(conv, ru)\n",
    "        else:\n",
    "            return conv\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "    # Lightning training\n",
    "    def setup(self, stage):\n",
    "        data_dir = 'data/'\n",
    "        \n",
    "        # Train imgs/masks\n",
    "        train_imgs = []\n",
    "        with open(data_dir + 'train_imgs.txt', 'r') as f:\n",
    "            train_imgs = [image.rstrip() for image in f.readlines()]\n",
    "\n",
    "        train_masks = []\n",
    "        with open(data_dir + 'train_masks.txt', 'r') as f:\n",
    "            train_masks = [mask.rstrip() for mask in f.readlines()]\n",
    "        \n",
    "        train_dicts = [{'image': image, 'mask': mask} for (image, mask) in zip(train_imgs, train_masks)]\n",
    "        \n",
    "        train_dicts, val_dicts = train_test_split(train_dicts, test_size=0.2)\n",
    "        \n",
    "        # Basic transforms\n",
    "        data_keys = [\"image\", \"mask\"]\n",
    "        data_transforms = Compose(\n",
    "            [\n",
    "                LoadNiftid(keys=data_keys),\n",
    "                AddChanneld(keys=data_keys),\n",
    "                NormalizeIntensityd(keys=\"image\"),\n",
    "                RandCropByPosNegLabeld(\n",
    "                    keys=data_keys, label_key=\"mask\", size=(256, 256, 16), num_samples=4, image_key=\"image\"\n",
    "                ),\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "        self.train_dataset = monai.data.CacheDataset(\n",
    "            data=train_dicts,\n",
    "            transform=Compose(\n",
    "                [\n",
    "                    data_transforms,\n",
    "                    self.augmentations,\n",
    "                    ToTensord(keys=data_keys)\n",
    "                ]\n",
    "            ),\n",
    "            cache_rate=1.0\n",
    "        )\n",
    "        \n",
    "        self.val_dataset = monai.data.CacheDataset(\n",
    "            data=val_dicts,\n",
    "            transform=Compose(\n",
    "                [\n",
    "                    data_transforms,\n",
    "                    ToTensord(keys=data_keys)\n",
    "                ]\n",
    "            ),\n",
    "            cache_rate=1.0\n",
    "        )\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=self.lr)\n",
    "        \n",
    "    def train_dataloader(self):\n",
    "        return monai.data.DataLoader(\n",
    "            self.train_dataset, batch_size=self.batch_size, shuffle=True, num_workers=8\n",
    "        )\n",
    "    \n",
    "    def val_dataloader(self):\n",
    "        return monai.data.DataLoader(\n",
    "            self.val_dataset, batch_size=self.batch_size, num_workers=8\n",
    "        )\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        inputs, labels = (\n",
    "            batch[\"image\"],\n",
    "            batch[\"mask\"],\n",
    "        )\n",
    "        outputs = self(inputs)\n",
    "        loss = self.criterion(outputs, labels)\n",
    "        tensorboard_logs = {\"loss/train\": loss}\n",
    "        return {\"loss\": loss, \"log\": tensorboard_logs}\n",
    "    \n",
    "\n",
    "    # Lightning validation\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        inputs, labels = (\n",
    "            batch[\"image\"],\n",
    "            batch[\"mask\"],\n",
    "        )\n",
    "        outputs = self(inputs)\n",
    "        loss = self.criterion(outputs, labels)\n",
    "        return {\"val_loss\": loss}\n",
    "\n",
    "    def validation_epoch_end(self, outputs):\n",
    "        avg_loss = torch.stack([x[\"val_loss\"] for x in outputs]).mean()\n",
    "        tensorboard_logs = {\"loss/val\": avg_loss}\n",
    "        return {\"val_loss\": avg_loss, \"log\": tensorboard_logs}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def region_loss(outputs, labels):\n",
    "#     dice = monai.losses.DiceLoss(to_onehot_y=True, softmax=True)\n",
    "#     loss = dice(outputs, labels)\n",
    "#     for item in batch\n",
    "#         for img_slice in outputs[:, :]:\n",
    "#             num_regions = len(measure.regionprops(measure.label(img_slice)))\n",
    "#             if num_regions >= 2:\n",
    "#                 loss += 0.5 * num_regions\n",
    "#     return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "MisconfigurationException",
     "evalue": "\n                You requested GPUs: [0]\n                But your machine only has: []\n            ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMisconfigurationException\u001b[0m                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-ab89a5c358a1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m trainer = Trainer(\n\u001b[0m\u001b[1;32m     33\u001b[0m     \u001b[0mauto_lr_find\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0mauto_scale_batch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'binsearch'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data3/johnkim/environments/env_pytorch/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, logger, checkpoint_callback, early_stop_callback, callbacks, default_root_dir, gradient_clip_val, process_position, num_nodes, num_processes, gpus, auto_select_gpus, tpu_cores, log_gpu_memory, progress_bar_refresh_rate, overfit_batches, track_grad_norm, check_val_every_n_epoch, fast_dev_run, accumulate_grad_batches, max_epochs, min_epochs, max_steps, min_steps, limit_train_batches, limit_val_batches, limit_test_batches, val_check_interval, log_save_interval, row_log_interval, distributed_backend, precision, print_nan_grads, weights_summary, weights_save_path, num_sanity_val_steps, truncated_bptt_steps, resume_from_checkpoint, profiler, benchmark, deterministic, reload_dataloaders_every_epoch, auto_lr_find, replace_sampler_ddp, terminate_on_nan, auto_scale_batch_size, prepare_data_per_node, amp_level, num_tpu_cores, use_amp, show_progress_bar, val_percent_check, test_percent_check, train_percent_check, overfit_pct)\u001b[0m\n\u001b[1;32m    466\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgpus\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgpus\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    467\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 468\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_parallel_device_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_parse_gpu_ids\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgpus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    469\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot_gpu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdetermine_root_gpu_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_parallel_device_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    470\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot_device\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data3/johnkim/environments/env_pytorch/lib/python3.8/site-packages/pytorch_lightning/trainer/distrib_parts.py\u001b[0m in \u001b[0;36m_parse_gpu_ids\u001b[0;34m(gpus)\u001b[0m\n\u001b[1;32m    442\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mgpus\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mMisconfigurationException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"GPUs requested but none are available.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 444\u001b[0;31m     \u001b[0mgpus\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msanitize_gpu_ids\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgpus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    445\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    446\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgpus\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data3/johnkim/environments/env_pytorch/lib/python3.8/site-packages/pytorch_lightning/trainer/distrib_parts.py\u001b[0m in \u001b[0;36msanitize_gpu_ids\u001b[0;34m(gpus)\u001b[0m\n\u001b[1;32m    398\u001b[0m             \u001b[0mgpus\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mall_available_gpus\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    399\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 400\u001b[0;31m             raise MisconfigurationException(f\"\"\"\n\u001b[0m\u001b[1;32m    401\u001b[0m                 \u001b[0mYou\u001b[0m \u001b[0mrequested\u001b[0m \u001b[0mGPUs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mgpus\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m                 \u001b[0mBut\u001b[0m \u001b[0myour\u001b[0m \u001b[0mmachine\u001b[0m \u001b[0monly\u001b[0m \u001b[0mhas\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mall_available_gpus\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMisconfigurationException\u001b[0m: \n                You requested GPUs: [0]\n                But your machine only has: []\n            "
     ]
    }
   ],
   "source": [
    "NAME = 'models/6-29-2020/'\n",
    "NUM_EPOCHS = 1000\n",
    "\n",
    "# criterion = monai.losses.DiceLoss(to_onehot_y=True, softmax=True)\n",
    "criterion = monai.losses.FocalLoss()\n",
    "\n",
    "model = UNet(\n",
    "    data_dir='data/',\n",
    "    dimensions=3,\n",
    "    in_channels=1,\n",
    "    out_channels=2,\n",
    "    channels=(64, 128, 258, 512, 1024),\n",
    "    strides=(2, 2, 2, 2),\n",
    "    norm=monai.networks.layers.Norm.BATCH,\n",
    "    criterion=criterion,\n",
    "    augmentations=Identityd(keys=[\"image\", \"mask\"]),\n",
    "    dropout=0,\n",
    "    num_res_units=2,\n",
    ")\n",
    "\n",
    "logger = TensorBoardLogger(NAME + \"tb_logs/\", name='')\n",
    "\n",
    "# Callbacks\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=10\n",
    ")\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(filepath=NAME + 'checkpoints/')\n",
    "\n",
    "\n",
    "trainer = Trainer(\n",
    "    auto_lr_find=True,\n",
    "    auto_scale_batch_size='binsearch',\n",
    "    checkpoint_callback=checkpoint_callback,\n",
    "    early_stop_callback=early_stopping,\n",
    "    check_val_every_n_epoch=5,\n",
    "    gpus=1,\n",
    "    max_epochs=NUM_EPOCHS,\n",
    "    logger=logger,\n",
    ")\n",
    "\n",
    "trainer.fit(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
