{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that I have more training data, I'll be training a full 3D UNet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import monai\n",
    "from monai.transforms import(\n",
    "    Compose,\n",
    "    LoadNiftid,\n",
    "    AddChanneld,\n",
    "    ScaleIntensityRangePercentilesd,\n",
    "    RandCropByPosNegLabeld,\n",
    "    CenterSpatialCropd,\n",
    "    ToTensord\n",
    ")\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "import torch\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pytorch Lightning Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNet3D(pl.LightningModule):\n",
    "    def __init__(self, hparams):\n",
    "        super().__init__()\n",
    "        self.hparams = hparams\n",
    "        self.unet = monai.networks.nets.UNet(\n",
    "            dimensions=3,\n",
    "            in_channels=1,\n",
    "            out_channels=2,\n",
    "            channels=(16, 32, 64, 128, 256),\n",
    "            strides=(2, 2, 2, 2),\n",
    "            norm=monai.networks.layers.Norm.BATCH,\n",
    "            num_res_units=2\n",
    "        )\n",
    "        self.sample_masks = []\n",
    "    \n",
    "    def prepare_data(self):\n",
    "        data_dir = 'data/new/'\n",
    "        \n",
    "        # Train imgs/masks\n",
    "        train_imgs = []\n",
    "        train_masks = []\n",
    "        with open(data_dir + 'train_imgs.txt', 'r') as f:\n",
    "            train_imgs = [image.rstrip() for image in f.readlines()]\n",
    "        with open(data_dir + 'train_masks.txt', 'r') as f:\n",
    "            train_masks = [mask.rstrip() for mask in f.readlines()]\n",
    "        train_dicts = [{'image': image, 'mask': mask} for (image, mask) in zip(train_imgs, train_masks)]\n",
    "        train_dicts, val_dicts = train_test_split(train_dicts, test_size=0.2)\n",
    "        \n",
    "        # Basic transforms\n",
    "        data_keys = [\"image\", \"mask\"]\n",
    "        data_transforms = Compose(\n",
    "            [\n",
    "                LoadNiftid(keys=data_keys),\n",
    "                AddChanneld(keys=data_keys),\n",
    "                ScaleIntensityRangePercentilesd(\n",
    "                    keys=data_keys,\n",
    "                    lower=25,\n",
    "                    upper=75,\n",
    "                    b_min=-0.5,\n",
    "                    b_max=0.5\n",
    "                )\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "        self.train_dataset = monai.data.CacheDataset(\n",
    "            data=train_dicts,\n",
    "            transform=Compose(\n",
    "                [\n",
    "                    data_transforms,\n",
    "                    RandCropByPosNegLabeld(\n",
    "                        keys=data_keys,\n",
    "                        label_key=\"mask\",\n",
    "                        spatial_size=self.hparams.patch_size,\n",
    "                        num_samples=4,\n",
    "                        image_key=\"image\",\n",
    "                        pos=0.8,\n",
    "                        neg=0.2\n",
    "                    ),\n",
    "                    ToTensord(keys=data_keys)\n",
    "                ]\n",
    "            ),\n",
    "            cache_rate=1.0\n",
    "        )\n",
    "        \n",
    "        self.val_dataset = monai.data.CacheDataset(\n",
    "            data=val_dicts,\n",
    "            transform=Compose(\n",
    "                [\n",
    "                    data_transforms,\n",
    "                    CenterSpatialCropd(keys=data_keys, roi_size=self.hparams.patch_size),\n",
    "                    ToTensord(keys=data_keys)\n",
    "                ]\n",
    "            ),\n",
    "            cache_rate=1.0\n",
    "        )\n",
    "        \n",
    "    def train_dataloader(self):\n",
    "        return monai.data.DataLoader(\n",
    "            self.train_dataset,\n",
    "            batch_size=self.hparams.batch_size,\n",
    "            shuffle=True,\n",
    "            num_workers=hparams.num_workers\n",
    "        )\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return monai.data.DataLoader(\n",
    "            self.val_dataset,\n",
    "            batch_size=self.hparams.batch_size,\n",
    "            num_workers=hparams.num_workers\n",
    "        )\n",
    "    \n",
    "    # Training setup\n",
    "    def forward(self, image):\n",
    "        return self.unet(image)\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        inputs, labels = batch['image'], batch['mask']\n",
    "        outputs = self(inputs)\n",
    "        loss = self.criterion(outputs, labels)\n",
    "        self.logger.log_metrics({\"loss/train\": loss}, self.global_step)\n",
    "        return {'loss': loss}\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        inputs, labels = (\n",
    "            batch[\"image\"],\n",
    "            batch[\"mask\"],\n",
    "        )\n",
    "        outputs = self(inputs)\n",
    "        # Sample masks\n",
    "        if self.current_epoch != 0:\n",
    "            image = outputs[0].argmax(0)[:, :, 8].unsqueeze(0).detach()\n",
    "            self.sample_masks.append(image)\n",
    "        loss = self.criterion(outputs, labels)\n",
    "        return {\"val_loss\": loss}\n",
    "\n",
    "    def validation_epoch_end(self, outputs):\n",
    "        avg_loss = torch.stack([x[\"val_loss\"] for x in outputs]).mean()\n",
    "        self.logger.log_metrics({\"val/loss\": avg_loss}, self.current_epoch)\n",
    "        if self.current_epoch != 0:\n",
    "            grid = torchvision.utils.make_grid(self.sample_masks)\n",
    "            self.logger.experiment.add_image('sample_masks', grid, self.current_epoch)\n",
    "            self.sample_masks = []\n",
    "        return {\"val_loss\": avg_loss}\n",
    "    \n",
    "    def criterion(self, y_hat, y):\n",
    "        dice_loss = monai.losses.DiceLoss(\n",
    "            to_onehot_y=True,\n",
    "            softmax=True\n",
    "        )\n",
    "        focal_loss = monai.losses.FocalLoss()\n",
    "        return dice_loss(y_hat, y) + focal_loss(y_hat, y)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        lr = self.hparams.lr\n",
    "        optimizer = torch.optim.Adam(self.unet.parameters(), lr=lr)\n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from argparse import Namespace\n",
    "\n",
    "args = {\n",
    "    'name': '2020-10-14_UNet_NewData',\n",
    "    'batch_size': 2,\n",
    "    'lr': 0.001,\n",
    "    'patch_size': [256, 256, 16],\n",
    "    'num_workers': 6,\n",
    "}\n",
    "\n",
    "hparams = Namespace(**args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Namespace(batch_size=2, lr=0.001, name='2020-10-14_UNet_NewData', num_workers=6, patch_size=[256, 256, 16])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = UNet3D(hparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Load and cache transformed data: 100%|██████████| 187/187 [00:00<00:00, 308428.96it/s]\n",
      "Load and cache transformed data: 100%|██████████| 47/47 [00:00<00:00, 100989.90it/s]\n",
      "\n",
      "  | Name | Type | Params\n",
      "------------------------------\n",
      "0 | unet | UNet | 4 M   \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17e237175c754caeb5e581b6e42d3744",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validation sanity check', layout=Layout…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data3/johnkim/environments/env_pytorch/lib/python3.8/site-packages/monai/transforms/intensity/array.py:289: Warning: Divide by zero (a_min == a_max)\n",
      "  warn(\"Divide by zero (a_min == a_max)\", Warning)\n"
     ]
    }
   ],
   "source": [
    "filepath = 'models/' + hparams.name\n",
    "logger = pl.loggers.TensorBoardLogger(filepath + \"/tb_logs/\", name='')\n",
    "\n",
    "# Callbacks\n",
    "early_stopping_cb = pl.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=5\n",
    ")\n",
    "checkpoint_cb = pl.callbacks.ModelCheckpoint(\n",
    "    monitor='val_loss',\n",
    "    filepath=filepath + '/checkpoints/{epoch:02d}-{val_loss:.2f}'\n",
    ")\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    auto_scale_batch_size='binsearch',\n",
    "    checkpoint_callback=checkpoint_cb,\n",
    "    callbacks=[early_stopping_cb],\n",
    "    check_val_every_n_epoch=5,\n",
    "    gpus=1,\n",
    "    max_epochs=1000,\n",
    "    logger=logger,\n",
    ")\n",
    "\n",
    "trainer.fit(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
