/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
DEBUG:tensorflow:+++++ Looking for CUDA devices
DEBUG:tensorflow:+++++ gpu:0 CUDA_VISIBLE_DEVICES=0
DEBUG:tensorflow:+++++ 0: name=/device:CPU:0
DEBUG:tensorflow:+++++ 1: name=/device:XLA_GPU:0
DEBUG:tensorflow:+++++ gpu:0 CUDA_VISIBLE_DEVICES=0
INFO:tensorflow:Using config: {'_service': None, '_task_id': 0, '_num_worker_replicas': 1, '_num_ps_replicas': 0, '_keep_checkpoint_max': 2, '_global_id_in_cluster': 0, '_save_summary_steps': 100, '_master': '', '_task_type': 'worker', '_evaluation_master': '', '_tf_random_seed': None, '_save_checkpoints_steps': None, '_session_config': allow_soft_placement: true
graph_options {
  rewrite_options {
    meta_optimizer_iterations: ONE
  }
}
, '_eval_distribute': None, '_is_chief': True, '_device_fn': None, '_log_step_count_steps': 100, '_model_dir': '/data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model', '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fc7d56199b0>, '_experimental_distribute': None, '_protocol': None, '_keep_checkpoint_every_n_hours': 10000, '_save_checkpoints_secs': 600, '_train_distribute': None}
WARNING:tensorflow:Estimator's model_fn (<bound method SemanticClassifier.model_fn of <__main__.SemanticClassifier object at 0x7fc8942b2a58>>) includes params argument, but params are not passed to Estimator.
INFO:tensorflow:Loading training data: ['lv_train_imgs']
INFO:tensorflow:Normalizing input data: ['quantile']
INFO:tensorflow:
-----------------------------------------
-----
---- Training model...
-----
DEBUG:tensorflow:Train data: epoch size = 5120
DEBUG:tensorflow:Train data: batch size = 128
DEBUG:tensorflow:Train data: num_epochs = 100
DEBUG:tensorflow:Train data: patch_size: [64, 64, 7]
DEBUG:tensorflow:Train data: feature[0].shape: (5120, 64, 64, 7)
DEBUG:tensorflow:Train data: target[0].shape: (5120, 64, 64, 1)
INFO:tensorflow:Augmenting training data
INFO:tensorflow:Peformed 2592 flips
WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/estimator/inputs/queues/feeding_queue_runner.py:62: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.
Instructions for updating:
To construct input pipelines, use the `tf.data` module.
WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/estimator/inputs/queues/feeding_functions.py:500: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.
Instructions for updating:
To construct input pipelines, use the `tf.data` module.
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:Creating model...
DEBUG:tensorflow:Stacked data shape: (?, 64, 64, 7)
DEBUG:tensorflow:Input data shape: (64, 64, 7)
DEBUG:tensorflow:Rectified input data shape: (?, 64, 64, 7)
DEBUG:tensorflow:===== Creating U-Net model: U-Net
DEBUG:tensorflow:Training: True
DEBUG:tensorflow:Apply dropout: True
DEBUG:tensorflow:==== Convolution Layer 1
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:==== Convolution Layer 2
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:==== Convolution Layer 3
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:==== Middle Convolution Layer 
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 8, 8, 512)
DEBUG:tensorflow:Using dropout_rate=0.150000
DEBUG:tensorflow:feature shape: (?, 8, 8, 512)
DEBUG:tensorflow:Using dropout_rate=0.150000
DEBUG:tensorflow:===== Convolution Transpose Layer 3
DEBUG:tensorflow:upconv shape: (?, 16, 16, 256)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:===== Convolution Transpose Layer 2
DEBUG:tensorflow:upconv shape: (?, 32, 32, 128)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:===== Convolution Transpose Layer 1
DEBUG:tensorflow:upconv shape: (?, 64, 64, 64)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:===== Final Convolution Layer 1
DEBUG:tensorflow:feature shape: (?, 64, 64, 2)
DEBUG:tensorflow:=====
DEBUG:tensorflow:Model output layer shape = (?, 64, 64, 2)
INFO:tensorflow:Total number of trainable model parameters = 7,699,712
DEBUG:tensorflow:Labels shape = (?, 64, 64, 1)
INFO:tensorflow:Preparing loss function metric: CrossEntropy
INFO:tensorflow:Creating AdamOptimizer with learning-rate = 0.001, and learning-rate decay rate = 1.0
DEBUG:tensorflow:num_iterations_per_epoch = 40.000000
DEBUG:tensorflow:opt_decay_steps = 40.000000
DEBUG:tensorflow:opt_moving_average = 1.000000
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Create CheckpointSaverHook.
INFO:tensorflow:Graph was finalized.
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py:804: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.
Instructions for updating:
To construct input pipelines, use the `tf.data` module.
INFO:tensorflow:Saving checkpoints for 0 into /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt.
DEBUG:tensorflow:Training iteration 0 / 4000 (0.00%)
INFO:tensorflow:loss = 0.8303009, step = 0
DEBUG:tensorflow:Training iteration 10 / 4000 (0.25%)
DEBUG:tensorflow:Training iteration 20 / 4000 (0.50%)
DEBUG:tensorflow:Training iteration 30 / 4000 (0.75%)
DEBUG:tensorflow:Training iteration 40 / 4000 (1.00%)
INFO:tensorflow:Saving checkpoints for 40 into /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt.
INFO:tensorflow:Loss for final step: 0.1741052.
INFO:tensorflow:
-----------------------------------------
-----
---- Training model...
-----
DEBUG:tensorflow:Train data: epoch size = 5120
DEBUG:tensorflow:Train data: batch size = 128
DEBUG:tensorflow:Train data: num_epochs = 100
DEBUG:tensorflow:Train data: patch_size: [64, 64, 7]
DEBUG:tensorflow:Train data: feature[0].shape: (5120, 64, 64, 7)
DEBUG:tensorflow:Train data: target[0].shape: (5120, 64, 64, 1)
INFO:tensorflow:Augmenting training data
INFO:tensorflow:Peformed 2546 flips
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:Creating model...
DEBUG:tensorflow:Stacked data shape: (?, 64, 64, 7)
DEBUG:tensorflow:Input data shape: (64, 64, 7)
DEBUG:tensorflow:Rectified input data shape: (?, 64, 64, 7)
DEBUG:tensorflow:===== Creating U-Net model: U-Net
DEBUG:tensorflow:Training: True
DEBUG:tensorflow:Apply dropout: True
DEBUG:tensorflow:==== Convolution Layer 1
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:==== Convolution Layer 2
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:==== Convolution Layer 3
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:==== Middle Convolution Layer 
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 8, 8, 512)
DEBUG:tensorflow:Using dropout_rate=0.150000
DEBUG:tensorflow:feature shape: (?, 8, 8, 512)
DEBUG:tensorflow:Using dropout_rate=0.150000
DEBUG:tensorflow:===== Convolution Transpose Layer 3
DEBUG:tensorflow:upconv shape: (?, 16, 16, 256)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:===== Convolution Transpose Layer 2
DEBUG:tensorflow:upconv shape: (?, 32, 32, 128)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:===== Convolution Transpose Layer 1
DEBUG:tensorflow:upconv shape: (?, 64, 64, 64)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:===== Final Convolution Layer 1
DEBUG:tensorflow:feature shape: (?, 64, 64, 2)
DEBUG:tensorflow:=====
DEBUG:tensorflow:Model output layer shape = (?, 64, 64, 2)
INFO:tensorflow:Total number of trainable model parameters = 7,699,712
DEBUG:tensorflow:Labels shape = (?, 64, 64, 1)
INFO:tensorflow:Preparing loss function metric: CrossEntropy
INFO:tensorflow:Creating AdamOptimizer with learning-rate = 0.001, and learning-rate decay rate = 1.0
DEBUG:tensorflow:num_iterations_per_epoch = 40.000000
DEBUG:tensorflow:opt_decay_steps = 40.000000
DEBUG:tensorflow:opt_moving_average = 1.000000
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Create CheckpointSaverHook.
INFO:tensorflow:Graph was finalized.
INFO:tensorflow:Restoring parameters from /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt-40
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
INFO:tensorflow:Saving checkpoints for 40 into /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt.
DEBUG:tensorflow:Training iteration 40 / 4000 (1.00%)
INFO:tensorflow:loss = 0.1633922, step = 40
DEBUG:tensorflow:Training iteration 50 / 4000 (1.25%)
DEBUG:tensorflow:Training iteration 60 / 4000 (1.50%)
DEBUG:tensorflow:Training iteration 70 / 4000 (1.75%)
DEBUG:tensorflow:Training iteration 80 / 4000 (2.00%)
INFO:tensorflow:Saving checkpoints for 80 into /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt.
INFO:tensorflow:Loss for final step: 0.12342657.
INFO:tensorflow:
-----------------------------------------
-----
---- Training model...
-----
DEBUG:tensorflow:Train data: epoch size = 5120
DEBUG:tensorflow:Train data: batch size = 128
DEBUG:tensorflow:Train data: num_epochs = 100
DEBUG:tensorflow:Train data: patch_size: [64, 64, 7]
DEBUG:tensorflow:Train data: feature[0].shape: (5120, 64, 64, 7)
DEBUG:tensorflow:Train data: target[0].shape: (5120, 64, 64, 1)
INFO:tensorflow:Augmenting training data
INFO:tensorflow:Peformed 2582 flips
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:Creating model...
DEBUG:tensorflow:Stacked data shape: (?, 64, 64, 7)
DEBUG:tensorflow:Input data shape: (64, 64, 7)
DEBUG:tensorflow:Rectified input data shape: (?, 64, 64, 7)
DEBUG:tensorflow:===== Creating U-Net model: U-Net
DEBUG:tensorflow:Training: True
DEBUG:tensorflow:Apply dropout: True
DEBUG:tensorflow:==== Convolution Layer 1
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:==== Convolution Layer 2
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:==== Convolution Layer 3
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:==== Middle Convolution Layer 
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 8, 8, 512)
DEBUG:tensorflow:Using dropout_rate=0.150000
DEBUG:tensorflow:feature shape: (?, 8, 8, 512)
DEBUG:tensorflow:Using dropout_rate=0.150000
DEBUG:tensorflow:===== Convolution Transpose Layer 3
DEBUG:tensorflow:upconv shape: (?, 16, 16, 256)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:===== Convolution Transpose Layer 2
DEBUG:tensorflow:upconv shape: (?, 32, 32, 128)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:===== Convolution Transpose Layer 1
DEBUG:tensorflow:upconv shape: (?, 64, 64, 64)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:===== Final Convolution Layer 1
DEBUG:tensorflow:feature shape: (?, 64, 64, 2)
DEBUG:tensorflow:=====
DEBUG:tensorflow:Model output layer shape = (?, 64, 64, 2)
INFO:tensorflow:Total number of trainable model parameters = 7,699,712
DEBUG:tensorflow:Labels shape = (?, 64, 64, 1)
INFO:tensorflow:Preparing loss function metric: CrossEntropy
INFO:tensorflow:Creating AdamOptimizer with learning-rate = 0.001, and learning-rate decay rate = 1.0
DEBUG:tensorflow:num_iterations_per_epoch = 40.000000
DEBUG:tensorflow:opt_decay_steps = 40.000000
DEBUG:tensorflow:opt_moving_average = 1.000000
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Create CheckpointSaverHook.
INFO:tensorflow:Graph was finalized.
INFO:tensorflow:Restoring parameters from /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt-80
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
INFO:tensorflow:Saving checkpoints for 80 into /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt.
DEBUG:tensorflow:Training iteration 80 / 4000 (2.00%)
INFO:tensorflow:loss = 0.11440056, step = 80
DEBUG:tensorflow:Training iteration 90 / 4000 (2.25%)
DEBUG:tensorflow:Training iteration 100 / 4000 (2.50%)
DEBUG:tensorflow:Training iteration 110 / 4000 (2.75%)
DEBUG:tensorflow:Training iteration 120 / 4000 (3.00%)
INFO:tensorflow:Saving checkpoints for 120 into /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt.
INFO:tensorflow:Loss for final step: 0.089664355.
INFO:tensorflow:
-----------------------------------------
-----
---- Training model...
-----
DEBUG:tensorflow:Train data: epoch size = 5120
DEBUG:tensorflow:Train data: batch size = 128
DEBUG:tensorflow:Train data: num_epochs = 100
DEBUG:tensorflow:Train data: patch_size: [64, 64, 7]
DEBUG:tensorflow:Train data: feature[0].shape: (5120, 64, 64, 7)
DEBUG:tensorflow:Train data: target[0].shape: (5120, 64, 64, 1)
INFO:tensorflow:Augmenting training data
INFO:tensorflow:Peformed 2603 flips
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:Creating model...
DEBUG:tensorflow:Stacked data shape: (?, 64, 64, 7)
DEBUG:tensorflow:Input data shape: (64, 64, 7)
DEBUG:tensorflow:Rectified input data shape: (?, 64, 64, 7)
DEBUG:tensorflow:===== Creating U-Net model: U-Net
DEBUG:tensorflow:Training: True
DEBUG:tensorflow:Apply dropout: True
DEBUG:tensorflow:==== Convolution Layer 1
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:==== Convolution Layer 2
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:==== Convolution Layer 3
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:==== Middle Convolution Layer 
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 8, 8, 512)
DEBUG:tensorflow:Using dropout_rate=0.150000
DEBUG:tensorflow:feature shape: (?, 8, 8, 512)
DEBUG:tensorflow:Using dropout_rate=0.150000
DEBUG:tensorflow:===== Convolution Transpose Layer 3
DEBUG:tensorflow:upconv shape: (?, 16, 16, 256)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:===== Convolution Transpose Layer 2
DEBUG:tensorflow:upconv shape: (?, 32, 32, 128)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:===== Convolution Transpose Layer 1
DEBUG:tensorflow:upconv shape: (?, 64, 64, 64)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:===== Final Convolution Layer 1
DEBUG:tensorflow:feature shape: (?, 64, 64, 2)
DEBUG:tensorflow:=====
DEBUG:tensorflow:Model output layer shape = (?, 64, 64, 2)
INFO:tensorflow:Total number of trainable model parameters = 7,699,712
DEBUG:tensorflow:Labels shape = (?, 64, 64, 1)
INFO:tensorflow:Preparing loss function metric: CrossEntropy
INFO:tensorflow:Creating AdamOptimizer with learning-rate = 0.001, and learning-rate decay rate = 1.0
DEBUG:tensorflow:num_iterations_per_epoch = 40.000000
DEBUG:tensorflow:opt_decay_steps = 40.000000
DEBUG:tensorflow:opt_moving_average = 1.000000
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Create CheckpointSaverHook.
INFO:tensorflow:Graph was finalized.
INFO:tensorflow:Restoring parameters from /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt-120
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
INFO:tensorflow:Saving checkpoints for 120 into /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt.
DEBUG:tensorflow:Training iteration 120 / 4000 (3.00%)
INFO:tensorflow:loss = 0.11799171, step = 120
DEBUG:tensorflow:Training iteration 130 / 4000 (3.25%)
DEBUG:tensorflow:Training iteration 140 / 4000 (3.50%)
DEBUG:tensorflow:Training iteration 150 / 4000 (3.75%)
DEBUG:tensorflow:Training iteration 160 / 4000 (4.00%)
INFO:tensorflow:Saving checkpoints for 160 into /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt.
INFO:tensorflow:Loss for final step: 0.10941976.
INFO:tensorflow:
-----------------------------------------
-----
---- Training model...
-----
DEBUG:tensorflow:Train data: epoch size = 5120
DEBUG:tensorflow:Train data: batch size = 128
DEBUG:tensorflow:Train data: num_epochs = 100
DEBUG:tensorflow:Train data: patch_size: [64, 64, 7]
DEBUG:tensorflow:Train data: feature[0].shape: (5120, 64, 64, 7)
DEBUG:tensorflow:Train data: target[0].shape: (5120, 64, 64, 1)
INFO:tensorflow:Augmenting training data
INFO:tensorflow:Peformed 2539 flips
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:Creating model...
DEBUG:tensorflow:Stacked data shape: (?, 64, 64, 7)
DEBUG:tensorflow:Input data shape: (64, 64, 7)
DEBUG:tensorflow:Rectified input data shape: (?, 64, 64, 7)
DEBUG:tensorflow:===== Creating U-Net model: U-Net
DEBUG:tensorflow:Training: True
DEBUG:tensorflow:Apply dropout: True
DEBUG:tensorflow:==== Convolution Layer 1
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:==== Convolution Layer 2
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:==== Convolution Layer 3
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:==== Middle Convolution Layer 
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 8, 8, 512)
DEBUG:tensorflow:Using dropout_rate=0.150000
DEBUG:tensorflow:feature shape: (?, 8, 8, 512)
DEBUG:tensorflow:Using dropout_rate=0.150000
DEBUG:tensorflow:===== Convolution Transpose Layer 3
DEBUG:tensorflow:upconv shape: (?, 16, 16, 256)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:===== Convolution Transpose Layer 2
DEBUG:tensorflow:upconv shape: (?, 32, 32, 128)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:===== Convolution Transpose Layer 1
DEBUG:tensorflow:upconv shape: (?, 64, 64, 64)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:===== Final Convolution Layer 1
DEBUG:tensorflow:feature shape: (?, 64, 64, 2)
DEBUG:tensorflow:=====
DEBUG:tensorflow:Model output layer shape = (?, 64, 64, 2)
INFO:tensorflow:Total number of trainable model parameters = 7,699,712
DEBUG:tensorflow:Labels shape = (?, 64, 64, 1)
INFO:tensorflow:Preparing loss function metric: CrossEntropy
INFO:tensorflow:Creating AdamOptimizer with learning-rate = 0.001, and learning-rate decay rate = 1.0
DEBUG:tensorflow:num_iterations_per_epoch = 40.000000
DEBUG:tensorflow:opt_decay_steps = 40.000000
DEBUG:tensorflow:opt_moving_average = 1.000000
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Create CheckpointSaverHook.
INFO:tensorflow:Graph was finalized.
INFO:tensorflow:Restoring parameters from /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt-160
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
INFO:tensorflow:Saving checkpoints for 160 into /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt.
DEBUG:tensorflow:Training iteration 160 / 4000 (4.00%)
INFO:tensorflow:loss = 0.10087373, step = 160
DEBUG:tensorflow:Training iteration 170 / 4000 (4.25%)
DEBUG:tensorflow:Training iteration 180 / 4000 (4.50%)
DEBUG:tensorflow:Training iteration 190 / 4000 (4.75%)
DEBUG:tensorflow:Training iteration 200 / 4000 (5.00%)
INFO:tensorflow:Saving checkpoints for 200 into /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt.
INFO:tensorflow:Loss for final step: 0.10116285.
INFO:tensorflow:
-----------------------------------------
-----
---- Training model...
-----
DEBUG:tensorflow:Train data: epoch size = 5120
DEBUG:tensorflow:Train data: batch size = 128
DEBUG:tensorflow:Train data: num_epochs = 100
DEBUG:tensorflow:Train data: patch_size: [64, 64, 7]
DEBUG:tensorflow:Train data: feature[0].shape: (5120, 64, 64, 7)
DEBUG:tensorflow:Train data: target[0].shape: (5120, 64, 64, 1)
INFO:tensorflow:Augmenting training data
INFO:tensorflow:Peformed 2518 flips
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:Creating model...
DEBUG:tensorflow:Stacked data shape: (?, 64, 64, 7)
DEBUG:tensorflow:Input data shape: (64, 64, 7)
DEBUG:tensorflow:Rectified input data shape: (?, 64, 64, 7)
DEBUG:tensorflow:===== Creating U-Net model: U-Net
DEBUG:tensorflow:Training: True
DEBUG:tensorflow:Apply dropout: True
DEBUG:tensorflow:==== Convolution Layer 1
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:==== Convolution Layer 2
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:==== Convolution Layer 3
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:==== Middle Convolution Layer 
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 8, 8, 512)
DEBUG:tensorflow:Using dropout_rate=0.150000
DEBUG:tensorflow:feature shape: (?, 8, 8, 512)
DEBUG:tensorflow:Using dropout_rate=0.150000
DEBUG:tensorflow:===== Convolution Transpose Layer 3
DEBUG:tensorflow:upconv shape: (?, 16, 16, 256)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:===== Convolution Transpose Layer 2
DEBUG:tensorflow:upconv shape: (?, 32, 32, 128)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:===== Convolution Transpose Layer 1
DEBUG:tensorflow:upconv shape: (?, 64, 64, 64)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:===== Final Convolution Layer 1
DEBUG:tensorflow:feature shape: (?, 64, 64, 2)
DEBUG:tensorflow:=====
DEBUG:tensorflow:Model output layer shape = (?, 64, 64, 2)
INFO:tensorflow:Total number of trainable model parameters = 7,699,712
DEBUG:tensorflow:Labels shape = (?, 64, 64, 1)
INFO:tensorflow:Preparing loss function metric: CrossEntropy
INFO:tensorflow:Creating AdamOptimizer with learning-rate = 0.001, and learning-rate decay rate = 1.0
DEBUG:tensorflow:num_iterations_per_epoch = 40.000000
DEBUG:tensorflow:opt_decay_steps = 40.000000
DEBUG:tensorflow:opt_moving_average = 1.000000
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Create CheckpointSaverHook.
INFO:tensorflow:Graph was finalized.
INFO:tensorflow:Restoring parameters from /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt-200
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
INFO:tensorflow:Saving checkpoints for 200 into /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt.
DEBUG:tensorflow:Training iteration 200 / 4000 (5.00%)
INFO:tensorflow:loss = 0.08375309, step = 200
DEBUG:tensorflow:Training iteration 210 / 4000 (5.25%)
DEBUG:tensorflow:Training iteration 220 / 4000 (5.50%)
DEBUG:tensorflow:Training iteration 230 / 4000 (5.75%)
DEBUG:tensorflow:Training iteration 240 / 4000 (6.00%)
INFO:tensorflow:Saving checkpoints for 240 into /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt.
INFO:tensorflow:Loss for final step: 0.064289816.
INFO:tensorflow:
-----------------------------------------
-----
---- Training model...
-----
DEBUG:tensorflow:Train data: epoch size = 5120
DEBUG:tensorflow:Train data: batch size = 128
DEBUG:tensorflow:Train data: num_epochs = 100
DEBUG:tensorflow:Train data: patch_size: [64, 64, 7]
DEBUG:tensorflow:Train data: feature[0].shape: (5120, 64, 64, 7)
DEBUG:tensorflow:Train data: target[0].shape: (5120, 64, 64, 1)
INFO:tensorflow:Augmenting training data
INFO:tensorflow:Peformed 2556 flips
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:Creating model...
DEBUG:tensorflow:Stacked data shape: (?, 64, 64, 7)
DEBUG:tensorflow:Input data shape: (64, 64, 7)
DEBUG:tensorflow:Rectified input data shape: (?, 64, 64, 7)
DEBUG:tensorflow:===== Creating U-Net model: U-Net
DEBUG:tensorflow:Training: True
DEBUG:tensorflow:Apply dropout: True
DEBUG:tensorflow:==== Convolution Layer 1
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:==== Convolution Layer 2
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:==== Convolution Layer 3
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:==== Middle Convolution Layer 
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 8, 8, 512)
DEBUG:tensorflow:Using dropout_rate=0.150000
DEBUG:tensorflow:feature shape: (?, 8, 8, 512)
DEBUG:tensorflow:Using dropout_rate=0.150000
DEBUG:tensorflow:===== Convolution Transpose Layer 3
DEBUG:tensorflow:upconv shape: (?, 16, 16, 256)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:===== Convolution Transpose Layer 2
DEBUG:tensorflow:upconv shape: (?, 32, 32, 128)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:===== Convolution Transpose Layer 1
DEBUG:tensorflow:upconv shape: (?, 64, 64, 64)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:===== Final Convolution Layer 1
DEBUG:tensorflow:feature shape: (?, 64, 64, 2)
DEBUG:tensorflow:=====
DEBUG:tensorflow:Model output layer shape = (?, 64, 64, 2)
INFO:tensorflow:Total number of trainable model parameters = 7,699,712
DEBUG:tensorflow:Labels shape = (?, 64, 64, 1)
INFO:tensorflow:Preparing loss function metric: CrossEntropy
INFO:tensorflow:Creating AdamOptimizer with learning-rate = 0.001, and learning-rate decay rate = 1.0
DEBUG:tensorflow:num_iterations_per_epoch = 40.000000
DEBUG:tensorflow:opt_decay_steps = 40.000000
DEBUG:tensorflow:opt_moving_average = 1.000000
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Create CheckpointSaverHook.
INFO:tensorflow:Graph was finalized.
INFO:tensorflow:Restoring parameters from /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt-240
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
INFO:tensorflow:Saving checkpoints for 240 into /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt.
DEBUG:tensorflow:Training iteration 240 / 4000 (6.00%)
INFO:tensorflow:loss = 0.08349508, step = 240
DEBUG:tensorflow:Training iteration 250 / 4000 (6.25%)
DEBUG:tensorflow:Training iteration 260 / 4000 (6.50%)
DEBUG:tensorflow:Training iteration 270 / 4000 (6.75%)
DEBUG:tensorflow:Training iteration 280 / 4000 (7.00%)
INFO:tensorflow:Saving checkpoints for 280 into /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt.
INFO:tensorflow:Loss for final step: 0.09014732.
INFO:tensorflow:
-----------------------------------------
-----
---- Training model...
-----
DEBUG:tensorflow:Train data: epoch size = 5120
DEBUG:tensorflow:Train data: batch size = 128
DEBUG:tensorflow:Train data: num_epochs = 100
DEBUG:tensorflow:Train data: patch_size: [64, 64, 7]
DEBUG:tensorflow:Train data: feature[0].shape: (5120, 64, 64, 7)
DEBUG:tensorflow:Train data: target[0].shape: (5120, 64, 64, 1)
INFO:tensorflow:Augmenting training data
INFO:tensorflow:Peformed 2522 flips
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:Creating model...
DEBUG:tensorflow:Stacked data shape: (?, 64, 64, 7)
DEBUG:tensorflow:Input data shape: (64, 64, 7)
DEBUG:tensorflow:Rectified input data shape: (?, 64, 64, 7)
DEBUG:tensorflow:===== Creating U-Net model: U-Net
DEBUG:tensorflow:Training: True
DEBUG:tensorflow:Apply dropout: True
DEBUG:tensorflow:==== Convolution Layer 1
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:==== Convolution Layer 2
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:==== Convolution Layer 3
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:==== Middle Convolution Layer 
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 8, 8, 512)
DEBUG:tensorflow:Using dropout_rate=0.150000
DEBUG:tensorflow:feature shape: (?, 8, 8, 512)
DEBUG:tensorflow:Using dropout_rate=0.150000
DEBUG:tensorflow:===== Convolution Transpose Layer 3
DEBUG:tensorflow:upconv shape: (?, 16, 16, 256)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:===== Convolution Transpose Layer 2
DEBUG:tensorflow:upconv shape: (?, 32, 32, 128)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:===== Convolution Transpose Layer 1
DEBUG:tensorflow:upconv shape: (?, 64, 64, 64)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:===== Final Convolution Layer 1
DEBUG:tensorflow:feature shape: (?, 64, 64, 2)
DEBUG:tensorflow:=====
DEBUG:tensorflow:Model output layer shape = (?, 64, 64, 2)
INFO:tensorflow:Total number of trainable model parameters = 7,699,712
DEBUG:tensorflow:Labels shape = (?, 64, 64, 1)
INFO:tensorflow:Preparing loss function metric: CrossEntropy
INFO:tensorflow:Creating AdamOptimizer with learning-rate = 0.001, and learning-rate decay rate = 1.0
DEBUG:tensorflow:num_iterations_per_epoch = 40.000000
DEBUG:tensorflow:opt_decay_steps = 40.000000
DEBUG:tensorflow:opt_moving_average = 1.000000
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Create CheckpointSaverHook.
INFO:tensorflow:Graph was finalized.
INFO:tensorflow:Restoring parameters from /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt-280
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
INFO:tensorflow:Saving checkpoints for 280 into /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt.
DEBUG:tensorflow:Training iteration 280 / 4000 (7.00%)
INFO:tensorflow:loss = 0.0794288, step = 280
DEBUG:tensorflow:Training iteration 290 / 4000 (7.25%)
DEBUG:tensorflow:Training iteration 300 / 4000 (7.50%)
DEBUG:tensorflow:Training iteration 310 / 4000 (7.75%)
DEBUG:tensorflow:Training iteration 320 / 4000 (8.00%)
INFO:tensorflow:Saving checkpoints for 320 into /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt.
INFO:tensorflow:Loss for final step: 0.09197795.
INFO:tensorflow:
-----------------------------------------
-----
---- Training model...
-----
DEBUG:tensorflow:Train data: epoch size = 5120
DEBUG:tensorflow:Train data: batch size = 128
DEBUG:tensorflow:Train data: num_epochs = 100
DEBUG:tensorflow:Train data: patch_size: [64, 64, 7]
DEBUG:tensorflow:Train data: feature[0].shape: (5120, 64, 64, 7)
DEBUG:tensorflow:Train data: target[0].shape: (5120, 64, 64, 1)
INFO:tensorflow:Augmenting training data
INFO:tensorflow:Peformed 2586 flips
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:Creating model...
DEBUG:tensorflow:Stacked data shape: (?, 64, 64, 7)
DEBUG:tensorflow:Input data shape: (64, 64, 7)
DEBUG:tensorflow:Rectified input data shape: (?, 64, 64, 7)
DEBUG:tensorflow:===== Creating U-Net model: U-Net
DEBUG:tensorflow:Training: True
DEBUG:tensorflow:Apply dropout: True
DEBUG:tensorflow:==== Convolution Layer 1
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:==== Convolution Layer 2
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:==== Convolution Layer 3
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:==== Middle Convolution Layer 
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 8, 8, 512)
DEBUG:tensorflow:Using dropout_rate=0.150000
DEBUG:tensorflow:feature shape: (?, 8, 8, 512)
DEBUG:tensorflow:Using dropout_rate=0.150000
DEBUG:tensorflow:===== Convolution Transpose Layer 3
DEBUG:tensorflow:upconv shape: (?, 16, 16, 256)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:===== Convolution Transpose Layer 2
DEBUG:tensorflow:upconv shape: (?, 32, 32, 128)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:===== Convolution Transpose Layer 1
DEBUG:tensorflow:upconv shape: (?, 64, 64, 64)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:===== Final Convolution Layer 1
DEBUG:tensorflow:feature shape: (?, 64, 64, 2)
DEBUG:tensorflow:=====
DEBUG:tensorflow:Model output layer shape = (?, 64, 64, 2)
INFO:tensorflow:Total number of trainable model parameters = 7,699,712
DEBUG:tensorflow:Labels shape = (?, 64, 64, 1)
INFO:tensorflow:Preparing loss function metric: CrossEntropy
INFO:tensorflow:Creating AdamOptimizer with learning-rate = 0.001, and learning-rate decay rate = 1.0
DEBUG:tensorflow:num_iterations_per_epoch = 40.000000
DEBUG:tensorflow:opt_decay_steps = 40.000000
DEBUG:tensorflow:opt_moving_average = 1.000000
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Create CheckpointSaverHook.
INFO:tensorflow:Graph was finalized.
INFO:tensorflow:Restoring parameters from /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt-320
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
INFO:tensorflow:Saving checkpoints for 320 into /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt.
DEBUG:tensorflow:Training iteration 320 / 4000 (8.00%)
INFO:tensorflow:loss = 0.07529691, step = 320
DEBUG:tensorflow:Training iteration 330 / 4000 (8.25%)
DEBUG:tensorflow:Training iteration 340 / 4000 (8.50%)
DEBUG:tensorflow:Training iteration 350 / 4000 (8.75%)
DEBUG:tensorflow:Training iteration 360 / 4000 (9.00%)
INFO:tensorflow:Saving checkpoints for 360 into /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt.
INFO:tensorflow:Loss for final step: 0.081013724.
INFO:tensorflow:
-----------------------------------------
-----
---- Training model...
-----
DEBUG:tensorflow:Train data: epoch size = 5120
DEBUG:tensorflow:Train data: batch size = 128
DEBUG:tensorflow:Train data: num_epochs = 100
DEBUG:tensorflow:Train data: patch_size: [64, 64, 7]
DEBUG:tensorflow:Train data: feature[0].shape: (5120, 64, 64, 7)
DEBUG:tensorflow:Train data: target[0].shape: (5120, 64, 64, 1)
INFO:tensorflow:Augmenting training data
INFO:tensorflow:Peformed 2618 flips
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:Creating model...
DEBUG:tensorflow:Stacked data shape: (?, 64, 64, 7)
DEBUG:tensorflow:Input data shape: (64, 64, 7)
DEBUG:tensorflow:Rectified input data shape: (?, 64, 64, 7)
DEBUG:tensorflow:===== Creating U-Net model: U-Net
DEBUG:tensorflow:Training: True
DEBUG:tensorflow:Apply dropout: True
DEBUG:tensorflow:==== Convolution Layer 1
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:==== Convolution Layer 2
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:==== Convolution Layer 3
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:==== Middle Convolution Layer 
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 8, 8, 512)
DEBUG:tensorflow:Using dropout_rate=0.150000
DEBUG:tensorflow:feature shape: (?, 8, 8, 512)
DEBUG:tensorflow:Using dropout_rate=0.150000
DEBUG:tensorflow:===== Convolution Transpose Layer 3
DEBUG:tensorflow:upconv shape: (?, 16, 16, 256)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:===== Convolution Transpose Layer 2
DEBUG:tensorflow:upconv shape: (?, 32, 32, 128)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:===== Convolution Transpose Layer 1
DEBUG:tensorflow:upconv shape: (?, 64, 64, 64)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:===== Final Convolution Layer 1
DEBUG:tensorflow:feature shape: (?, 64, 64, 2)
DEBUG:tensorflow:=====
DEBUG:tensorflow:Model output layer shape = (?, 64, 64, 2)
INFO:tensorflow:Total number of trainable model parameters = 7,699,712
DEBUG:tensorflow:Labels shape = (?, 64, 64, 1)
INFO:tensorflow:Preparing loss function metric: CrossEntropy
INFO:tensorflow:Creating AdamOptimizer with learning-rate = 0.001, and learning-rate decay rate = 1.0
DEBUG:tensorflow:num_iterations_per_epoch = 40.000000
DEBUG:tensorflow:opt_decay_steps = 40.000000
DEBUG:tensorflow:opt_moving_average = 1.000000
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Create CheckpointSaverHook.
INFO:tensorflow:Graph was finalized.
INFO:tensorflow:Restoring parameters from /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt-360
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
INFO:tensorflow:Saving checkpoints for 360 into /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt.
DEBUG:tensorflow:Training iteration 360 / 4000 (9.00%)
INFO:tensorflow:loss = 0.08192676, step = 360
DEBUG:tensorflow:Training iteration 370 / 4000 (9.25%)
DEBUG:tensorflow:Training iteration 380 / 4000 (9.50%)
DEBUG:tensorflow:Training iteration 390 / 4000 (9.75%)
DEBUG:tensorflow:Training iteration 400 / 4000 (10.00%)
INFO:tensorflow:Saving checkpoints for 400 into /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt.
INFO:tensorflow:Loss for final step: 0.054921158.
INFO:tensorflow:
-----------------------------------------
-----
---- Training model...
-----
DEBUG:tensorflow:Train data: epoch size = 5120
DEBUG:tensorflow:Train data: batch size = 128
DEBUG:tensorflow:Train data: num_epochs = 100
DEBUG:tensorflow:Train data: patch_size: [64, 64, 7]
DEBUG:tensorflow:Train data: feature[0].shape: (5120, 64, 64, 7)
DEBUG:tensorflow:Train data: target[0].shape: (5120, 64, 64, 1)
INFO:tensorflow:Augmenting training data
INFO:tensorflow:Peformed 2577 flips
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:Creating model...
DEBUG:tensorflow:Stacked data shape: (?, 64, 64, 7)
DEBUG:tensorflow:Input data shape: (64, 64, 7)
DEBUG:tensorflow:Rectified input data shape: (?, 64, 64, 7)
DEBUG:tensorflow:===== Creating U-Net model: U-Net
DEBUG:tensorflow:Training: True
DEBUG:tensorflow:Apply dropout: True
DEBUG:tensorflow:==== Convolution Layer 1
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:==== Convolution Layer 2
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:==== Convolution Layer 3
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:==== Middle Convolution Layer 
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 8, 8, 512)
DEBUG:tensorflow:Using dropout_rate=0.150000
DEBUG:tensorflow:feature shape: (?, 8, 8, 512)
DEBUG:tensorflow:Using dropout_rate=0.150000
DEBUG:tensorflow:===== Convolution Transpose Layer 3
DEBUG:tensorflow:upconv shape: (?, 16, 16, 256)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:===== Convolution Transpose Layer 2
DEBUG:tensorflow:upconv shape: (?, 32, 32, 128)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:===== Convolution Transpose Layer 1
DEBUG:tensorflow:upconv shape: (?, 64, 64, 64)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:===== Final Convolution Layer 1
DEBUG:tensorflow:feature shape: (?, 64, 64, 2)
DEBUG:tensorflow:=====
DEBUG:tensorflow:Model output layer shape = (?, 64, 64, 2)
INFO:tensorflow:Total number of trainable model parameters = 7,699,712
DEBUG:tensorflow:Labels shape = (?, 64, 64, 1)
INFO:tensorflow:Preparing loss function metric: CrossEntropy
INFO:tensorflow:Creating AdamOptimizer with learning-rate = 0.001, and learning-rate decay rate = 1.0
DEBUG:tensorflow:num_iterations_per_epoch = 40.000000
DEBUG:tensorflow:opt_decay_steps = 40.000000
DEBUG:tensorflow:opt_moving_average = 1.000000
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Create CheckpointSaverHook.
INFO:tensorflow:Graph was finalized.
INFO:tensorflow:Restoring parameters from /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt-400
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
INFO:tensorflow:Saving checkpoints for 400 into /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt.
DEBUG:tensorflow:Training iteration 400 / 4000 (10.00%)
INFO:tensorflow:loss = 0.074668735, step = 400
DEBUG:tensorflow:Training iteration 410 / 4000 (10.25%)
DEBUG:tensorflow:Training iteration 420 / 4000 (10.50%)
DEBUG:tensorflow:Training iteration 430 / 4000 (10.75%)
DEBUG:tensorflow:Training iteration 440 / 4000 (11.00%)
INFO:tensorflow:Saving checkpoints for 440 into /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt.
INFO:tensorflow:Loss for final step: 0.064260915.
INFO:tensorflow:
-----------------------------------------
-----
---- Training model...
-----
DEBUG:tensorflow:Train data: epoch size = 5120
DEBUG:tensorflow:Train data: batch size = 128
DEBUG:tensorflow:Train data: num_epochs = 100
DEBUG:tensorflow:Train data: patch_size: [64, 64, 7]
DEBUG:tensorflow:Train data: feature[0].shape: (5120, 64, 64, 7)
DEBUG:tensorflow:Train data: target[0].shape: (5120, 64, 64, 1)
INFO:tensorflow:Augmenting training data
INFO:tensorflow:Peformed 2589 flips
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:Creating model...
DEBUG:tensorflow:Stacked data shape: (?, 64, 64, 7)
DEBUG:tensorflow:Input data shape: (64, 64, 7)
DEBUG:tensorflow:Rectified input data shape: (?, 64, 64, 7)
DEBUG:tensorflow:===== Creating U-Net model: U-Net
DEBUG:tensorflow:Training: True
DEBUG:tensorflow:Apply dropout: True
DEBUG:tensorflow:==== Convolution Layer 1
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:==== Convolution Layer 2
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:==== Convolution Layer 3
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:==== Middle Convolution Layer 
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 8, 8, 512)
DEBUG:tensorflow:Using dropout_rate=0.150000
DEBUG:tensorflow:feature shape: (?, 8, 8, 512)
DEBUG:tensorflow:Using dropout_rate=0.150000
DEBUG:tensorflow:===== Convolution Transpose Layer 3
DEBUG:tensorflow:upconv shape: (?, 16, 16, 256)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:===== Convolution Transpose Layer 2
DEBUG:tensorflow:upconv shape: (?, 32, 32, 128)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:===== Convolution Transpose Layer 1
DEBUG:tensorflow:upconv shape: (?, 64, 64, 64)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:===== Final Convolution Layer 1
DEBUG:tensorflow:feature shape: (?, 64, 64, 2)
DEBUG:tensorflow:=====
DEBUG:tensorflow:Model output layer shape = (?, 64, 64, 2)
INFO:tensorflow:Total number of trainable model parameters = 7,699,712
DEBUG:tensorflow:Labels shape = (?, 64, 64, 1)
INFO:tensorflow:Preparing loss function metric: CrossEntropy
INFO:tensorflow:Creating AdamOptimizer with learning-rate = 0.001, and learning-rate decay rate = 1.0
DEBUG:tensorflow:num_iterations_per_epoch = 40.000000
DEBUG:tensorflow:opt_decay_steps = 40.000000
DEBUG:tensorflow:opt_moving_average = 1.000000
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Create CheckpointSaverHook.
INFO:tensorflow:Graph was finalized.
INFO:tensorflow:Restoring parameters from /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt-440
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
INFO:tensorflow:Saving checkpoints for 440 into /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt.
DEBUG:tensorflow:Training iteration 440 / 4000 (11.00%)
INFO:tensorflow:loss = 0.053986408, step = 440
DEBUG:tensorflow:Training iteration 450 / 4000 (11.25%)
DEBUG:tensorflow:Training iteration 460 / 4000 (11.50%)
DEBUG:tensorflow:Training iteration 470 / 4000 (11.75%)
DEBUG:tensorflow:Training iteration 480 / 4000 (12.00%)
INFO:tensorflow:Saving checkpoints for 480 into /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt.
INFO:tensorflow:Loss for final step: 0.07925849.
INFO:tensorflow:
-----------------------------------------
-----
---- Training model...
-----
DEBUG:tensorflow:Train data: epoch size = 5120
DEBUG:tensorflow:Train data: batch size = 128
DEBUG:tensorflow:Train data: num_epochs = 100
DEBUG:tensorflow:Train data: patch_size: [64, 64, 7]
DEBUG:tensorflow:Train data: feature[0].shape: (5120, 64, 64, 7)
DEBUG:tensorflow:Train data: target[0].shape: (5120, 64, 64, 1)
INFO:tensorflow:Augmenting training data
INFO:tensorflow:Peformed 2559 flips
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:Creating model...
DEBUG:tensorflow:Stacked data shape: (?, 64, 64, 7)
DEBUG:tensorflow:Input data shape: (64, 64, 7)
DEBUG:tensorflow:Rectified input data shape: (?, 64, 64, 7)
DEBUG:tensorflow:===== Creating U-Net model: U-Net
DEBUG:tensorflow:Training: True
DEBUG:tensorflow:Apply dropout: True
DEBUG:tensorflow:==== Convolution Layer 1
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:==== Convolution Layer 2
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:==== Convolution Layer 3
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:==== Middle Convolution Layer 
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 8, 8, 512)
DEBUG:tensorflow:Using dropout_rate=0.150000
DEBUG:tensorflow:feature shape: (?, 8, 8, 512)
DEBUG:tensorflow:Using dropout_rate=0.150000
DEBUG:tensorflow:===== Convolution Transpose Layer 3
DEBUG:tensorflow:upconv shape: (?, 16, 16, 256)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:===== Convolution Transpose Layer 2
DEBUG:tensorflow:upconv shape: (?, 32, 32, 128)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:===== Convolution Transpose Layer 1
DEBUG:tensorflow:upconv shape: (?, 64, 64, 64)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:===== Final Convolution Layer 1
DEBUG:tensorflow:feature shape: (?, 64, 64, 2)
DEBUG:tensorflow:=====
DEBUG:tensorflow:Model output layer shape = (?, 64, 64, 2)
INFO:tensorflow:Total number of trainable model parameters = 7,699,712
DEBUG:tensorflow:Labels shape = (?, 64, 64, 1)
INFO:tensorflow:Preparing loss function metric: CrossEntropy
INFO:tensorflow:Creating AdamOptimizer with learning-rate = 0.001, and learning-rate decay rate = 1.0
DEBUG:tensorflow:num_iterations_per_epoch = 40.000000
DEBUG:tensorflow:opt_decay_steps = 40.000000
DEBUG:tensorflow:opt_moving_average = 1.000000
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Create CheckpointSaverHook.
INFO:tensorflow:Graph was finalized.
INFO:tensorflow:Restoring parameters from /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt-480
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
INFO:tensorflow:Saving checkpoints for 480 into /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt.
DEBUG:tensorflow:Training iteration 480 / 4000 (12.00%)
INFO:tensorflow:loss = 0.08114762, step = 480
DEBUG:tensorflow:Training iteration 490 / 4000 (12.25%)
DEBUG:tensorflow:Training iteration 500 / 4000 (12.50%)
DEBUG:tensorflow:Training iteration 510 / 4000 (12.75%)
DEBUG:tensorflow:Training iteration 520 / 4000 (13.00%)
INFO:tensorflow:Saving checkpoints for 520 into /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt.
INFO:tensorflow:Loss for final step: 0.055390455.
INFO:tensorflow:
-----------------------------------------
-----
---- Training model...
-----
DEBUG:tensorflow:Train data: epoch size = 5120
DEBUG:tensorflow:Train data: batch size = 128
DEBUG:tensorflow:Train data: num_epochs = 100
DEBUG:tensorflow:Train data: patch_size: [64, 64, 7]
DEBUG:tensorflow:Train data: feature[0].shape: (5120, 64, 64, 7)
DEBUG:tensorflow:Train data: target[0].shape: (5120, 64, 64, 1)
INFO:tensorflow:Augmenting training data
INFO:tensorflow:Peformed 2563 flips
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:Creating model...
DEBUG:tensorflow:Stacked data shape: (?, 64, 64, 7)
DEBUG:tensorflow:Input data shape: (64, 64, 7)
DEBUG:tensorflow:Rectified input data shape: (?, 64, 64, 7)
DEBUG:tensorflow:===== Creating U-Net model: U-Net
DEBUG:tensorflow:Training: True
DEBUG:tensorflow:Apply dropout: True
DEBUG:tensorflow:==== Convolution Layer 1
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:==== Convolution Layer 2
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:==== Convolution Layer 3
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:==== Middle Convolution Layer 
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 8, 8, 512)
DEBUG:tensorflow:Using dropout_rate=0.150000
DEBUG:tensorflow:feature shape: (?, 8, 8, 512)
DEBUG:tensorflow:Using dropout_rate=0.150000
DEBUG:tensorflow:===== Convolution Transpose Layer 3
DEBUG:tensorflow:upconv shape: (?, 16, 16, 256)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:===== Convolution Transpose Layer 2
DEBUG:tensorflow:upconv shape: (?, 32, 32, 128)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:===== Convolution Transpose Layer 1
DEBUG:tensorflow:upconv shape: (?, 64, 64, 64)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:===== Final Convolution Layer 1
DEBUG:tensorflow:feature shape: (?, 64, 64, 2)
DEBUG:tensorflow:=====
DEBUG:tensorflow:Model output layer shape = (?, 64, 64, 2)
INFO:tensorflow:Total number of trainable model parameters = 7,699,712
DEBUG:tensorflow:Labels shape = (?, 64, 64, 1)
INFO:tensorflow:Preparing loss function metric: CrossEntropy
INFO:tensorflow:Creating AdamOptimizer with learning-rate = 0.001, and learning-rate decay rate = 1.0
DEBUG:tensorflow:num_iterations_per_epoch = 40.000000
DEBUG:tensorflow:opt_decay_steps = 40.000000
DEBUG:tensorflow:opt_moving_average = 1.000000
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Create CheckpointSaverHook.
INFO:tensorflow:Graph was finalized.
INFO:tensorflow:Restoring parameters from /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt-520
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
INFO:tensorflow:Saving checkpoints for 520 into /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt.
DEBUG:tensorflow:Training iteration 520 / 4000 (13.00%)
INFO:tensorflow:loss = 0.0727288, step = 520
DEBUG:tensorflow:Training iteration 530 / 4000 (13.25%)
DEBUG:tensorflow:Training iteration 540 / 4000 (13.50%)
DEBUG:tensorflow:Training iteration 550 / 4000 (13.75%)
DEBUG:tensorflow:Training iteration 560 / 4000 (14.00%)
INFO:tensorflow:Saving checkpoints for 560 into /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt.
INFO:tensorflow:Loss for final step: 0.053000785.
INFO:tensorflow:
-----------------------------------------
-----
---- Training model...
-----
DEBUG:tensorflow:Train data: epoch size = 5120
DEBUG:tensorflow:Train data: batch size = 128
DEBUG:tensorflow:Train data: num_epochs = 100
DEBUG:tensorflow:Train data: patch_size: [64, 64, 7]
DEBUG:tensorflow:Train data: feature[0].shape: (5120, 64, 64, 7)
DEBUG:tensorflow:Train data: target[0].shape: (5120, 64, 64, 1)
INFO:tensorflow:Augmenting training data
INFO:tensorflow:Peformed 2619 flips
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:Creating model...
DEBUG:tensorflow:Stacked data shape: (?, 64, 64, 7)
DEBUG:tensorflow:Input data shape: (64, 64, 7)
DEBUG:tensorflow:Rectified input data shape: (?, 64, 64, 7)
DEBUG:tensorflow:===== Creating U-Net model: U-Net
DEBUG:tensorflow:Training: True
DEBUG:tensorflow:Apply dropout: True
DEBUG:tensorflow:==== Convolution Layer 1
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:==== Convolution Layer 2
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:==== Convolution Layer 3
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:==== Middle Convolution Layer 
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 8, 8, 512)
DEBUG:tensorflow:Using dropout_rate=0.150000
DEBUG:tensorflow:feature shape: (?, 8, 8, 512)
DEBUG:tensorflow:Using dropout_rate=0.150000
DEBUG:tensorflow:===== Convolution Transpose Layer 3
DEBUG:tensorflow:upconv shape: (?, 16, 16, 256)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:===== Convolution Transpose Layer 2
DEBUG:tensorflow:upconv shape: (?, 32, 32, 128)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:===== Convolution Transpose Layer 1
DEBUG:tensorflow:upconv shape: (?, 64, 64, 64)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:===== Final Convolution Layer 1
DEBUG:tensorflow:feature shape: (?, 64, 64, 2)
DEBUG:tensorflow:=====
DEBUG:tensorflow:Model output layer shape = (?, 64, 64, 2)
INFO:tensorflow:Total number of trainable model parameters = 7,699,712
DEBUG:tensorflow:Labels shape = (?, 64, 64, 1)
INFO:tensorflow:Preparing loss function metric: CrossEntropy
INFO:tensorflow:Creating AdamOptimizer with learning-rate = 0.001, and learning-rate decay rate = 1.0
DEBUG:tensorflow:num_iterations_per_epoch = 40.000000
DEBUG:tensorflow:opt_decay_steps = 40.000000
DEBUG:tensorflow:opt_moving_average = 1.000000
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Create CheckpointSaverHook.
INFO:tensorflow:Graph was finalized.
INFO:tensorflow:Restoring parameters from /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt-560
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
INFO:tensorflow:Saving checkpoints for 560 into /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt.
DEBUG:tensorflow:Training iteration 560 / 4000 (14.00%)
INFO:tensorflow:loss = 0.06677412, step = 560
DEBUG:tensorflow:Training iteration 570 / 4000 (14.25%)
DEBUG:tensorflow:Training iteration 580 / 4000 (14.50%)
DEBUG:tensorflow:Training iteration 590 / 4000 (14.75%)
DEBUG:tensorflow:Training iteration 600 / 4000 (15.00%)
INFO:tensorflow:Saving checkpoints for 600 into /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt.
INFO:tensorflow:Loss for final step: 0.07198237.
INFO:tensorflow:
-----------------------------------------
-----
---- Training model...
-----
DEBUG:tensorflow:Train data: epoch size = 5120
DEBUG:tensorflow:Train data: batch size = 128
DEBUG:tensorflow:Train data: num_epochs = 100
DEBUG:tensorflow:Train data: patch_size: [64, 64, 7]
DEBUG:tensorflow:Train data: feature[0].shape: (5120, 64, 64, 7)
DEBUG:tensorflow:Train data: target[0].shape: (5120, 64, 64, 1)
INFO:tensorflow:Augmenting training data
INFO:tensorflow:Peformed 2616 flips
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:Creating model...
DEBUG:tensorflow:Stacked data shape: (?, 64, 64, 7)
DEBUG:tensorflow:Input data shape: (64, 64, 7)
DEBUG:tensorflow:Rectified input data shape: (?, 64, 64, 7)
DEBUG:tensorflow:===== Creating U-Net model: U-Net
DEBUG:tensorflow:Training: True
DEBUG:tensorflow:Apply dropout: True
DEBUG:tensorflow:==== Convolution Layer 1
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:==== Convolution Layer 2
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:==== Convolution Layer 3
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:==== Middle Convolution Layer 
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 8, 8, 512)
DEBUG:tensorflow:Using dropout_rate=0.150000
DEBUG:tensorflow:feature shape: (?, 8, 8, 512)
DEBUG:tensorflow:Using dropout_rate=0.150000
DEBUG:tensorflow:===== Convolution Transpose Layer 3
DEBUG:tensorflow:upconv shape: (?, 16, 16, 256)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:===== Convolution Transpose Layer 2
DEBUG:tensorflow:upconv shape: (?, 32, 32, 128)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:===== Convolution Transpose Layer 1
DEBUG:tensorflow:upconv shape: (?, 64, 64, 64)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:===== Final Convolution Layer 1
DEBUG:tensorflow:feature shape: (?, 64, 64, 2)
DEBUG:tensorflow:=====
DEBUG:tensorflow:Model output layer shape = (?, 64, 64, 2)
INFO:tensorflow:Total number of trainable model parameters = 7,699,712
DEBUG:tensorflow:Labels shape = (?, 64, 64, 1)
INFO:tensorflow:Preparing loss function metric: CrossEntropy
INFO:tensorflow:Creating AdamOptimizer with learning-rate = 0.001, and learning-rate decay rate = 1.0
DEBUG:tensorflow:num_iterations_per_epoch = 40.000000
DEBUG:tensorflow:opt_decay_steps = 40.000000
DEBUG:tensorflow:opt_moving_average = 1.000000
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Create CheckpointSaverHook.
INFO:tensorflow:Graph was finalized.
INFO:tensorflow:Restoring parameters from /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt-600
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
INFO:tensorflow:Saving checkpoints for 600 into /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt.
DEBUG:tensorflow:Training iteration 600 / 4000 (15.00%)
INFO:tensorflow:loss = 0.07943529, step = 600
DEBUG:tensorflow:Training iteration 610 / 4000 (15.25%)
DEBUG:tensorflow:Training iteration 620 / 4000 (15.50%)
DEBUG:tensorflow:Training iteration 630 / 4000 (15.75%)
DEBUG:tensorflow:Training iteration 640 / 4000 (16.00%)
INFO:tensorflow:Saving checkpoints for 640 into /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt.
INFO:tensorflow:Loss for final step: 0.05339289.
INFO:tensorflow:
-----------------------------------------
-----
---- Training model...
-----
DEBUG:tensorflow:Train data: epoch size = 5120
DEBUG:tensorflow:Train data: batch size = 128
DEBUG:tensorflow:Train data: num_epochs = 100
DEBUG:tensorflow:Train data: patch_size: [64, 64, 7]
DEBUG:tensorflow:Train data: feature[0].shape: (5120, 64, 64, 7)
DEBUG:tensorflow:Train data: target[0].shape: (5120, 64, 64, 1)
INFO:tensorflow:Augmenting training data
INFO:tensorflow:Peformed 2591 flips
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:Creating model...
DEBUG:tensorflow:Stacked data shape: (?, 64, 64, 7)
DEBUG:tensorflow:Input data shape: (64, 64, 7)
DEBUG:tensorflow:Rectified input data shape: (?, 64, 64, 7)
DEBUG:tensorflow:===== Creating U-Net model: U-Net
DEBUG:tensorflow:Training: True
DEBUG:tensorflow:Apply dropout: True
DEBUG:tensorflow:==== Convolution Layer 1
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:==== Convolution Layer 2
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:==== Convolution Layer 3
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:==== Middle Convolution Layer 
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 8, 8, 512)
DEBUG:tensorflow:Using dropout_rate=0.150000
DEBUG:tensorflow:feature shape: (?, 8, 8, 512)
DEBUG:tensorflow:Using dropout_rate=0.150000
DEBUG:tensorflow:===== Convolution Transpose Layer 3
DEBUG:tensorflow:upconv shape: (?, 16, 16, 256)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:===== Convolution Transpose Layer 2
DEBUG:tensorflow:upconv shape: (?, 32, 32, 128)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:===== Convolution Transpose Layer 1
DEBUG:tensorflow:upconv shape: (?, 64, 64, 64)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:===== Final Convolution Layer 1
DEBUG:tensorflow:feature shape: (?, 64, 64, 2)
DEBUG:tensorflow:=====
DEBUG:tensorflow:Model output layer shape = (?, 64, 64, 2)
INFO:tensorflow:Total number of trainable model parameters = 7,699,712
DEBUG:tensorflow:Labels shape = (?, 64, 64, 1)
INFO:tensorflow:Preparing loss function metric: CrossEntropy
INFO:tensorflow:Creating AdamOptimizer with learning-rate = 0.001, and learning-rate decay rate = 1.0
DEBUG:tensorflow:num_iterations_per_epoch = 40.000000
DEBUG:tensorflow:opt_decay_steps = 40.000000
DEBUG:tensorflow:opt_moving_average = 1.000000
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Create CheckpointSaverHook.
INFO:tensorflow:Graph was finalized.
INFO:tensorflow:Restoring parameters from /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt-640
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
INFO:tensorflow:Saving checkpoints for 640 into /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt.
DEBUG:tensorflow:Training iteration 640 / 4000 (16.00%)
INFO:tensorflow:loss = 0.07464771, step = 640
DEBUG:tensorflow:Training iteration 650 / 4000 (16.25%)
DEBUG:tensorflow:Training iteration 660 / 4000 (16.50%)
DEBUG:tensorflow:Training iteration 670 / 4000 (16.75%)
DEBUG:tensorflow:Training iteration 680 / 4000 (17.00%)
INFO:tensorflow:Saving checkpoints for 680 into /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt.
INFO:tensorflow:Loss for final step: 0.063002944.
INFO:tensorflow:
-----------------------------------------
-----
---- Training model...
-----
DEBUG:tensorflow:Train data: epoch size = 5120
DEBUG:tensorflow:Train data: batch size = 128
DEBUG:tensorflow:Train data: num_epochs = 100
DEBUG:tensorflow:Train data: patch_size: [64, 64, 7]
DEBUG:tensorflow:Train data: feature[0].shape: (5120, 64, 64, 7)
DEBUG:tensorflow:Train data: target[0].shape: (5120, 64, 64, 1)
INFO:tensorflow:Augmenting training data
INFO:tensorflow:Peformed 2566 flips
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:Creating model...
DEBUG:tensorflow:Stacked data shape: (?, 64, 64, 7)
DEBUG:tensorflow:Input data shape: (64, 64, 7)
DEBUG:tensorflow:Rectified input data shape: (?, 64, 64, 7)
DEBUG:tensorflow:===== Creating U-Net model: U-Net
DEBUG:tensorflow:Training: True
DEBUG:tensorflow:Apply dropout: True
DEBUG:tensorflow:==== Convolution Layer 1
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:==== Convolution Layer 2
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:==== Convolution Layer 3
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:==== Middle Convolution Layer 
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 8, 8, 512)
DEBUG:tensorflow:Using dropout_rate=0.150000
DEBUG:tensorflow:feature shape: (?, 8, 8, 512)
DEBUG:tensorflow:Using dropout_rate=0.150000
DEBUG:tensorflow:===== Convolution Transpose Layer 3
DEBUG:tensorflow:upconv shape: (?, 16, 16, 256)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:===== Convolution Transpose Layer 2
DEBUG:tensorflow:upconv shape: (?, 32, 32, 128)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:===== Convolution Transpose Layer 1
DEBUG:tensorflow:upconv shape: (?, 64, 64, 64)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:===== Final Convolution Layer 1
DEBUG:tensorflow:feature shape: (?, 64, 64, 2)
DEBUG:tensorflow:=====
DEBUG:tensorflow:Model output layer shape = (?, 64, 64, 2)
INFO:tensorflow:Total number of trainable model parameters = 7,699,712
DEBUG:tensorflow:Labels shape = (?, 64, 64, 1)
INFO:tensorflow:Preparing loss function metric: CrossEntropy
INFO:tensorflow:Creating AdamOptimizer with learning-rate = 0.001, and learning-rate decay rate = 1.0
DEBUG:tensorflow:num_iterations_per_epoch = 40.000000
DEBUG:tensorflow:opt_decay_steps = 40.000000
DEBUG:tensorflow:opt_moving_average = 1.000000
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Create CheckpointSaverHook.
INFO:tensorflow:Graph was finalized.
INFO:tensorflow:Restoring parameters from /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt-680
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
INFO:tensorflow:Saving checkpoints for 680 into /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt.
DEBUG:tensorflow:Training iteration 680 / 4000 (17.00%)
INFO:tensorflow:loss = 0.069456354, step = 680
DEBUG:tensorflow:Training iteration 690 / 4000 (17.25%)
DEBUG:tensorflow:Training iteration 700 / 4000 (17.50%)
DEBUG:tensorflow:Training iteration 710 / 4000 (17.75%)
DEBUG:tensorflow:Training iteration 720 / 4000 (18.00%)
INFO:tensorflow:Saving checkpoints for 720 into /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt.
INFO:tensorflow:Loss for final step: 0.07294537.
INFO:tensorflow:
-----------------------------------------
-----
---- Training model...
-----
DEBUG:tensorflow:Train data: epoch size = 5120
DEBUG:tensorflow:Train data: batch size = 128
DEBUG:tensorflow:Train data: num_epochs = 100
DEBUG:tensorflow:Train data: patch_size: [64, 64, 7]
DEBUG:tensorflow:Train data: feature[0].shape: (5120, 64, 64, 7)
DEBUG:tensorflow:Train data: target[0].shape: (5120, 64, 64, 1)
INFO:tensorflow:Augmenting training data
INFO:tensorflow:Peformed 2527 flips
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:Creating model...
DEBUG:tensorflow:Stacked data shape: (?, 64, 64, 7)
DEBUG:tensorflow:Input data shape: (64, 64, 7)
DEBUG:tensorflow:Rectified input data shape: (?, 64, 64, 7)
DEBUG:tensorflow:===== Creating U-Net model: U-Net
DEBUG:tensorflow:Training: True
DEBUG:tensorflow:Apply dropout: True
DEBUG:tensorflow:==== Convolution Layer 1
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:==== Convolution Layer 2
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:==== Convolution Layer 3
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:==== Middle Convolution Layer 
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 8, 8, 512)
DEBUG:tensorflow:Using dropout_rate=0.150000
DEBUG:tensorflow:feature shape: (?, 8, 8, 512)
DEBUG:tensorflow:Using dropout_rate=0.150000
DEBUG:tensorflow:===== Convolution Transpose Layer 3
DEBUG:tensorflow:upconv shape: (?, 16, 16, 256)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:===== Convolution Transpose Layer 2
DEBUG:tensorflow:upconv shape: (?, 32, 32, 128)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:===== Convolution Transpose Layer 1
DEBUG:tensorflow:upconv shape: (?, 64, 64, 64)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:===== Final Convolution Layer 1
DEBUG:tensorflow:feature shape: (?, 64, 64, 2)
DEBUG:tensorflow:=====
DEBUG:tensorflow:Model output layer shape = (?, 64, 64, 2)
INFO:tensorflow:Total number of trainable model parameters = 7,699,712
DEBUG:tensorflow:Labels shape = (?, 64, 64, 1)
INFO:tensorflow:Preparing loss function metric: CrossEntropy
INFO:tensorflow:Creating AdamOptimizer with learning-rate = 0.001, and learning-rate decay rate = 1.0
DEBUG:tensorflow:num_iterations_per_epoch = 40.000000
DEBUG:tensorflow:opt_decay_steps = 40.000000
DEBUG:tensorflow:opt_moving_average = 1.000000
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Create CheckpointSaverHook.
INFO:tensorflow:Graph was finalized.
INFO:tensorflow:Restoring parameters from /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt-720
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
INFO:tensorflow:Saving checkpoints for 720 into /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt.
DEBUG:tensorflow:Training iteration 720 / 4000 (18.00%)
INFO:tensorflow:loss = 0.06267864, step = 720
DEBUG:tensorflow:Training iteration 730 / 4000 (18.25%)
DEBUG:tensorflow:Training iteration 740 / 4000 (18.50%)
DEBUG:tensorflow:Training iteration 750 / 4000 (18.75%)
DEBUG:tensorflow:Training iteration 760 / 4000 (19.00%)
INFO:tensorflow:Saving checkpoints for 760 into /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt.
INFO:tensorflow:Loss for final step: 0.04422174.
INFO:tensorflow:
-----------------------------------------
-----
---- Training model...
-----
DEBUG:tensorflow:Train data: epoch size = 5120
DEBUG:tensorflow:Train data: batch size = 128
DEBUG:tensorflow:Train data: num_epochs = 100
DEBUG:tensorflow:Train data: patch_size: [64, 64, 7]
DEBUG:tensorflow:Train data: feature[0].shape: (5120, 64, 64, 7)
DEBUG:tensorflow:Train data: target[0].shape: (5120, 64, 64, 1)
INFO:tensorflow:Augmenting training data
INFO:tensorflow:Peformed 2586 flips
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:Creating model...
DEBUG:tensorflow:Stacked data shape: (?, 64, 64, 7)
DEBUG:tensorflow:Input data shape: (64, 64, 7)
DEBUG:tensorflow:Rectified input data shape: (?, 64, 64, 7)
DEBUG:tensorflow:===== Creating U-Net model: U-Net
DEBUG:tensorflow:Training: True
DEBUG:tensorflow:Apply dropout: True
DEBUG:tensorflow:==== Convolution Layer 1
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:==== Convolution Layer 2
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:==== Convolution Layer 3
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:==== Middle Convolution Layer 
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 8, 8, 512)
DEBUG:tensorflow:Using dropout_rate=0.150000
DEBUG:tensorflow:feature shape: (?, 8, 8, 512)
DEBUG:tensorflow:Using dropout_rate=0.150000
DEBUG:tensorflow:===== Convolution Transpose Layer 3
DEBUG:tensorflow:upconv shape: (?, 16, 16, 256)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:===== Convolution Transpose Layer 2
DEBUG:tensorflow:upconv shape: (?, 32, 32, 128)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:===== Convolution Transpose Layer 1
DEBUG:tensorflow:upconv shape: (?, 64, 64, 64)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:===== Final Convolution Layer 1
DEBUG:tensorflow:feature shape: (?, 64, 64, 2)
DEBUG:tensorflow:=====
DEBUG:tensorflow:Model output layer shape = (?, 64, 64, 2)
INFO:tensorflow:Total number of trainable model parameters = 7,699,712
DEBUG:tensorflow:Labels shape = (?, 64, 64, 1)
INFO:tensorflow:Preparing loss function metric: CrossEntropy
INFO:tensorflow:Creating AdamOptimizer with learning-rate = 0.001, and learning-rate decay rate = 1.0
DEBUG:tensorflow:num_iterations_per_epoch = 40.000000
DEBUG:tensorflow:opt_decay_steps = 40.000000
DEBUG:tensorflow:opt_moving_average = 1.000000
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Create CheckpointSaverHook.
INFO:tensorflow:Graph was finalized.
INFO:tensorflow:Restoring parameters from /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt-760
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
INFO:tensorflow:Saving checkpoints for 760 into /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt.
DEBUG:tensorflow:Training iteration 760 / 4000 (19.00%)
INFO:tensorflow:loss = 0.049767468, step = 760
DEBUG:tensorflow:Training iteration 770 / 4000 (19.25%)
DEBUG:tensorflow:Training iteration 780 / 4000 (19.50%)
DEBUG:tensorflow:Training iteration 790 / 4000 (19.75%)
DEBUG:tensorflow:Training iteration 800 / 4000 (20.00%)
INFO:tensorflow:Saving checkpoints for 800 into /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt.
INFO:tensorflow:Loss for final step: 0.06102173.
INFO:tensorflow:
-----------------------------------------
-----
---- Training model...
-----
DEBUG:tensorflow:Train data: epoch size = 5120
DEBUG:tensorflow:Train data: batch size = 128
DEBUG:tensorflow:Train data: num_epochs = 100
DEBUG:tensorflow:Train data: patch_size: [64, 64, 7]
DEBUG:tensorflow:Train data: feature[0].shape: (5120, 64, 64, 7)
DEBUG:tensorflow:Train data: target[0].shape: (5120, 64, 64, 1)
INFO:tensorflow:Augmenting training data
INFO:tensorflow:Peformed 2574 flips
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:Creating model...
DEBUG:tensorflow:Stacked data shape: (?, 64, 64, 7)
DEBUG:tensorflow:Input data shape: (64, 64, 7)
DEBUG:tensorflow:Rectified input data shape: (?, 64, 64, 7)
DEBUG:tensorflow:===== Creating U-Net model: U-Net
DEBUG:tensorflow:Training: True
DEBUG:tensorflow:Apply dropout: True
DEBUG:tensorflow:==== Convolution Layer 1
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:==== Convolution Layer 2
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:==== Convolution Layer 3
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:==== Middle Convolution Layer 
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 8, 8, 512)
DEBUG:tensorflow:Using dropout_rate=0.150000
DEBUG:tensorflow:feature shape: (?, 8, 8, 512)
DEBUG:tensorflow:Using dropout_rate=0.150000
DEBUG:tensorflow:===== Convolution Transpose Layer 3
DEBUG:tensorflow:upconv shape: (?, 16, 16, 256)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:===== Convolution Transpose Layer 2
DEBUG:tensorflow:upconv shape: (?, 32, 32, 128)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:===== Convolution Transpose Layer 1
DEBUG:tensorflow:upconv shape: (?, 64, 64, 64)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:===== Final Convolution Layer 1
DEBUG:tensorflow:feature shape: (?, 64, 64, 2)
DEBUG:tensorflow:=====
DEBUG:tensorflow:Model output layer shape = (?, 64, 64, 2)
INFO:tensorflow:Total number of trainable model parameters = 7,699,712
DEBUG:tensorflow:Labels shape = (?, 64, 64, 1)
INFO:tensorflow:Preparing loss function metric: CrossEntropy
INFO:tensorflow:Creating AdamOptimizer with learning-rate = 0.001, and learning-rate decay rate = 1.0
DEBUG:tensorflow:num_iterations_per_epoch = 40.000000
DEBUG:tensorflow:opt_decay_steps = 40.000000
DEBUG:tensorflow:opt_moving_average = 1.000000
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Create CheckpointSaverHook.
INFO:tensorflow:Graph was finalized.
INFO:tensorflow:Restoring parameters from /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt-800
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
INFO:tensorflow:Saving checkpoints for 800 into /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt.
DEBUG:tensorflow:Training iteration 800 / 4000 (20.00%)
INFO:tensorflow:loss = 0.04555828, step = 800
DEBUG:tensorflow:Training iteration 810 / 4000 (20.25%)
DEBUG:tensorflow:Training iteration 820 / 4000 (20.50%)
DEBUG:tensorflow:Training iteration 830 / 4000 (20.75%)
DEBUG:tensorflow:Training iteration 840 / 4000 (21.00%)
INFO:tensorflow:Saving checkpoints for 840 into /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt.
INFO:tensorflow:Loss for final step: 0.049876634.
INFO:tensorflow:
-----------------------------------------
-----
---- Training model...
-----
DEBUG:tensorflow:Train data: epoch size = 5120
DEBUG:tensorflow:Train data: batch size = 128
DEBUG:tensorflow:Train data: num_epochs = 100
DEBUG:tensorflow:Train data: patch_size: [64, 64, 7]
DEBUG:tensorflow:Train data: feature[0].shape: (5120, 64, 64, 7)
DEBUG:tensorflow:Train data: target[0].shape: (5120, 64, 64, 1)
INFO:tensorflow:Augmenting training data
INFO:tensorflow:Peformed 2547 flips
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:Creating model...
DEBUG:tensorflow:Stacked data shape: (?, 64, 64, 7)
DEBUG:tensorflow:Input data shape: (64, 64, 7)
DEBUG:tensorflow:Rectified input data shape: (?, 64, 64, 7)
DEBUG:tensorflow:===== Creating U-Net model: U-Net
DEBUG:tensorflow:Training: True
DEBUG:tensorflow:Apply dropout: True
DEBUG:tensorflow:==== Convolution Layer 1
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:==== Convolution Layer 2
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:==== Convolution Layer 3
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:==== Middle Convolution Layer 
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 8, 8, 512)
DEBUG:tensorflow:Using dropout_rate=0.150000
DEBUG:tensorflow:feature shape: (?, 8, 8, 512)
DEBUG:tensorflow:Using dropout_rate=0.150000
DEBUG:tensorflow:===== Convolution Transpose Layer 3
DEBUG:tensorflow:upconv shape: (?, 16, 16, 256)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:===== Convolution Transpose Layer 2
DEBUG:tensorflow:upconv shape: (?, 32, 32, 128)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:===== Convolution Transpose Layer 1
DEBUG:tensorflow:upconv shape: (?, 64, 64, 64)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:===== Final Convolution Layer 1
DEBUG:tensorflow:feature shape: (?, 64, 64, 2)
DEBUG:tensorflow:=====
DEBUG:tensorflow:Model output layer shape = (?, 64, 64, 2)
INFO:tensorflow:Total number of trainable model parameters = 7,699,712
DEBUG:tensorflow:Labels shape = (?, 64, 64, 1)
INFO:tensorflow:Preparing loss function metric: CrossEntropy
INFO:tensorflow:Creating AdamOptimizer with learning-rate = 0.001, and learning-rate decay rate = 1.0
DEBUG:tensorflow:num_iterations_per_epoch = 40.000000
DEBUG:tensorflow:opt_decay_steps = 40.000000
DEBUG:tensorflow:opt_moving_average = 1.000000
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Create CheckpointSaverHook.
INFO:tensorflow:Graph was finalized.
INFO:tensorflow:Restoring parameters from /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt-840
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
INFO:tensorflow:Saving checkpoints for 840 into /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt.
DEBUG:tensorflow:Training iteration 840 / 4000 (21.00%)
INFO:tensorflow:loss = 0.05475605, step = 840
DEBUG:tensorflow:Training iteration 850 / 4000 (21.25%)
DEBUG:tensorflow:Training iteration 860 / 4000 (21.50%)
DEBUG:tensorflow:Training iteration 870 / 4000 (21.75%)
DEBUG:tensorflow:Training iteration 880 / 4000 (22.00%)
INFO:tensorflow:Saving checkpoints for 880 into /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt.
INFO:tensorflow:Loss for final step: 0.07111857.
INFO:tensorflow:
-----------------------------------------
-----
---- Training model...
-----
DEBUG:tensorflow:Train data: epoch size = 5120
DEBUG:tensorflow:Train data: batch size = 128
DEBUG:tensorflow:Train data: num_epochs = 100
DEBUG:tensorflow:Train data: patch_size: [64, 64, 7]
DEBUG:tensorflow:Train data: feature[0].shape: (5120, 64, 64, 7)
DEBUG:tensorflow:Train data: target[0].shape: (5120, 64, 64, 1)
INFO:tensorflow:Augmenting training data
INFO:tensorflow:Peformed 2655 flips
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:Creating model...
DEBUG:tensorflow:Stacked data shape: (?, 64, 64, 7)
DEBUG:tensorflow:Input data shape: (64, 64, 7)
DEBUG:tensorflow:Rectified input data shape: (?, 64, 64, 7)
DEBUG:tensorflow:===== Creating U-Net model: U-Net
DEBUG:tensorflow:Training: True
DEBUG:tensorflow:Apply dropout: True
DEBUG:tensorflow:==== Convolution Layer 1
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:==== Convolution Layer 2
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:==== Convolution Layer 3
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:==== Middle Convolution Layer 
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 8, 8, 512)
DEBUG:tensorflow:Using dropout_rate=0.150000
DEBUG:tensorflow:feature shape: (?, 8, 8, 512)
DEBUG:tensorflow:Using dropout_rate=0.150000
DEBUG:tensorflow:===== Convolution Transpose Layer 3
DEBUG:tensorflow:upconv shape: (?, 16, 16, 256)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:===== Convolution Transpose Layer 2
DEBUG:tensorflow:upconv shape: (?, 32, 32, 128)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:===== Convolution Transpose Layer 1
DEBUG:tensorflow:upconv shape: (?, 64, 64, 64)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:===== Final Convolution Layer 1
DEBUG:tensorflow:feature shape: (?, 64, 64, 2)
DEBUG:tensorflow:=====
DEBUG:tensorflow:Model output layer shape = (?, 64, 64, 2)
INFO:tensorflow:Total number of trainable model parameters = 7,699,712
DEBUG:tensorflow:Labels shape = (?, 64, 64, 1)
INFO:tensorflow:Preparing loss function metric: CrossEntropy
INFO:tensorflow:Creating AdamOptimizer with learning-rate = 0.001, and learning-rate decay rate = 1.0
DEBUG:tensorflow:num_iterations_per_epoch = 40.000000
DEBUG:tensorflow:opt_decay_steps = 40.000000
DEBUG:tensorflow:opt_moving_average = 1.000000
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Create CheckpointSaverHook.
INFO:tensorflow:Graph was finalized.
INFO:tensorflow:Restoring parameters from /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt-880
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
INFO:tensorflow:Saving checkpoints for 880 into /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt.
DEBUG:tensorflow:Training iteration 880 / 4000 (22.00%)
INFO:tensorflow:loss = 0.056898583, step = 880
DEBUG:tensorflow:Training iteration 890 / 4000 (22.25%)
DEBUG:tensorflow:Training iteration 900 / 4000 (22.50%)
DEBUG:tensorflow:Training iteration 910 / 4000 (22.75%)
DEBUG:tensorflow:Training iteration 920 / 4000 (23.00%)
INFO:tensorflow:Saving checkpoints for 920 into /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt.
INFO:tensorflow:Loss for final step: 0.06532512.
INFO:tensorflow:
-----------------------------------------
-----
---- Training model...
-----
DEBUG:tensorflow:Train data: epoch size = 5120
DEBUG:tensorflow:Train data: batch size = 128
DEBUG:tensorflow:Train data: num_epochs = 100
DEBUG:tensorflow:Train data: patch_size: [64, 64, 7]
DEBUG:tensorflow:Train data: feature[0].shape: (5120, 64, 64, 7)
DEBUG:tensorflow:Train data: target[0].shape: (5120, 64, 64, 1)
INFO:tensorflow:Augmenting training data
INFO:tensorflow:Peformed 2536 flips
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:Creating model...
DEBUG:tensorflow:Stacked data shape: (?, 64, 64, 7)
DEBUG:tensorflow:Input data shape: (64, 64, 7)
DEBUG:tensorflow:Rectified input data shape: (?, 64, 64, 7)
DEBUG:tensorflow:===== Creating U-Net model: U-Net
DEBUG:tensorflow:Training: True
DEBUG:tensorflow:Apply dropout: True
DEBUG:tensorflow:==== Convolution Layer 1
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:==== Convolution Layer 2
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:==== Convolution Layer 3
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:==== Middle Convolution Layer 
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 8, 8, 512)
DEBUG:tensorflow:Using dropout_rate=0.150000
DEBUG:tensorflow:feature shape: (?, 8, 8, 512)
DEBUG:tensorflow:Using dropout_rate=0.150000
DEBUG:tensorflow:===== Convolution Transpose Layer 3
DEBUG:tensorflow:upconv shape: (?, 16, 16, 256)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:===== Convolution Transpose Layer 2
DEBUG:tensorflow:upconv shape: (?, 32, 32, 128)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:===== Convolution Transpose Layer 1
DEBUG:tensorflow:upconv shape: (?, 64, 64, 64)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:===== Final Convolution Layer 1
DEBUG:tensorflow:feature shape: (?, 64, 64, 2)
DEBUG:tensorflow:=====
DEBUG:tensorflow:Model output layer shape = (?, 64, 64, 2)
INFO:tensorflow:Total number of trainable model parameters = 7,699,712
DEBUG:tensorflow:Labels shape = (?, 64, 64, 1)
INFO:tensorflow:Preparing loss function metric: CrossEntropy
INFO:tensorflow:Creating AdamOptimizer with learning-rate = 0.001, and learning-rate decay rate = 1.0
DEBUG:tensorflow:num_iterations_per_epoch = 40.000000
DEBUG:tensorflow:opt_decay_steps = 40.000000
DEBUG:tensorflow:opt_moving_average = 1.000000
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Create CheckpointSaverHook.
INFO:tensorflow:Graph was finalized.
INFO:tensorflow:Restoring parameters from /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt-920
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
INFO:tensorflow:Saving checkpoints for 920 into /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt.
DEBUG:tensorflow:Training iteration 920 / 4000 (23.00%)
INFO:tensorflow:loss = 0.07306132, step = 920
DEBUG:tensorflow:Training iteration 930 / 4000 (23.25%)
DEBUG:tensorflow:Training iteration 940 / 4000 (23.50%)
DEBUG:tensorflow:Training iteration 950 / 4000 (23.75%)
DEBUG:tensorflow:Training iteration 960 / 4000 (24.00%)
INFO:tensorflow:Saving checkpoints for 960 into /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt.
INFO:tensorflow:Loss for final step: 0.05680106.
INFO:tensorflow:
-----------------------------------------
-----
---- Training model...
-----
DEBUG:tensorflow:Train data: epoch size = 5120
DEBUG:tensorflow:Train data: batch size = 128
DEBUG:tensorflow:Train data: num_epochs = 100
DEBUG:tensorflow:Train data: patch_size: [64, 64, 7]
DEBUG:tensorflow:Train data: feature[0].shape: (5120, 64, 64, 7)
DEBUG:tensorflow:Train data: target[0].shape: (5120, 64, 64, 1)
INFO:tensorflow:Augmenting training data
INFO:tensorflow:Peformed 2581 flips
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:Creating model...
DEBUG:tensorflow:Stacked data shape: (?, 64, 64, 7)
DEBUG:tensorflow:Input data shape: (64, 64, 7)
DEBUG:tensorflow:Rectified input data shape: (?, 64, 64, 7)
DEBUG:tensorflow:===== Creating U-Net model: U-Net
DEBUG:tensorflow:Training: True
DEBUG:tensorflow:Apply dropout: True
DEBUG:tensorflow:==== Convolution Layer 1
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:==== Convolution Layer 2
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:==== Convolution Layer 3
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:==== Middle Convolution Layer 
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 8, 8, 512)
DEBUG:tensorflow:Using dropout_rate=0.150000
DEBUG:tensorflow:feature shape: (?, 8, 8, 512)
DEBUG:tensorflow:Using dropout_rate=0.150000
DEBUG:tensorflow:===== Convolution Transpose Layer 3
DEBUG:tensorflow:upconv shape: (?, 16, 16, 256)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:===== Convolution Transpose Layer 2
DEBUG:tensorflow:upconv shape: (?, 32, 32, 128)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:===== Convolution Transpose Layer 1
DEBUG:tensorflow:upconv shape: (?, 64, 64, 64)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:===== Final Convolution Layer 1
DEBUG:tensorflow:feature shape: (?, 64, 64, 2)
DEBUG:tensorflow:=====
DEBUG:tensorflow:Model output layer shape = (?, 64, 64, 2)
INFO:tensorflow:Total number of trainable model parameters = 7,699,712
DEBUG:tensorflow:Labels shape = (?, 64, 64, 1)
INFO:tensorflow:Preparing loss function metric: CrossEntropy
INFO:tensorflow:Creating AdamOptimizer with learning-rate = 0.001, and learning-rate decay rate = 1.0
DEBUG:tensorflow:num_iterations_per_epoch = 40.000000
DEBUG:tensorflow:opt_decay_steps = 40.000000
DEBUG:tensorflow:opt_moving_average = 1.000000
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Create CheckpointSaverHook.
INFO:tensorflow:Graph was finalized.
INFO:tensorflow:Restoring parameters from /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt-960
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
INFO:tensorflow:Saving checkpoints for 960 into /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt.
DEBUG:tensorflow:Training iteration 960 / 4000 (24.00%)
INFO:tensorflow:loss = 0.061878208, step = 960
DEBUG:tensorflow:Training iteration 970 / 4000 (24.25%)
DEBUG:tensorflow:Training iteration 980 / 4000 (24.50%)
DEBUG:tensorflow:Training iteration 990 / 4000 (24.75%)
DEBUG:tensorflow:Training iteration 1000 / 4000 (25.00%)
INFO:tensorflow:Saving checkpoints for 1000 into /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt.
INFO:tensorflow:Loss for final step: 0.05804701.
INFO:tensorflow:
-----------------------------------------
-----
---- Training model...
-----
DEBUG:tensorflow:Train data: epoch size = 5120
DEBUG:tensorflow:Train data: batch size = 128
DEBUG:tensorflow:Train data: num_epochs = 100
DEBUG:tensorflow:Train data: patch_size: [64, 64, 7]
DEBUG:tensorflow:Train data: feature[0].shape: (5120, 64, 64, 7)
DEBUG:tensorflow:Train data: target[0].shape: (5120, 64, 64, 1)
INFO:tensorflow:Augmenting training data
INFO:tensorflow:Peformed 2589 flips
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:Creating model...
DEBUG:tensorflow:Stacked data shape: (?, 64, 64, 7)
DEBUG:tensorflow:Input data shape: (64, 64, 7)
DEBUG:tensorflow:Rectified input data shape: (?, 64, 64, 7)
DEBUG:tensorflow:===== Creating U-Net model: U-Net
DEBUG:tensorflow:Training: True
DEBUG:tensorflow:Apply dropout: True
DEBUG:tensorflow:==== Convolution Layer 1
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:==== Convolution Layer 2
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:==== Convolution Layer 3
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:==== Middle Convolution Layer 
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 8, 8, 512)
DEBUG:tensorflow:Using dropout_rate=0.150000
DEBUG:tensorflow:feature shape: (?, 8, 8, 512)
DEBUG:tensorflow:Using dropout_rate=0.150000
DEBUG:tensorflow:===== Convolution Transpose Layer 3
DEBUG:tensorflow:upconv shape: (?, 16, 16, 256)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:===== Convolution Transpose Layer 2
DEBUG:tensorflow:upconv shape: (?, 32, 32, 128)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:===== Convolution Transpose Layer 1
DEBUG:tensorflow:upconv shape: (?, 64, 64, 64)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:===== Final Convolution Layer 1
DEBUG:tensorflow:feature shape: (?, 64, 64, 2)
DEBUG:tensorflow:=====
DEBUG:tensorflow:Model output layer shape = (?, 64, 64, 2)
INFO:tensorflow:Total number of trainable model parameters = 7,699,712
DEBUG:tensorflow:Labels shape = (?, 64, 64, 1)
INFO:tensorflow:Preparing loss function metric: CrossEntropy
INFO:tensorflow:Creating AdamOptimizer with learning-rate = 0.001, and learning-rate decay rate = 1.0
DEBUG:tensorflow:num_iterations_per_epoch = 40.000000
DEBUG:tensorflow:opt_decay_steps = 40.000000
DEBUG:tensorflow:opt_moving_average = 1.000000
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Create CheckpointSaverHook.
INFO:tensorflow:Graph was finalized.
INFO:tensorflow:Restoring parameters from /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt-1000
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
INFO:tensorflow:Saving checkpoints for 1000 into /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt.
DEBUG:tensorflow:Training iteration 1000 / 4000 (25.00%)
INFO:tensorflow:loss = 0.06897146, step = 1000
DEBUG:tensorflow:Training iteration 1010 / 4000 (25.25%)
DEBUG:tensorflow:Training iteration 1020 / 4000 (25.50%)
DEBUG:tensorflow:Training iteration 1030 / 4000 (25.75%)
DEBUG:tensorflow:Training iteration 1040 / 4000 (26.00%)
INFO:tensorflow:Saving checkpoints for 1040 into /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt.
INFO:tensorflow:Loss for final step: 0.05208818.
INFO:tensorflow:
-----------------------------------------
-----
---- Training model...
-----
DEBUG:tensorflow:Train data: epoch size = 5120
DEBUG:tensorflow:Train data: batch size = 128
DEBUG:tensorflow:Train data: num_epochs = 100
DEBUG:tensorflow:Train data: patch_size: [64, 64, 7]
DEBUG:tensorflow:Train data: feature[0].shape: (5120, 64, 64, 7)
DEBUG:tensorflow:Train data: target[0].shape: (5120, 64, 64, 1)
INFO:tensorflow:Augmenting training data
INFO:tensorflow:Peformed 2506 flips
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:Creating model...
DEBUG:tensorflow:Stacked data shape: (?, 64, 64, 7)
DEBUG:tensorflow:Input data shape: (64, 64, 7)
DEBUG:tensorflow:Rectified input data shape: (?, 64, 64, 7)
DEBUG:tensorflow:===== Creating U-Net model: U-Net
DEBUG:tensorflow:Training: True
DEBUG:tensorflow:Apply dropout: True
DEBUG:tensorflow:==== Convolution Layer 1
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:==== Convolution Layer 2
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:==== Convolution Layer 3
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:==== Middle Convolution Layer 
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 8, 8, 512)
DEBUG:tensorflow:Using dropout_rate=0.150000
DEBUG:tensorflow:feature shape: (?, 8, 8, 512)
DEBUG:tensorflow:Using dropout_rate=0.150000
DEBUG:tensorflow:===== Convolution Transpose Layer 3
DEBUG:tensorflow:upconv shape: (?, 16, 16, 256)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:===== Convolution Transpose Layer 2
DEBUG:tensorflow:upconv shape: (?, 32, 32, 128)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:===== Convolution Transpose Layer 1
DEBUG:tensorflow:upconv shape: (?, 64, 64, 64)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:===== Final Convolution Layer 1
DEBUG:tensorflow:feature shape: (?, 64, 64, 2)
DEBUG:tensorflow:=====
DEBUG:tensorflow:Model output layer shape = (?, 64, 64, 2)
INFO:tensorflow:Total number of trainable model parameters = 7,699,712
DEBUG:tensorflow:Labels shape = (?, 64, 64, 1)
INFO:tensorflow:Preparing loss function metric: CrossEntropy
INFO:tensorflow:Creating AdamOptimizer with learning-rate = 0.001, and learning-rate decay rate = 1.0
DEBUG:tensorflow:num_iterations_per_epoch = 40.000000
DEBUG:tensorflow:opt_decay_steps = 40.000000
DEBUG:tensorflow:opt_moving_average = 1.000000
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Create CheckpointSaverHook.
INFO:tensorflow:Graph was finalized.
INFO:tensorflow:Restoring parameters from /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt-1040
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
INFO:tensorflow:Saving checkpoints for 1040 into /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt.
DEBUG:tensorflow:Training iteration 1040 / 4000 (26.00%)
INFO:tensorflow:loss = 0.058074508, step = 1040
DEBUG:tensorflow:Training iteration 1050 / 4000 (26.25%)
DEBUG:tensorflow:Training iteration 1060 / 4000 (26.50%)
DEBUG:tensorflow:Training iteration 1070 / 4000 (26.75%)
DEBUG:tensorflow:Training iteration 1080 / 4000 (27.00%)
INFO:tensorflow:Saving checkpoints for 1080 into /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt.
INFO:tensorflow:Loss for final step: 0.044558384.
INFO:tensorflow:
-----------------------------------------
-----
---- Training model...
-----
DEBUG:tensorflow:Train data: epoch size = 5120
DEBUG:tensorflow:Train data: batch size = 128
DEBUG:tensorflow:Train data: num_epochs = 100
DEBUG:tensorflow:Train data: patch_size: [64, 64, 7]
DEBUG:tensorflow:Train data: feature[0].shape: (5120, 64, 64, 7)
DEBUG:tensorflow:Train data: target[0].shape: (5120, 64, 64, 1)
INFO:tensorflow:Augmenting training data
INFO:tensorflow:Peformed 2579 flips
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:Creating model...
DEBUG:tensorflow:Stacked data shape: (?, 64, 64, 7)
DEBUG:tensorflow:Input data shape: (64, 64, 7)
DEBUG:tensorflow:Rectified input data shape: (?, 64, 64, 7)
DEBUG:tensorflow:===== Creating U-Net model: U-Net
DEBUG:tensorflow:Training: True
DEBUG:tensorflow:Apply dropout: True
DEBUG:tensorflow:==== Convolution Layer 1
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:==== Convolution Layer 2
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:==== Convolution Layer 3
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:==== Middle Convolution Layer 
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 8, 8, 512)
DEBUG:tensorflow:Using dropout_rate=0.150000
DEBUG:tensorflow:feature shape: (?, 8, 8, 512)
DEBUG:tensorflow:Using dropout_rate=0.150000
DEBUG:tensorflow:===== Convolution Transpose Layer 3
DEBUG:tensorflow:upconv shape: (?, 16, 16, 256)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:===== Convolution Transpose Layer 2
DEBUG:tensorflow:upconv shape: (?, 32, 32, 128)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:===== Convolution Transpose Layer 1
DEBUG:tensorflow:upconv shape: (?, 64, 64, 64)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:===== Final Convolution Layer 1
DEBUG:tensorflow:feature shape: (?, 64, 64, 2)
DEBUG:tensorflow:=====
DEBUG:tensorflow:Model output layer shape = (?, 64, 64, 2)
INFO:tensorflow:Total number of trainable model parameters = 7,699,712
DEBUG:tensorflow:Labels shape = (?, 64, 64, 1)
INFO:tensorflow:Preparing loss function metric: CrossEntropy
INFO:tensorflow:Creating AdamOptimizer with learning-rate = 0.001, and learning-rate decay rate = 1.0
DEBUG:tensorflow:num_iterations_per_epoch = 40.000000
DEBUG:tensorflow:opt_decay_steps = 40.000000
DEBUG:tensorflow:opt_moving_average = 1.000000
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Create CheckpointSaverHook.
INFO:tensorflow:Graph was finalized.
INFO:tensorflow:Restoring parameters from /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt-1080
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
INFO:tensorflow:Saving checkpoints for 1080 into /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt.
DEBUG:tensorflow:Training iteration 1080 / 4000 (27.00%)
INFO:tensorflow:loss = 0.06995216, step = 1080
DEBUG:tensorflow:Training iteration 1090 / 4000 (27.25%)
DEBUG:tensorflow:Training iteration 1100 / 4000 (27.50%)
DEBUG:tensorflow:Training iteration 1110 / 4000 (27.75%)
DEBUG:tensorflow:Training iteration 1120 / 4000 (28.00%)
INFO:tensorflow:Saving checkpoints for 1120 into /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt.
INFO:tensorflow:Loss for final step: 0.04084785.
INFO:tensorflow:
-----------------------------------------
-----
---- Training model...
-----
DEBUG:tensorflow:Train data: epoch size = 5120
DEBUG:tensorflow:Train data: batch size = 128
DEBUG:tensorflow:Train data: num_epochs = 100
DEBUG:tensorflow:Train data: patch_size: [64, 64, 7]
DEBUG:tensorflow:Train data: feature[0].shape: (5120, 64, 64, 7)
DEBUG:tensorflow:Train data: target[0].shape: (5120, 64, 64, 1)
INFO:tensorflow:Augmenting training data
INFO:tensorflow:Peformed 2514 flips
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:Creating model...
DEBUG:tensorflow:Stacked data shape: (?, 64, 64, 7)
DEBUG:tensorflow:Input data shape: (64, 64, 7)
DEBUG:tensorflow:Rectified input data shape: (?, 64, 64, 7)
DEBUG:tensorflow:===== Creating U-Net model: U-Net
DEBUG:tensorflow:Training: True
DEBUG:tensorflow:Apply dropout: True
DEBUG:tensorflow:==== Convolution Layer 1
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:==== Convolution Layer 2
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:==== Convolution Layer 3
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:==== Middle Convolution Layer 
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 8, 8, 512)
DEBUG:tensorflow:Using dropout_rate=0.150000
DEBUG:tensorflow:feature shape: (?, 8, 8, 512)
DEBUG:tensorflow:Using dropout_rate=0.150000
DEBUG:tensorflow:===== Convolution Transpose Layer 3
DEBUG:tensorflow:upconv shape: (?, 16, 16, 256)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:===== Convolution Transpose Layer 2
DEBUG:tensorflow:upconv shape: (?, 32, 32, 128)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:===== Convolution Transpose Layer 1
DEBUG:tensorflow:upconv shape: (?, 64, 64, 64)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:===== Final Convolution Layer 1
DEBUG:tensorflow:feature shape: (?, 64, 64, 2)
DEBUG:tensorflow:=====
DEBUG:tensorflow:Model output layer shape = (?, 64, 64, 2)
INFO:tensorflow:Total number of trainable model parameters = 7,699,712
DEBUG:tensorflow:Labels shape = (?, 64, 64, 1)
INFO:tensorflow:Preparing loss function metric: CrossEntropy
INFO:tensorflow:Creating AdamOptimizer with learning-rate = 0.001, and learning-rate decay rate = 1.0
DEBUG:tensorflow:num_iterations_per_epoch = 40.000000
DEBUG:tensorflow:opt_decay_steps = 40.000000
DEBUG:tensorflow:opt_moving_average = 1.000000
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Create CheckpointSaverHook.
INFO:tensorflow:Graph was finalized.
INFO:tensorflow:Restoring parameters from /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt-1120
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
INFO:tensorflow:Saving checkpoints for 1120 into /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt.
DEBUG:tensorflow:Training iteration 1120 / 4000 (28.00%)
INFO:tensorflow:loss = 0.09661053, step = 1120
DEBUG:tensorflow:Training iteration 1130 / 4000 (28.25%)
DEBUG:tensorflow:Training iteration 1140 / 4000 (28.50%)
DEBUG:tensorflow:Training iteration 1150 / 4000 (28.75%)
DEBUG:tensorflow:Training iteration 1160 / 4000 (29.00%)
INFO:tensorflow:Saving checkpoints for 1160 into /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt.
INFO:tensorflow:Loss for final step: 0.06318768.
INFO:tensorflow:
-----------------------------------------
-----
---- Training model...
-----
DEBUG:tensorflow:Train data: epoch size = 5120
DEBUG:tensorflow:Train data: batch size = 128
DEBUG:tensorflow:Train data: num_epochs = 100
DEBUG:tensorflow:Train data: patch_size: [64, 64, 7]
DEBUG:tensorflow:Train data: feature[0].shape: (5120, 64, 64, 7)
DEBUG:tensorflow:Train data: target[0].shape: (5120, 64, 64, 1)
INFO:tensorflow:Augmenting training data
INFO:tensorflow:Peformed 2577 flips
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:Creating model...
DEBUG:tensorflow:Stacked data shape: (?, 64, 64, 7)
DEBUG:tensorflow:Input data shape: (64, 64, 7)
DEBUG:tensorflow:Rectified input data shape: (?, 64, 64, 7)
DEBUG:tensorflow:===== Creating U-Net model: U-Net
DEBUG:tensorflow:Training: True
DEBUG:tensorflow:Apply dropout: True
DEBUG:tensorflow:==== Convolution Layer 1
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:==== Convolution Layer 2
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:==== Convolution Layer 3
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:==== Middle Convolution Layer 
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 8, 8, 512)
DEBUG:tensorflow:Using dropout_rate=0.150000
DEBUG:tensorflow:feature shape: (?, 8, 8, 512)
DEBUG:tensorflow:Using dropout_rate=0.150000
DEBUG:tensorflow:===== Convolution Transpose Layer 3
DEBUG:tensorflow:upconv shape: (?, 16, 16, 256)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:===== Convolution Transpose Layer 2
DEBUG:tensorflow:upconv shape: (?, 32, 32, 128)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:===== Convolution Transpose Layer 1
DEBUG:tensorflow:upconv shape: (?, 64, 64, 64)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:===== Final Convolution Layer 1
DEBUG:tensorflow:feature shape: (?, 64, 64, 2)
DEBUG:tensorflow:=====
DEBUG:tensorflow:Model output layer shape = (?, 64, 64, 2)
INFO:tensorflow:Total number of trainable model parameters = 7,699,712
DEBUG:tensorflow:Labels shape = (?, 64, 64, 1)
INFO:tensorflow:Preparing loss function metric: CrossEntropy
INFO:tensorflow:Creating AdamOptimizer with learning-rate = 0.001, and learning-rate decay rate = 1.0
DEBUG:tensorflow:num_iterations_per_epoch = 40.000000
DEBUG:tensorflow:opt_decay_steps = 40.000000
DEBUG:tensorflow:opt_moving_average = 1.000000
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Create CheckpointSaverHook.
INFO:tensorflow:Graph was finalized.
INFO:tensorflow:Restoring parameters from /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt-1160
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
INFO:tensorflow:Saving checkpoints for 1160 into /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt.
DEBUG:tensorflow:Training iteration 1160 / 4000 (29.00%)
INFO:tensorflow:loss = 0.028428666, step = 1160
DEBUG:tensorflow:Training iteration 1170 / 4000 (29.25%)
DEBUG:tensorflow:Training iteration 1180 / 4000 (29.50%)
DEBUG:tensorflow:Training iteration 1190 / 4000 (29.75%)
DEBUG:tensorflow:Training iteration 1200 / 4000 (30.00%)
INFO:tensorflow:Saving checkpoints for 1200 into /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt.
INFO:tensorflow:Loss for final step: 0.050240077.
INFO:tensorflow:
-----------------------------------------
-----
---- Training model...
-----
DEBUG:tensorflow:Train data: epoch size = 5120
DEBUG:tensorflow:Train data: batch size = 128
DEBUG:tensorflow:Train data: num_epochs = 100
DEBUG:tensorflow:Train data: patch_size: [64, 64, 7]
DEBUG:tensorflow:Train data: feature[0].shape: (5120, 64, 64, 7)
DEBUG:tensorflow:Train data: target[0].shape: (5120, 64, 64, 1)
INFO:tensorflow:Augmenting training data
INFO:tensorflow:Peformed 2569 flips
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:Creating model...
DEBUG:tensorflow:Stacked data shape: (?, 64, 64, 7)
DEBUG:tensorflow:Input data shape: (64, 64, 7)
DEBUG:tensorflow:Rectified input data shape: (?, 64, 64, 7)
DEBUG:tensorflow:===== Creating U-Net model: U-Net
DEBUG:tensorflow:Training: True
DEBUG:tensorflow:Apply dropout: True
DEBUG:tensorflow:==== Convolution Layer 1
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:==== Convolution Layer 2
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:==== Convolution Layer 3
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:==== Middle Convolution Layer 
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 8, 8, 512)
DEBUG:tensorflow:Using dropout_rate=0.150000
DEBUG:tensorflow:feature shape: (?, 8, 8, 512)
DEBUG:tensorflow:Using dropout_rate=0.150000
DEBUG:tensorflow:===== Convolution Transpose Layer 3
DEBUG:tensorflow:upconv shape: (?, 16, 16, 256)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:===== Convolution Transpose Layer 2
DEBUG:tensorflow:upconv shape: (?, 32, 32, 128)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:===== Convolution Transpose Layer 1
DEBUG:tensorflow:upconv shape: (?, 64, 64, 64)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:===== Final Convolution Layer 1
DEBUG:tensorflow:feature shape: (?, 64, 64, 2)
DEBUG:tensorflow:=====
DEBUG:tensorflow:Model output layer shape = (?, 64, 64, 2)
INFO:tensorflow:Total number of trainable model parameters = 7,699,712
DEBUG:tensorflow:Labels shape = (?, 64, 64, 1)
INFO:tensorflow:Preparing loss function metric: CrossEntropy
INFO:tensorflow:Creating AdamOptimizer with learning-rate = 0.001, and learning-rate decay rate = 1.0
DEBUG:tensorflow:num_iterations_per_epoch = 40.000000
DEBUG:tensorflow:opt_decay_steps = 40.000000
DEBUG:tensorflow:opt_moving_average = 1.000000
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Create CheckpointSaverHook.
INFO:tensorflow:Graph was finalized.
INFO:tensorflow:Restoring parameters from /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt-1200
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
INFO:tensorflow:Saving checkpoints for 1200 into /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt.
DEBUG:tensorflow:Training iteration 1200 / 4000 (30.00%)
INFO:tensorflow:loss = 0.057421997, step = 1200
DEBUG:tensorflow:Training iteration 1210 / 4000 (30.25%)
DEBUG:tensorflow:Training iteration 1220 / 4000 (30.50%)
DEBUG:tensorflow:Training iteration 1230 / 4000 (30.75%)
DEBUG:tensorflow:Training iteration 1240 / 4000 (31.00%)
INFO:tensorflow:Saving checkpoints for 1240 into /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt.
INFO:tensorflow:Loss for final step: 0.05506952.
INFO:tensorflow:
-----------------------------------------
-----
---- Training model...
-----
DEBUG:tensorflow:Train data: epoch size = 5120
DEBUG:tensorflow:Train data: batch size = 128
DEBUG:tensorflow:Train data: num_epochs = 100
DEBUG:tensorflow:Train data: patch_size: [64, 64, 7]
DEBUG:tensorflow:Train data: feature[0].shape: (5120, 64, 64, 7)
DEBUG:tensorflow:Train data: target[0].shape: (5120, 64, 64, 1)
INFO:tensorflow:Augmenting training data
INFO:tensorflow:Peformed 2570 flips
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:Creating model...
DEBUG:tensorflow:Stacked data shape: (?, 64, 64, 7)
DEBUG:tensorflow:Input data shape: (64, 64, 7)
DEBUG:tensorflow:Rectified input data shape: (?, 64, 64, 7)
DEBUG:tensorflow:===== Creating U-Net model: U-Net
DEBUG:tensorflow:Training: True
DEBUG:tensorflow:Apply dropout: True
DEBUG:tensorflow:==== Convolution Layer 1
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:==== Convolution Layer 2
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:==== Convolution Layer 3
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:==== Middle Convolution Layer 
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 8, 8, 512)
DEBUG:tensorflow:Using dropout_rate=0.150000
DEBUG:tensorflow:feature shape: (?, 8, 8, 512)
DEBUG:tensorflow:Using dropout_rate=0.150000
DEBUG:tensorflow:===== Convolution Transpose Layer 3
DEBUG:tensorflow:upconv shape: (?, 16, 16, 256)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:===== Convolution Transpose Layer 2
DEBUG:tensorflow:upconv shape: (?, 32, 32, 128)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:===== Convolution Transpose Layer 1
DEBUG:tensorflow:upconv shape: (?, 64, 64, 64)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:===== Final Convolution Layer 1
DEBUG:tensorflow:feature shape: (?, 64, 64, 2)
DEBUG:tensorflow:=====
DEBUG:tensorflow:Model output layer shape = (?, 64, 64, 2)
INFO:tensorflow:Total number of trainable model parameters = 7,699,712
DEBUG:tensorflow:Labels shape = (?, 64, 64, 1)
INFO:tensorflow:Preparing loss function metric: CrossEntropy
INFO:tensorflow:Creating AdamOptimizer with learning-rate = 0.001, and learning-rate decay rate = 1.0
DEBUG:tensorflow:num_iterations_per_epoch = 40.000000
DEBUG:tensorflow:opt_decay_steps = 40.000000
DEBUG:tensorflow:opt_moving_average = 1.000000
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Create CheckpointSaverHook.
INFO:tensorflow:Graph was finalized.
INFO:tensorflow:Restoring parameters from /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt-1240
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
INFO:tensorflow:Saving checkpoints for 1240 into /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt.
DEBUG:tensorflow:Training iteration 1240 / 4000 (31.00%)
INFO:tensorflow:loss = 0.06071805, step = 1240
DEBUG:tensorflow:Training iteration 1250 / 4000 (31.25%)
DEBUG:tensorflow:Training iteration 1260 / 4000 (31.50%)
DEBUG:tensorflow:Training iteration 1270 / 4000 (31.75%)
DEBUG:tensorflow:Training iteration 1280 / 4000 (32.00%)
INFO:tensorflow:Saving checkpoints for 1280 into /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt.
INFO:tensorflow:Loss for final step: 0.058716554.
INFO:tensorflow:
-----------------------------------------
-----
---- Training model...
-----
DEBUG:tensorflow:Train data: epoch size = 5120
DEBUG:tensorflow:Train data: batch size = 128
DEBUG:tensorflow:Train data: num_epochs = 100
DEBUG:tensorflow:Train data: patch_size: [64, 64, 7]
DEBUG:tensorflow:Train data: feature[0].shape: (5120, 64, 64, 7)
DEBUG:tensorflow:Train data: target[0].shape: (5120, 64, 64, 1)
INFO:tensorflow:Augmenting training data
INFO:tensorflow:Peformed 2549 flips
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:Creating model...
DEBUG:tensorflow:Stacked data shape: (?, 64, 64, 7)
DEBUG:tensorflow:Input data shape: (64, 64, 7)
DEBUG:tensorflow:Rectified input data shape: (?, 64, 64, 7)
DEBUG:tensorflow:===== Creating U-Net model: U-Net
DEBUG:tensorflow:Training: True
DEBUG:tensorflow:Apply dropout: True
DEBUG:tensorflow:==== Convolution Layer 1
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:==== Convolution Layer 2
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:==== Convolution Layer 3
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:==== Middle Convolution Layer 
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 8, 8, 512)
DEBUG:tensorflow:Using dropout_rate=0.150000
DEBUG:tensorflow:feature shape: (?, 8, 8, 512)
DEBUG:tensorflow:Using dropout_rate=0.150000
DEBUG:tensorflow:===== Convolution Transpose Layer 3
DEBUG:tensorflow:upconv shape: (?, 16, 16, 256)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:===== Convolution Transpose Layer 2
DEBUG:tensorflow:upconv shape: (?, 32, 32, 128)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:===== Convolution Transpose Layer 1
DEBUG:tensorflow:upconv shape: (?, 64, 64, 64)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:===== Final Convolution Layer 1
DEBUG:tensorflow:feature shape: (?, 64, 64, 2)
DEBUG:tensorflow:=====
DEBUG:tensorflow:Model output layer shape = (?, 64, 64, 2)
INFO:tensorflow:Total number of trainable model parameters = 7,699,712
DEBUG:tensorflow:Labels shape = (?, 64, 64, 1)
INFO:tensorflow:Preparing loss function metric: CrossEntropy
INFO:tensorflow:Creating AdamOptimizer with learning-rate = 0.001, and learning-rate decay rate = 1.0
DEBUG:tensorflow:num_iterations_per_epoch = 40.000000
DEBUG:tensorflow:opt_decay_steps = 40.000000
DEBUG:tensorflow:opt_moving_average = 1.000000
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Create CheckpointSaverHook.
INFO:tensorflow:Graph was finalized.
INFO:tensorflow:Restoring parameters from /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt-1280
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
INFO:tensorflow:Saving checkpoints for 1280 into /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt.
DEBUG:tensorflow:Training iteration 1280 / 4000 (32.00%)
INFO:tensorflow:loss = 0.051542915, step = 1280
DEBUG:tensorflow:Training iteration 1290 / 4000 (32.25%)
DEBUG:tensorflow:Training iteration 1300 / 4000 (32.50%)
DEBUG:tensorflow:Training iteration 1310 / 4000 (32.75%)
DEBUG:tensorflow:Training iteration 1320 / 4000 (33.00%)
INFO:tensorflow:Saving checkpoints for 1320 into /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt.
INFO:tensorflow:Loss for final step: 0.07108049.
INFO:tensorflow:
-----------------------------------------
-----
---- Training model...
-----
DEBUG:tensorflow:Train data: epoch size = 5120
DEBUG:tensorflow:Train data: batch size = 128
DEBUG:tensorflow:Train data: num_epochs = 100
DEBUG:tensorflow:Train data: patch_size: [64, 64, 7]
DEBUG:tensorflow:Train data: feature[0].shape: (5120, 64, 64, 7)
DEBUG:tensorflow:Train data: target[0].shape: (5120, 64, 64, 1)
INFO:tensorflow:Augmenting training data
INFO:tensorflow:Peformed 2610 flips
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:Creating model...
DEBUG:tensorflow:Stacked data shape: (?, 64, 64, 7)
DEBUG:tensorflow:Input data shape: (64, 64, 7)
DEBUG:tensorflow:Rectified input data shape: (?, 64, 64, 7)
DEBUG:tensorflow:===== Creating U-Net model: U-Net
DEBUG:tensorflow:Training: True
DEBUG:tensorflow:Apply dropout: True
DEBUG:tensorflow:==== Convolution Layer 1
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:==== Convolution Layer 2
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:==== Convolution Layer 3
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:==== Middle Convolution Layer 
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 8, 8, 512)
DEBUG:tensorflow:Using dropout_rate=0.150000
DEBUG:tensorflow:feature shape: (?, 8, 8, 512)
DEBUG:tensorflow:Using dropout_rate=0.150000
DEBUG:tensorflow:===== Convolution Transpose Layer 3
DEBUG:tensorflow:upconv shape: (?, 16, 16, 256)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:===== Convolution Transpose Layer 2
DEBUG:tensorflow:upconv shape: (?, 32, 32, 128)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:===== Convolution Transpose Layer 1
DEBUG:tensorflow:upconv shape: (?, 64, 64, 64)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:===== Final Convolution Layer 1
DEBUG:tensorflow:feature shape: (?, 64, 64, 2)
DEBUG:tensorflow:=====
DEBUG:tensorflow:Model output layer shape = (?, 64, 64, 2)
INFO:tensorflow:Total number of trainable model parameters = 7,699,712
DEBUG:tensorflow:Labels shape = (?, 64, 64, 1)
INFO:tensorflow:Preparing loss function metric: CrossEntropy
INFO:tensorflow:Creating AdamOptimizer with learning-rate = 0.001, and learning-rate decay rate = 1.0
DEBUG:tensorflow:num_iterations_per_epoch = 40.000000
DEBUG:tensorflow:opt_decay_steps = 40.000000
DEBUG:tensorflow:opt_moving_average = 1.000000
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Create CheckpointSaverHook.
INFO:tensorflow:Graph was finalized.
INFO:tensorflow:Restoring parameters from /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt-1320
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
INFO:tensorflow:Saving checkpoints for 1320 into /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt.
DEBUG:tensorflow:Training iteration 1320 / 4000 (33.00%)
INFO:tensorflow:loss = 0.044441894, step = 1320
DEBUG:tensorflow:Training iteration 1330 / 4000 (33.25%)
DEBUG:tensorflow:Training iteration 1340 / 4000 (33.50%)
DEBUG:tensorflow:Training iteration 1350 / 4000 (33.75%)
DEBUG:tensorflow:Training iteration 1360 / 4000 (34.00%)
INFO:tensorflow:Saving checkpoints for 1360 into /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt.
INFO:tensorflow:Loss for final step: 0.050716825.
INFO:tensorflow:
-----------------------------------------
-----
---- Training model...
-----
DEBUG:tensorflow:Train data: epoch size = 5120
DEBUG:tensorflow:Train data: batch size = 128
DEBUG:tensorflow:Train data: num_epochs = 100
DEBUG:tensorflow:Train data: patch_size: [64, 64, 7]
DEBUG:tensorflow:Train data: feature[0].shape: (5120, 64, 64, 7)
DEBUG:tensorflow:Train data: target[0].shape: (5120, 64, 64, 1)
INFO:tensorflow:Augmenting training data
INFO:tensorflow:Peformed 2568 flips
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:Creating model...
DEBUG:tensorflow:Stacked data shape: (?, 64, 64, 7)
DEBUG:tensorflow:Input data shape: (64, 64, 7)
DEBUG:tensorflow:Rectified input data shape: (?, 64, 64, 7)
DEBUG:tensorflow:===== Creating U-Net model: U-Net
DEBUG:tensorflow:Training: True
DEBUG:tensorflow:Apply dropout: True
DEBUG:tensorflow:==== Convolution Layer 1
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:==== Convolution Layer 2
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:==== Convolution Layer 3
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:==== Middle Convolution Layer 
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 8, 8, 512)
DEBUG:tensorflow:Using dropout_rate=0.150000
DEBUG:tensorflow:feature shape: (?, 8, 8, 512)
DEBUG:tensorflow:Using dropout_rate=0.150000
DEBUG:tensorflow:===== Convolution Transpose Layer 3
DEBUG:tensorflow:upconv shape: (?, 16, 16, 256)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:===== Convolution Transpose Layer 2
DEBUG:tensorflow:upconv shape: (?, 32, 32, 128)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:===== Convolution Transpose Layer 1
DEBUG:tensorflow:upconv shape: (?, 64, 64, 64)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:===== Final Convolution Layer 1
DEBUG:tensorflow:feature shape: (?, 64, 64, 2)
DEBUG:tensorflow:=====
DEBUG:tensorflow:Model output layer shape = (?, 64, 64, 2)
INFO:tensorflow:Total number of trainable model parameters = 7,699,712
DEBUG:tensorflow:Labels shape = (?, 64, 64, 1)
INFO:tensorflow:Preparing loss function metric: CrossEntropy
INFO:tensorflow:Creating AdamOptimizer with learning-rate = 0.001, and learning-rate decay rate = 1.0
DEBUG:tensorflow:num_iterations_per_epoch = 40.000000
DEBUG:tensorflow:opt_decay_steps = 40.000000
DEBUG:tensorflow:opt_moving_average = 1.000000
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Create CheckpointSaverHook.
INFO:tensorflow:Graph was finalized.
INFO:tensorflow:Restoring parameters from /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt-1360
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
INFO:tensorflow:Saving checkpoints for 1360 into /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt.
DEBUG:tensorflow:Training iteration 1360 / 4000 (34.00%)
INFO:tensorflow:loss = 0.055193387, step = 1360
DEBUG:tensorflow:Training iteration 1370 / 4000 (34.25%)
DEBUG:tensorflow:Training iteration 1380 / 4000 (34.50%)
DEBUG:tensorflow:Training iteration 1390 / 4000 (34.75%)
DEBUG:tensorflow:Training iteration 1400 / 4000 (35.00%)
INFO:tensorflow:Saving checkpoints for 1400 into /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt.
INFO:tensorflow:Loss for final step: 0.07840738.
INFO:tensorflow:
-----------------------------------------
-----
---- Training model...
-----
DEBUG:tensorflow:Train data: epoch size = 5120
DEBUG:tensorflow:Train data: batch size = 128
DEBUG:tensorflow:Train data: num_epochs = 100
DEBUG:tensorflow:Train data: patch_size: [64, 64, 7]
DEBUG:tensorflow:Train data: feature[0].shape: (5120, 64, 64, 7)
DEBUG:tensorflow:Train data: target[0].shape: (5120, 64, 64, 1)
INFO:tensorflow:Augmenting training data
INFO:tensorflow:Peformed 2583 flips
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:Creating model...
DEBUG:tensorflow:Stacked data shape: (?, 64, 64, 7)
DEBUG:tensorflow:Input data shape: (64, 64, 7)
DEBUG:tensorflow:Rectified input data shape: (?, 64, 64, 7)
DEBUG:tensorflow:===== Creating U-Net model: U-Net
DEBUG:tensorflow:Training: True
DEBUG:tensorflow:Apply dropout: True
DEBUG:tensorflow:==== Convolution Layer 1
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:==== Convolution Layer 2
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:==== Convolution Layer 3
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:==== Middle Convolution Layer 
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 8, 8, 512)
DEBUG:tensorflow:Using dropout_rate=0.150000
DEBUG:tensorflow:feature shape: (?, 8, 8, 512)
DEBUG:tensorflow:Using dropout_rate=0.150000
DEBUG:tensorflow:===== Convolution Transpose Layer 3
DEBUG:tensorflow:upconv shape: (?, 16, 16, 256)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:===== Convolution Transpose Layer 2
DEBUG:tensorflow:upconv shape: (?, 32, 32, 128)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:===== Convolution Transpose Layer 1
DEBUG:tensorflow:upconv shape: (?, 64, 64, 64)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:===== Final Convolution Layer 1
DEBUG:tensorflow:feature shape: (?, 64, 64, 2)
DEBUG:tensorflow:=====
DEBUG:tensorflow:Model output layer shape = (?, 64, 64, 2)
INFO:tensorflow:Total number of trainable model parameters = 7,699,712
DEBUG:tensorflow:Labels shape = (?, 64, 64, 1)
INFO:tensorflow:Preparing loss function metric: CrossEntropy
INFO:tensorflow:Creating AdamOptimizer with learning-rate = 0.001, and learning-rate decay rate = 1.0
DEBUG:tensorflow:num_iterations_per_epoch = 40.000000
DEBUG:tensorflow:opt_decay_steps = 40.000000
DEBUG:tensorflow:opt_moving_average = 1.000000
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Create CheckpointSaverHook.
INFO:tensorflow:Graph was finalized.
INFO:tensorflow:Restoring parameters from /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt-1400
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
INFO:tensorflow:Saving checkpoints for 1400 into /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt.
DEBUG:tensorflow:Training iteration 1400 / 4000 (35.00%)
INFO:tensorflow:loss = 0.05962627, step = 1400
DEBUG:tensorflow:Training iteration 1410 / 4000 (35.25%)
DEBUG:tensorflow:Training iteration 1420 / 4000 (35.50%)
DEBUG:tensorflow:Training iteration 1430 / 4000 (35.75%)
DEBUG:tensorflow:Training iteration 1440 / 4000 (36.00%)
INFO:tensorflow:Saving checkpoints for 1440 into /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt.
INFO:tensorflow:Loss for final step: 0.037704855.
INFO:tensorflow:
-----------------------------------------
-----
---- Training model...
-----
DEBUG:tensorflow:Train data: epoch size = 5120
DEBUG:tensorflow:Train data: batch size = 128
DEBUG:tensorflow:Train data: num_epochs = 100
DEBUG:tensorflow:Train data: patch_size: [64, 64, 7]
DEBUG:tensorflow:Train data: feature[0].shape: (5120, 64, 64, 7)
DEBUG:tensorflow:Train data: target[0].shape: (5120, 64, 64, 1)
INFO:tensorflow:Augmenting training data
INFO:tensorflow:Peformed 2536 flips
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:Creating model...
DEBUG:tensorflow:Stacked data shape: (?, 64, 64, 7)
DEBUG:tensorflow:Input data shape: (64, 64, 7)
DEBUG:tensorflow:Rectified input data shape: (?, 64, 64, 7)
DEBUG:tensorflow:===== Creating U-Net model: U-Net
DEBUG:tensorflow:Training: True
DEBUG:tensorflow:Apply dropout: True
DEBUG:tensorflow:==== Convolution Layer 1
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:==== Convolution Layer 2
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:==== Convolution Layer 3
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:==== Middle Convolution Layer 
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 8, 8, 512)
DEBUG:tensorflow:Using dropout_rate=0.150000
DEBUG:tensorflow:feature shape: (?, 8, 8, 512)
DEBUG:tensorflow:Using dropout_rate=0.150000
DEBUG:tensorflow:===== Convolution Transpose Layer 3
DEBUG:tensorflow:upconv shape: (?, 16, 16, 256)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:===== Convolution Transpose Layer 2
DEBUG:tensorflow:upconv shape: (?, 32, 32, 128)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:===== Convolution Transpose Layer 1
DEBUG:tensorflow:upconv shape: (?, 64, 64, 64)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:===== Final Convolution Layer 1
DEBUG:tensorflow:feature shape: (?, 64, 64, 2)
DEBUG:tensorflow:=====
DEBUG:tensorflow:Model output layer shape = (?, 64, 64, 2)
INFO:tensorflow:Total number of trainable model parameters = 7,699,712
DEBUG:tensorflow:Labels shape = (?, 64, 64, 1)
INFO:tensorflow:Preparing loss function metric: CrossEntropy
INFO:tensorflow:Creating AdamOptimizer with learning-rate = 0.001, and learning-rate decay rate = 1.0
DEBUG:tensorflow:num_iterations_per_epoch = 40.000000
DEBUG:tensorflow:opt_decay_steps = 40.000000
DEBUG:tensorflow:opt_moving_average = 1.000000
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Create CheckpointSaverHook.
INFO:tensorflow:Graph was finalized.
INFO:tensorflow:Restoring parameters from /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt-1440
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
INFO:tensorflow:Saving checkpoints for 1440 into /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt.
DEBUG:tensorflow:Training iteration 1440 / 4000 (36.00%)
INFO:tensorflow:loss = 0.06529716, step = 1440
DEBUG:tensorflow:Training iteration 1450 / 4000 (36.25%)
DEBUG:tensorflow:Training iteration 1460 / 4000 (36.50%)
DEBUG:tensorflow:Training iteration 1470 / 4000 (36.75%)
DEBUG:tensorflow:Training iteration 1480 / 4000 (37.00%)
INFO:tensorflow:Saving checkpoints for 1480 into /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt.
INFO:tensorflow:Loss for final step: 0.05217173.
INFO:tensorflow:
-----------------------------------------
-----
---- Training model...
-----
DEBUG:tensorflow:Train data: epoch size = 5120
DEBUG:tensorflow:Train data: batch size = 128
DEBUG:tensorflow:Train data: num_epochs = 100
DEBUG:tensorflow:Train data: patch_size: [64, 64, 7]
DEBUG:tensorflow:Train data: feature[0].shape: (5120, 64, 64, 7)
DEBUG:tensorflow:Train data: target[0].shape: (5120, 64, 64, 1)
INFO:tensorflow:Augmenting training data
INFO:tensorflow:Peformed 2563 flips
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:Creating model...
DEBUG:tensorflow:Stacked data shape: (?, 64, 64, 7)
DEBUG:tensorflow:Input data shape: (64, 64, 7)
DEBUG:tensorflow:Rectified input data shape: (?, 64, 64, 7)
DEBUG:tensorflow:===== Creating U-Net model: U-Net
DEBUG:tensorflow:Training: True
DEBUG:tensorflow:Apply dropout: True
DEBUG:tensorflow:==== Convolution Layer 1
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:==== Convolution Layer 2
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:==== Convolution Layer 3
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:==== Middle Convolution Layer 
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 8, 8, 512)
DEBUG:tensorflow:Using dropout_rate=0.150000
DEBUG:tensorflow:feature shape: (?, 8, 8, 512)
DEBUG:tensorflow:Using dropout_rate=0.150000
DEBUG:tensorflow:===== Convolution Transpose Layer 3
DEBUG:tensorflow:upconv shape: (?, 16, 16, 256)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:===== Convolution Transpose Layer 2
DEBUG:tensorflow:upconv shape: (?, 32, 32, 128)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:===== Convolution Transpose Layer 1
DEBUG:tensorflow:upconv shape: (?, 64, 64, 64)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:===== Final Convolution Layer 1
DEBUG:tensorflow:feature shape: (?, 64, 64, 2)
DEBUG:tensorflow:=====
DEBUG:tensorflow:Model output layer shape = (?, 64, 64, 2)
INFO:tensorflow:Total number of trainable model parameters = 7,699,712
DEBUG:tensorflow:Labels shape = (?, 64, 64, 1)
INFO:tensorflow:Preparing loss function metric: CrossEntropy
INFO:tensorflow:Creating AdamOptimizer with learning-rate = 0.001, and learning-rate decay rate = 1.0
DEBUG:tensorflow:num_iterations_per_epoch = 40.000000
DEBUG:tensorflow:opt_decay_steps = 40.000000
DEBUG:tensorflow:opt_moving_average = 1.000000
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Create CheckpointSaverHook.
INFO:tensorflow:Graph was finalized.
INFO:tensorflow:Restoring parameters from /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt-1480
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
INFO:tensorflow:Saving checkpoints for 1480 into /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt.
DEBUG:tensorflow:Training iteration 1480 / 4000 (37.00%)
INFO:tensorflow:loss = 0.048310127, step = 1480
DEBUG:tensorflow:Training iteration 1490 / 4000 (37.25%)
DEBUG:tensorflow:Training iteration 1500 / 4000 (37.50%)
DEBUG:tensorflow:Training iteration 1510 / 4000 (37.75%)
DEBUG:tensorflow:Training iteration 1520 / 4000 (38.00%)
INFO:tensorflow:Saving checkpoints for 1520 into /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt.
INFO:tensorflow:Loss for final step: 0.052742712.
INFO:tensorflow:
-----------------------------------------
-----
---- Training model...
-----
DEBUG:tensorflow:Train data: epoch size = 5120
DEBUG:tensorflow:Train data: batch size = 128
DEBUG:tensorflow:Train data: num_epochs = 100
DEBUG:tensorflow:Train data: patch_size: [64, 64, 7]
DEBUG:tensorflow:Train data: feature[0].shape: (5120, 64, 64, 7)
DEBUG:tensorflow:Train data: target[0].shape: (5120, 64, 64, 1)
INFO:tensorflow:Augmenting training data
INFO:tensorflow:Peformed 2572 flips
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:Creating model...
DEBUG:tensorflow:Stacked data shape: (?, 64, 64, 7)
DEBUG:tensorflow:Input data shape: (64, 64, 7)
DEBUG:tensorflow:Rectified input data shape: (?, 64, 64, 7)
DEBUG:tensorflow:===== Creating U-Net model: U-Net
DEBUG:tensorflow:Training: True
DEBUG:tensorflow:Apply dropout: True
DEBUG:tensorflow:==== Convolution Layer 1
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:==== Convolution Layer 2
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:==== Convolution Layer 3
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:==== Middle Convolution Layer 
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 8, 8, 512)
DEBUG:tensorflow:Using dropout_rate=0.150000
DEBUG:tensorflow:feature shape: (?, 8, 8, 512)
DEBUG:tensorflow:Using dropout_rate=0.150000
DEBUG:tensorflow:===== Convolution Transpose Layer 3
DEBUG:tensorflow:upconv shape: (?, 16, 16, 256)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:===== Convolution Transpose Layer 2
DEBUG:tensorflow:upconv shape: (?, 32, 32, 128)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:===== Convolution Transpose Layer 1
DEBUG:tensorflow:upconv shape: (?, 64, 64, 64)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:===== Final Convolution Layer 1
DEBUG:tensorflow:feature shape: (?, 64, 64, 2)
DEBUG:tensorflow:=====
DEBUG:tensorflow:Model output layer shape = (?, 64, 64, 2)
INFO:tensorflow:Total number of trainable model parameters = 7,699,712
DEBUG:tensorflow:Labels shape = (?, 64, 64, 1)
INFO:tensorflow:Preparing loss function metric: CrossEntropy
INFO:tensorflow:Creating AdamOptimizer with learning-rate = 0.001, and learning-rate decay rate = 1.0
DEBUG:tensorflow:num_iterations_per_epoch = 40.000000
DEBUG:tensorflow:opt_decay_steps = 40.000000
DEBUG:tensorflow:opt_moving_average = 1.000000
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Create CheckpointSaverHook.
INFO:tensorflow:Graph was finalized.
INFO:tensorflow:Restoring parameters from /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt-1520
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
INFO:tensorflow:Saving checkpoints for 1520 into /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt.
DEBUG:tensorflow:Training iteration 1520 / 4000 (38.00%)
INFO:tensorflow:loss = 0.05155631, step = 1520
DEBUG:tensorflow:Training iteration 1530 / 4000 (38.25%)
DEBUG:tensorflow:Training iteration 1540 / 4000 (38.50%)
DEBUG:tensorflow:Training iteration 1550 / 4000 (38.75%)
DEBUG:tensorflow:Training iteration 1560 / 4000 (39.00%)
INFO:tensorflow:Saving checkpoints for 1560 into /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt.
INFO:tensorflow:Loss for final step: 0.06739262.
INFO:tensorflow:
-----------------------------------------
-----
---- Training model...
-----
DEBUG:tensorflow:Train data: epoch size = 5120
DEBUG:tensorflow:Train data: batch size = 128
DEBUG:tensorflow:Train data: num_epochs = 100
DEBUG:tensorflow:Train data: patch_size: [64, 64, 7]
DEBUG:tensorflow:Train data: feature[0].shape: (5120, 64, 64, 7)
DEBUG:tensorflow:Train data: target[0].shape: (5120, 64, 64, 1)
INFO:tensorflow:Augmenting training data
INFO:tensorflow:Peformed 2523 flips
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:Creating model...
DEBUG:tensorflow:Stacked data shape: (?, 64, 64, 7)
DEBUG:tensorflow:Input data shape: (64, 64, 7)
DEBUG:tensorflow:Rectified input data shape: (?, 64, 64, 7)
DEBUG:tensorflow:===== Creating U-Net model: U-Net
DEBUG:tensorflow:Training: True
DEBUG:tensorflow:Apply dropout: True
DEBUG:tensorflow:==== Convolution Layer 1
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:==== Convolution Layer 2
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:==== Convolution Layer 3
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:==== Middle Convolution Layer 
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 8, 8, 512)
DEBUG:tensorflow:Using dropout_rate=0.150000
DEBUG:tensorflow:feature shape: (?, 8, 8, 512)
DEBUG:tensorflow:Using dropout_rate=0.150000
DEBUG:tensorflow:===== Convolution Transpose Layer 3
DEBUG:tensorflow:upconv shape: (?, 16, 16, 256)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:===== Convolution Transpose Layer 2
DEBUG:tensorflow:upconv shape: (?, 32, 32, 128)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:===== Convolution Transpose Layer 1
DEBUG:tensorflow:upconv shape: (?, 64, 64, 64)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:===== Final Convolution Layer 1
DEBUG:tensorflow:feature shape: (?, 64, 64, 2)
DEBUG:tensorflow:=====
DEBUG:tensorflow:Model output layer shape = (?, 64, 64, 2)
INFO:tensorflow:Total number of trainable model parameters = 7,699,712
DEBUG:tensorflow:Labels shape = (?, 64, 64, 1)
INFO:tensorflow:Preparing loss function metric: CrossEntropy
INFO:tensorflow:Creating AdamOptimizer with learning-rate = 0.001, and learning-rate decay rate = 1.0
DEBUG:tensorflow:num_iterations_per_epoch = 40.000000
DEBUG:tensorflow:opt_decay_steps = 40.000000
DEBUG:tensorflow:opt_moving_average = 1.000000
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Create CheckpointSaverHook.
INFO:tensorflow:Graph was finalized.
INFO:tensorflow:Restoring parameters from /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt-1560
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
INFO:tensorflow:Saving checkpoints for 1560 into /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt.
DEBUG:tensorflow:Training iteration 1560 / 4000 (39.00%)
INFO:tensorflow:loss = 0.0507911, step = 1560
DEBUG:tensorflow:Training iteration 1570 / 4000 (39.25%)
DEBUG:tensorflow:Training iteration 1580 / 4000 (39.50%)
DEBUG:tensorflow:Training iteration 1590 / 4000 (39.75%)
DEBUG:tensorflow:Training iteration 1600 / 4000 (40.00%)
INFO:tensorflow:Saving checkpoints for 1600 into /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt.
INFO:tensorflow:Loss for final step: 0.05212085.
INFO:tensorflow:
-----------------------------------------
-----
---- Training model...
-----
DEBUG:tensorflow:Train data: epoch size = 5120
DEBUG:tensorflow:Train data: batch size = 128
DEBUG:tensorflow:Train data: num_epochs = 100
DEBUG:tensorflow:Train data: patch_size: [64, 64, 7]
DEBUG:tensorflow:Train data: feature[0].shape: (5120, 64, 64, 7)
DEBUG:tensorflow:Train data: target[0].shape: (5120, 64, 64, 1)
INFO:tensorflow:Augmenting training data
INFO:tensorflow:Peformed 2574 flips
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:Creating model...
DEBUG:tensorflow:Stacked data shape: (?, 64, 64, 7)
DEBUG:tensorflow:Input data shape: (64, 64, 7)
DEBUG:tensorflow:Rectified input data shape: (?, 64, 64, 7)
DEBUG:tensorflow:===== Creating U-Net model: U-Net
DEBUG:tensorflow:Training: True
DEBUG:tensorflow:Apply dropout: True
DEBUG:tensorflow:==== Convolution Layer 1
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:==== Convolution Layer 2
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:==== Convolution Layer 3
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:==== Middle Convolution Layer 
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 8, 8, 512)
DEBUG:tensorflow:Using dropout_rate=0.150000
DEBUG:tensorflow:feature shape: (?, 8, 8, 512)
DEBUG:tensorflow:Using dropout_rate=0.150000
DEBUG:tensorflow:===== Convolution Transpose Layer 3
DEBUG:tensorflow:upconv shape: (?, 16, 16, 256)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:===== Convolution Transpose Layer 2
DEBUG:tensorflow:upconv shape: (?, 32, 32, 128)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:===== Convolution Transpose Layer 1
DEBUG:tensorflow:upconv shape: (?, 64, 64, 64)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:===== Final Convolution Layer 1
DEBUG:tensorflow:feature shape: (?, 64, 64, 2)
DEBUG:tensorflow:=====
DEBUG:tensorflow:Model output layer shape = (?, 64, 64, 2)
INFO:tensorflow:Total number of trainable model parameters = 7,699,712
DEBUG:tensorflow:Labels shape = (?, 64, 64, 1)
INFO:tensorflow:Preparing loss function metric: CrossEntropy
INFO:tensorflow:Creating AdamOptimizer with learning-rate = 0.001, and learning-rate decay rate = 1.0
DEBUG:tensorflow:num_iterations_per_epoch = 40.000000
DEBUG:tensorflow:opt_decay_steps = 40.000000
DEBUG:tensorflow:opt_moving_average = 1.000000
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Create CheckpointSaverHook.
INFO:tensorflow:Graph was finalized.
INFO:tensorflow:Restoring parameters from /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt-1600
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
INFO:tensorflow:Saving checkpoints for 1600 into /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt.
DEBUG:tensorflow:Training iteration 1600 / 4000 (40.00%)
INFO:tensorflow:loss = 0.04347476, step = 1600
DEBUG:tensorflow:Training iteration 1610 / 4000 (40.25%)
DEBUG:tensorflow:Training iteration 1620 / 4000 (40.50%)
DEBUG:tensorflow:Training iteration 1630 / 4000 (40.75%)
DEBUG:tensorflow:Training iteration 1640 / 4000 (41.00%)
INFO:tensorflow:Saving checkpoints for 1640 into /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt.
INFO:tensorflow:Loss for final step: 0.050337896.
INFO:tensorflow:
-----------------------------------------
-----
---- Training model...
-----
DEBUG:tensorflow:Train data: epoch size = 5120
DEBUG:tensorflow:Train data: batch size = 128
DEBUG:tensorflow:Train data: num_epochs = 100
DEBUG:tensorflow:Train data: patch_size: [64, 64, 7]
DEBUG:tensorflow:Train data: feature[0].shape: (5120, 64, 64, 7)
DEBUG:tensorflow:Train data: target[0].shape: (5120, 64, 64, 1)
INFO:tensorflow:Augmenting training data
INFO:tensorflow:Peformed 2570 flips
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:Creating model...
DEBUG:tensorflow:Stacked data shape: (?, 64, 64, 7)
DEBUG:tensorflow:Input data shape: (64, 64, 7)
DEBUG:tensorflow:Rectified input data shape: (?, 64, 64, 7)
DEBUG:tensorflow:===== Creating U-Net model: U-Net
DEBUG:tensorflow:Training: True
DEBUG:tensorflow:Apply dropout: True
DEBUG:tensorflow:==== Convolution Layer 1
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:==== Convolution Layer 2
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:==== Convolution Layer 3
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:==== Middle Convolution Layer 
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 8, 8, 512)
DEBUG:tensorflow:Using dropout_rate=0.150000
DEBUG:tensorflow:feature shape: (?, 8, 8, 512)
DEBUG:tensorflow:Using dropout_rate=0.150000
DEBUG:tensorflow:===== Convolution Transpose Layer 3
DEBUG:tensorflow:upconv shape: (?, 16, 16, 256)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:===== Convolution Transpose Layer 2
DEBUG:tensorflow:upconv shape: (?, 32, 32, 128)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:===== Convolution Transpose Layer 1
DEBUG:tensorflow:upconv shape: (?, 64, 64, 64)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:===== Final Convolution Layer 1
DEBUG:tensorflow:feature shape: (?, 64, 64, 2)
DEBUG:tensorflow:=====
DEBUG:tensorflow:Model output layer shape = (?, 64, 64, 2)
INFO:tensorflow:Total number of trainable model parameters = 7,699,712
DEBUG:tensorflow:Labels shape = (?, 64, 64, 1)
INFO:tensorflow:Preparing loss function metric: CrossEntropy
INFO:tensorflow:Creating AdamOptimizer with learning-rate = 0.001, and learning-rate decay rate = 1.0
DEBUG:tensorflow:num_iterations_per_epoch = 40.000000
DEBUG:tensorflow:opt_decay_steps = 40.000000
DEBUG:tensorflow:opt_moving_average = 1.000000
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Create CheckpointSaverHook.
INFO:tensorflow:Graph was finalized.
INFO:tensorflow:Restoring parameters from /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt-1640
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
INFO:tensorflow:Saving checkpoints for 1640 into /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt.
DEBUG:tensorflow:Training iteration 1640 / 4000 (41.00%)
INFO:tensorflow:loss = 0.053627726, step = 1640
DEBUG:tensorflow:Training iteration 1650 / 4000 (41.25%)
DEBUG:tensorflow:Training iteration 1660 / 4000 (41.50%)
DEBUG:tensorflow:Training iteration 1670 / 4000 (41.75%)
DEBUG:tensorflow:Training iteration 1680 / 4000 (42.00%)
INFO:tensorflow:Saving checkpoints for 1680 into /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt.
INFO:tensorflow:Loss for final step: 0.042034857.
INFO:tensorflow:
-----------------------------------------
-----
---- Training model...
-----
DEBUG:tensorflow:Train data: epoch size = 5120
DEBUG:tensorflow:Train data: batch size = 128
DEBUG:tensorflow:Train data: num_epochs = 100
DEBUG:tensorflow:Train data: patch_size: [64, 64, 7]
DEBUG:tensorflow:Train data: feature[0].shape: (5120, 64, 64, 7)
DEBUG:tensorflow:Train data: target[0].shape: (5120, 64, 64, 1)
INFO:tensorflow:Augmenting training data
INFO:tensorflow:Peformed 2542 flips
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:Creating model...
DEBUG:tensorflow:Stacked data shape: (?, 64, 64, 7)
DEBUG:tensorflow:Input data shape: (64, 64, 7)
DEBUG:tensorflow:Rectified input data shape: (?, 64, 64, 7)
DEBUG:tensorflow:===== Creating U-Net model: U-Net
DEBUG:tensorflow:Training: True
DEBUG:tensorflow:Apply dropout: True
DEBUG:tensorflow:==== Convolution Layer 1
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:==== Convolution Layer 2
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:==== Convolution Layer 3
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:==== Middle Convolution Layer 
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 8, 8, 512)
DEBUG:tensorflow:Using dropout_rate=0.150000
DEBUG:tensorflow:feature shape: (?, 8, 8, 512)
DEBUG:tensorflow:Using dropout_rate=0.150000
DEBUG:tensorflow:===== Convolution Transpose Layer 3
DEBUG:tensorflow:upconv shape: (?, 16, 16, 256)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:===== Convolution Transpose Layer 2
DEBUG:tensorflow:upconv shape: (?, 32, 32, 128)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:===== Convolution Transpose Layer 1
DEBUG:tensorflow:upconv shape: (?, 64, 64, 64)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:===== Final Convolution Layer 1
DEBUG:tensorflow:feature shape: (?, 64, 64, 2)
DEBUG:tensorflow:=====
DEBUG:tensorflow:Model output layer shape = (?, 64, 64, 2)
INFO:tensorflow:Total number of trainable model parameters = 7,699,712
DEBUG:tensorflow:Labels shape = (?, 64, 64, 1)
INFO:tensorflow:Preparing loss function metric: CrossEntropy
INFO:tensorflow:Creating AdamOptimizer with learning-rate = 0.001, and learning-rate decay rate = 1.0
DEBUG:tensorflow:num_iterations_per_epoch = 40.000000
DEBUG:tensorflow:opt_decay_steps = 40.000000
DEBUG:tensorflow:opt_moving_average = 1.000000
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Create CheckpointSaverHook.
INFO:tensorflow:Graph was finalized.
INFO:tensorflow:Restoring parameters from /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt-1680
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
INFO:tensorflow:Saving checkpoints for 1680 into /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt.
DEBUG:tensorflow:Training iteration 1680 / 4000 (42.00%)
INFO:tensorflow:loss = 0.034722198, step = 1680
DEBUG:tensorflow:Training iteration 1690 / 4000 (42.25%)
DEBUG:tensorflow:Training iteration 1700 / 4000 (42.50%)
DEBUG:tensorflow:Training iteration 1710 / 4000 (42.75%)
DEBUG:tensorflow:Training iteration 1720 / 4000 (43.00%)
INFO:tensorflow:Saving checkpoints for 1720 into /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt.
INFO:tensorflow:Loss for final step: 0.06215456.
INFO:tensorflow:
-----------------------------------------
-----
---- Training model...
-----
DEBUG:tensorflow:Train data: epoch size = 5120
DEBUG:tensorflow:Train data: batch size = 128
DEBUG:tensorflow:Train data: num_epochs = 100
DEBUG:tensorflow:Train data: patch_size: [64, 64, 7]
DEBUG:tensorflow:Train data: feature[0].shape: (5120, 64, 64, 7)
DEBUG:tensorflow:Train data: target[0].shape: (5120, 64, 64, 1)
INFO:tensorflow:Augmenting training data
INFO:tensorflow:Peformed 2550 flips
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:Creating model...
DEBUG:tensorflow:Stacked data shape: (?, 64, 64, 7)
DEBUG:tensorflow:Input data shape: (64, 64, 7)
DEBUG:tensorflow:Rectified input data shape: (?, 64, 64, 7)
DEBUG:tensorflow:===== Creating U-Net model: U-Net
DEBUG:tensorflow:Training: True
DEBUG:tensorflow:Apply dropout: True
DEBUG:tensorflow:==== Convolution Layer 1
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:==== Convolution Layer 2
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:==== Convolution Layer 3
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:==== Middle Convolution Layer 
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 8, 8, 512)
DEBUG:tensorflow:Using dropout_rate=0.150000
DEBUG:tensorflow:feature shape: (?, 8, 8, 512)
DEBUG:tensorflow:Using dropout_rate=0.150000
DEBUG:tensorflow:===== Convolution Transpose Layer 3
DEBUG:tensorflow:upconv shape: (?, 16, 16, 256)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:===== Convolution Transpose Layer 2
DEBUG:tensorflow:upconv shape: (?, 32, 32, 128)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:===== Convolution Transpose Layer 1
DEBUG:tensorflow:upconv shape: (?, 64, 64, 64)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:===== Final Convolution Layer 1
DEBUG:tensorflow:feature shape: (?, 64, 64, 2)
DEBUG:tensorflow:=====
DEBUG:tensorflow:Model output layer shape = (?, 64, 64, 2)
INFO:tensorflow:Total number of trainable model parameters = 7,699,712
DEBUG:tensorflow:Labels shape = (?, 64, 64, 1)
INFO:tensorflow:Preparing loss function metric: CrossEntropy
INFO:tensorflow:Creating AdamOptimizer with learning-rate = 0.001, and learning-rate decay rate = 1.0
DEBUG:tensorflow:num_iterations_per_epoch = 40.000000
DEBUG:tensorflow:opt_decay_steps = 40.000000
DEBUG:tensorflow:opt_moving_average = 1.000000
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Create CheckpointSaverHook.
INFO:tensorflow:Graph was finalized.
INFO:tensorflow:Restoring parameters from /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt-1720
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
INFO:tensorflow:Saving checkpoints for 1720 into /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt.
DEBUG:tensorflow:Training iteration 1720 / 4000 (43.00%)
INFO:tensorflow:loss = 0.054552928, step = 1720
DEBUG:tensorflow:Training iteration 1730 / 4000 (43.25%)
DEBUG:tensorflow:Training iteration 1740 / 4000 (43.50%)
DEBUG:tensorflow:Training iteration 1750 / 4000 (43.75%)
DEBUG:tensorflow:Training iteration 1760 / 4000 (44.00%)
INFO:tensorflow:Saving checkpoints for 1760 into /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt.
INFO:tensorflow:Loss for final step: 0.063302636.
INFO:tensorflow:
-----------------------------------------
-----
---- Training model...
-----
DEBUG:tensorflow:Train data: epoch size = 5120
DEBUG:tensorflow:Train data: batch size = 128
DEBUG:tensorflow:Train data: num_epochs = 100
DEBUG:tensorflow:Train data: patch_size: [64, 64, 7]
DEBUG:tensorflow:Train data: feature[0].shape: (5120, 64, 64, 7)
DEBUG:tensorflow:Train data: target[0].shape: (5120, 64, 64, 1)
INFO:tensorflow:Augmenting training data
INFO:tensorflow:Peformed 2524 flips
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:Creating model...
DEBUG:tensorflow:Stacked data shape: (?, 64, 64, 7)
DEBUG:tensorflow:Input data shape: (64, 64, 7)
DEBUG:tensorflow:Rectified input data shape: (?, 64, 64, 7)
DEBUG:tensorflow:===== Creating U-Net model: U-Net
DEBUG:tensorflow:Training: True
DEBUG:tensorflow:Apply dropout: True
DEBUG:tensorflow:==== Convolution Layer 1
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:==== Convolution Layer 2
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:==== Convolution Layer 3
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:==== Middle Convolution Layer 
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 8, 8, 512)
DEBUG:tensorflow:Using dropout_rate=0.150000
DEBUG:tensorflow:feature shape: (?, 8, 8, 512)
DEBUG:tensorflow:Using dropout_rate=0.150000
DEBUG:tensorflow:===== Convolution Transpose Layer 3
DEBUG:tensorflow:upconv shape: (?, 16, 16, 256)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:===== Convolution Transpose Layer 2
DEBUG:tensorflow:upconv shape: (?, 32, 32, 128)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:===== Convolution Transpose Layer 1
DEBUG:tensorflow:upconv shape: (?, 64, 64, 64)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:===== Final Convolution Layer 1
DEBUG:tensorflow:feature shape: (?, 64, 64, 2)
DEBUG:tensorflow:=====
DEBUG:tensorflow:Model output layer shape = (?, 64, 64, 2)
INFO:tensorflow:Total number of trainable model parameters = 7,699,712
DEBUG:tensorflow:Labels shape = (?, 64, 64, 1)
INFO:tensorflow:Preparing loss function metric: CrossEntropy
INFO:tensorflow:Creating AdamOptimizer with learning-rate = 0.001, and learning-rate decay rate = 1.0
DEBUG:tensorflow:num_iterations_per_epoch = 40.000000
DEBUG:tensorflow:opt_decay_steps = 40.000000
DEBUG:tensorflow:opt_moving_average = 1.000000
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Create CheckpointSaverHook.
INFO:tensorflow:Graph was finalized.
INFO:tensorflow:Restoring parameters from /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt-1760
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
INFO:tensorflow:Saving checkpoints for 1760 into /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt.
DEBUG:tensorflow:Training iteration 1760 / 4000 (44.00%)
INFO:tensorflow:loss = 0.06487679, step = 1760
DEBUG:tensorflow:Training iteration 1770 / 4000 (44.25%)
DEBUG:tensorflow:Training iteration 1780 / 4000 (44.50%)
DEBUG:tensorflow:Training iteration 1790 / 4000 (44.75%)
DEBUG:tensorflow:Training iteration 1800 / 4000 (45.00%)
INFO:tensorflow:Saving checkpoints for 1800 into /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt.
INFO:tensorflow:Loss for final step: 0.042203344.
INFO:tensorflow:
-----------------------------------------
-----
---- Training model...
-----
DEBUG:tensorflow:Train data: epoch size = 5120
DEBUG:tensorflow:Train data: batch size = 128
DEBUG:tensorflow:Train data: num_epochs = 100
DEBUG:tensorflow:Train data: patch_size: [64, 64, 7]
DEBUG:tensorflow:Train data: feature[0].shape: (5120, 64, 64, 7)
DEBUG:tensorflow:Train data: target[0].shape: (5120, 64, 64, 1)
INFO:tensorflow:Augmenting training data
INFO:tensorflow:Peformed 2537 flips
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:Creating model...
DEBUG:tensorflow:Stacked data shape: (?, 64, 64, 7)
DEBUG:tensorflow:Input data shape: (64, 64, 7)
DEBUG:tensorflow:Rectified input data shape: (?, 64, 64, 7)
DEBUG:tensorflow:===== Creating U-Net model: U-Net
DEBUG:tensorflow:Training: True
DEBUG:tensorflow:Apply dropout: True
DEBUG:tensorflow:==== Convolution Layer 1
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:==== Convolution Layer 2
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:==== Convolution Layer 3
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:==== Middle Convolution Layer 
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 8, 8, 512)
DEBUG:tensorflow:Using dropout_rate=0.150000
DEBUG:tensorflow:feature shape: (?, 8, 8, 512)
DEBUG:tensorflow:Using dropout_rate=0.150000
DEBUG:tensorflow:===== Convolution Transpose Layer 3
DEBUG:tensorflow:upconv shape: (?, 16, 16, 256)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:===== Convolution Transpose Layer 2
DEBUG:tensorflow:upconv shape: (?, 32, 32, 128)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:===== Convolution Transpose Layer 1
DEBUG:tensorflow:upconv shape: (?, 64, 64, 64)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:===== Final Convolution Layer 1
DEBUG:tensorflow:feature shape: (?, 64, 64, 2)
DEBUG:tensorflow:=====
DEBUG:tensorflow:Model output layer shape = (?, 64, 64, 2)
INFO:tensorflow:Total number of trainable model parameters = 7,699,712
DEBUG:tensorflow:Labels shape = (?, 64, 64, 1)
INFO:tensorflow:Preparing loss function metric: CrossEntropy
INFO:tensorflow:Creating AdamOptimizer with learning-rate = 0.001, and learning-rate decay rate = 1.0
DEBUG:tensorflow:num_iterations_per_epoch = 40.000000
DEBUG:tensorflow:opt_decay_steps = 40.000000
DEBUG:tensorflow:opt_moving_average = 1.000000
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Create CheckpointSaverHook.
INFO:tensorflow:Graph was finalized.
INFO:tensorflow:Restoring parameters from /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt-1800
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
INFO:tensorflow:Saving checkpoints for 1800 into /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt.
DEBUG:tensorflow:Training iteration 1800 / 4000 (45.00%)
INFO:tensorflow:loss = 0.0574143, step = 1800
DEBUG:tensorflow:Training iteration 1810 / 4000 (45.25%)
DEBUG:tensorflow:Training iteration 1820 / 4000 (45.50%)
DEBUG:tensorflow:Training iteration 1830 / 4000 (45.75%)
DEBUG:tensorflow:Training iteration 1840 / 4000 (46.00%)
INFO:tensorflow:Saving checkpoints for 1840 into /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt.
INFO:tensorflow:Loss for final step: 0.057856.
INFO:tensorflow:
-----------------------------------------
-----
---- Training model...
-----
DEBUG:tensorflow:Train data: epoch size = 5120
DEBUG:tensorflow:Train data: batch size = 128
DEBUG:tensorflow:Train data: num_epochs = 100
DEBUG:tensorflow:Train data: patch_size: [64, 64, 7]
DEBUG:tensorflow:Train data: feature[0].shape: (5120, 64, 64, 7)
DEBUG:tensorflow:Train data: target[0].shape: (5120, 64, 64, 1)
INFO:tensorflow:Augmenting training data
INFO:tensorflow:Peformed 2607 flips
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:Creating model...
DEBUG:tensorflow:Stacked data shape: (?, 64, 64, 7)
DEBUG:tensorflow:Input data shape: (64, 64, 7)
DEBUG:tensorflow:Rectified input data shape: (?, 64, 64, 7)
DEBUG:tensorflow:===== Creating U-Net model: U-Net
DEBUG:tensorflow:Training: True
DEBUG:tensorflow:Apply dropout: True
DEBUG:tensorflow:==== Convolution Layer 1
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:==== Convolution Layer 2
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:==== Convolution Layer 3
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:==== Middle Convolution Layer 
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 8, 8, 512)
DEBUG:tensorflow:Using dropout_rate=0.150000
DEBUG:tensorflow:feature shape: (?, 8, 8, 512)
DEBUG:tensorflow:Using dropout_rate=0.150000
DEBUG:tensorflow:===== Convolution Transpose Layer 3
DEBUG:tensorflow:upconv shape: (?, 16, 16, 256)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:===== Convolution Transpose Layer 2
DEBUG:tensorflow:upconv shape: (?, 32, 32, 128)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:===== Convolution Transpose Layer 1
DEBUG:tensorflow:upconv shape: (?, 64, 64, 64)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:===== Final Convolution Layer 1
DEBUG:tensorflow:feature shape: (?, 64, 64, 2)
DEBUG:tensorflow:=====
DEBUG:tensorflow:Model output layer shape = (?, 64, 64, 2)
INFO:tensorflow:Total number of trainable model parameters = 7,699,712
DEBUG:tensorflow:Labels shape = (?, 64, 64, 1)
INFO:tensorflow:Preparing loss function metric: CrossEntropy
INFO:tensorflow:Creating AdamOptimizer with learning-rate = 0.001, and learning-rate decay rate = 1.0
DEBUG:tensorflow:num_iterations_per_epoch = 40.000000
DEBUG:tensorflow:opt_decay_steps = 40.000000
DEBUG:tensorflow:opt_moving_average = 1.000000
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Create CheckpointSaverHook.
INFO:tensorflow:Graph was finalized.
INFO:tensorflow:Restoring parameters from /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt-1840
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
INFO:tensorflow:Saving checkpoints for 1840 into /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt.
DEBUG:tensorflow:Training iteration 1840 / 4000 (46.00%)
INFO:tensorflow:loss = 0.04170149, step = 1840
DEBUG:tensorflow:Training iteration 1850 / 4000 (46.25%)
DEBUG:tensorflow:Training iteration 1860 / 4000 (46.50%)
DEBUG:tensorflow:Training iteration 1870 / 4000 (46.75%)
DEBUG:tensorflow:Training iteration 1880 / 4000 (47.00%)
INFO:tensorflow:Saving checkpoints for 1880 into /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt.
INFO:tensorflow:Loss for final step: 0.067108005.
INFO:tensorflow:
-----------------------------------------
-----
---- Training model...
-----
DEBUG:tensorflow:Train data: epoch size = 5120
DEBUG:tensorflow:Train data: batch size = 128
DEBUG:tensorflow:Train data: num_epochs = 100
DEBUG:tensorflow:Train data: patch_size: [64, 64, 7]
DEBUG:tensorflow:Train data: feature[0].shape: (5120, 64, 64, 7)
DEBUG:tensorflow:Train data: target[0].shape: (5120, 64, 64, 1)
INFO:tensorflow:Augmenting training data
INFO:tensorflow:Peformed 2566 flips
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:Creating model...
DEBUG:tensorflow:Stacked data shape: (?, 64, 64, 7)
DEBUG:tensorflow:Input data shape: (64, 64, 7)
DEBUG:tensorflow:Rectified input data shape: (?, 64, 64, 7)
DEBUG:tensorflow:===== Creating U-Net model: U-Net
DEBUG:tensorflow:Training: True
DEBUG:tensorflow:Apply dropout: True
DEBUG:tensorflow:==== Convolution Layer 1
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:==== Convolution Layer 2
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:==== Convolution Layer 3
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:==== Middle Convolution Layer 
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 8, 8, 512)
DEBUG:tensorflow:Using dropout_rate=0.150000
DEBUG:tensorflow:feature shape: (?, 8, 8, 512)
DEBUG:tensorflow:Using dropout_rate=0.150000
DEBUG:tensorflow:===== Convolution Transpose Layer 3
DEBUG:tensorflow:upconv shape: (?, 16, 16, 256)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:===== Convolution Transpose Layer 2
DEBUG:tensorflow:upconv shape: (?, 32, 32, 128)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:===== Convolution Transpose Layer 1
DEBUG:tensorflow:upconv shape: (?, 64, 64, 64)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:===== Final Convolution Layer 1
DEBUG:tensorflow:feature shape: (?, 64, 64, 2)
DEBUG:tensorflow:=====
DEBUG:tensorflow:Model output layer shape = (?, 64, 64, 2)
INFO:tensorflow:Total number of trainable model parameters = 7,699,712
DEBUG:tensorflow:Labels shape = (?, 64, 64, 1)
INFO:tensorflow:Preparing loss function metric: CrossEntropy
INFO:tensorflow:Creating AdamOptimizer with learning-rate = 0.001, and learning-rate decay rate = 1.0
DEBUG:tensorflow:num_iterations_per_epoch = 40.000000
DEBUG:tensorflow:opt_decay_steps = 40.000000
DEBUG:tensorflow:opt_moving_average = 1.000000
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Create CheckpointSaverHook.
INFO:tensorflow:Graph was finalized.
INFO:tensorflow:Restoring parameters from /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt-1880
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
INFO:tensorflow:Saving checkpoints for 1880 into /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt.
DEBUG:tensorflow:Training iteration 1880 / 4000 (47.00%)
INFO:tensorflow:loss = 0.060870763, step = 1880
DEBUG:tensorflow:Training iteration 1890 / 4000 (47.25%)
DEBUG:tensorflow:Training iteration 1900 / 4000 (47.50%)
DEBUG:tensorflow:Training iteration 1910 / 4000 (47.75%)
DEBUG:tensorflow:Training iteration 1920 / 4000 (48.00%)
INFO:tensorflow:Saving checkpoints for 1920 into /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt.
INFO:tensorflow:Loss for final step: 0.049369942.
INFO:tensorflow:
-----------------------------------------
-----
---- Training model...
-----
DEBUG:tensorflow:Train data: epoch size = 5120
DEBUG:tensorflow:Train data: batch size = 128
DEBUG:tensorflow:Train data: num_epochs = 100
DEBUG:tensorflow:Train data: patch_size: [64, 64, 7]
DEBUG:tensorflow:Train data: feature[0].shape: (5120, 64, 64, 7)
DEBUG:tensorflow:Train data: target[0].shape: (5120, 64, 64, 1)
INFO:tensorflow:Augmenting training data
INFO:tensorflow:Peformed 2590 flips
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:Creating model...
DEBUG:tensorflow:Stacked data shape: (?, 64, 64, 7)
DEBUG:tensorflow:Input data shape: (64, 64, 7)
DEBUG:tensorflow:Rectified input data shape: (?, 64, 64, 7)
DEBUG:tensorflow:===== Creating U-Net model: U-Net
DEBUG:tensorflow:Training: True
DEBUG:tensorflow:Apply dropout: True
DEBUG:tensorflow:==== Convolution Layer 1
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:==== Convolution Layer 2
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:==== Convolution Layer 3
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:==== Middle Convolution Layer 
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 8, 8, 512)
DEBUG:tensorflow:Using dropout_rate=0.150000
DEBUG:tensorflow:feature shape: (?, 8, 8, 512)
DEBUG:tensorflow:Using dropout_rate=0.150000
DEBUG:tensorflow:===== Convolution Transpose Layer 3
DEBUG:tensorflow:upconv shape: (?, 16, 16, 256)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:===== Convolution Transpose Layer 2
DEBUG:tensorflow:upconv shape: (?, 32, 32, 128)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:===== Convolution Transpose Layer 1
DEBUG:tensorflow:upconv shape: (?, 64, 64, 64)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:===== Final Convolution Layer 1
DEBUG:tensorflow:feature shape: (?, 64, 64, 2)
DEBUG:tensorflow:=====
DEBUG:tensorflow:Model output layer shape = (?, 64, 64, 2)
INFO:tensorflow:Total number of trainable model parameters = 7,699,712
DEBUG:tensorflow:Labels shape = (?, 64, 64, 1)
INFO:tensorflow:Preparing loss function metric: CrossEntropy
INFO:tensorflow:Creating AdamOptimizer with learning-rate = 0.001, and learning-rate decay rate = 1.0
DEBUG:tensorflow:num_iterations_per_epoch = 40.000000
DEBUG:tensorflow:opt_decay_steps = 40.000000
DEBUG:tensorflow:opt_moving_average = 1.000000
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Create CheckpointSaverHook.
INFO:tensorflow:Graph was finalized.
INFO:tensorflow:Restoring parameters from /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt-1920
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
INFO:tensorflow:Saving checkpoints for 1920 into /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt.
DEBUG:tensorflow:Training iteration 1920 / 4000 (48.00%)
INFO:tensorflow:loss = 0.037693046, step = 1920
DEBUG:tensorflow:Training iteration 1930 / 4000 (48.25%)
DEBUG:tensorflow:Training iteration 1940 / 4000 (48.50%)
DEBUG:tensorflow:Training iteration 1950 / 4000 (48.75%)
DEBUG:tensorflow:Training iteration 1960 / 4000 (49.00%)
INFO:tensorflow:Saving checkpoints for 1960 into /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt.
INFO:tensorflow:Loss for final step: 0.037816003.
INFO:tensorflow:
-----------------------------------------
-----
---- Training model...
-----
DEBUG:tensorflow:Train data: epoch size = 5120
DEBUG:tensorflow:Train data: batch size = 128
DEBUG:tensorflow:Train data: num_epochs = 100
DEBUG:tensorflow:Train data: patch_size: [64, 64, 7]
DEBUG:tensorflow:Train data: feature[0].shape: (5120, 64, 64, 7)
DEBUG:tensorflow:Train data: target[0].shape: (5120, 64, 64, 1)
INFO:tensorflow:Augmenting training data
INFO:tensorflow:Peformed 2565 flips
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:Creating model...
DEBUG:tensorflow:Stacked data shape: (?, 64, 64, 7)
DEBUG:tensorflow:Input data shape: (64, 64, 7)
DEBUG:tensorflow:Rectified input data shape: (?, 64, 64, 7)
DEBUG:tensorflow:===== Creating U-Net model: U-Net
DEBUG:tensorflow:Training: True
DEBUG:tensorflow:Apply dropout: True
DEBUG:tensorflow:==== Convolution Layer 1
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:==== Convolution Layer 2
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:==== Convolution Layer 3
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:==== Middle Convolution Layer 
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 8, 8, 512)
DEBUG:tensorflow:Using dropout_rate=0.150000
DEBUG:tensorflow:feature shape: (?, 8, 8, 512)
DEBUG:tensorflow:Using dropout_rate=0.150000
DEBUG:tensorflow:===== Convolution Transpose Layer 3
DEBUG:tensorflow:upconv shape: (?, 16, 16, 256)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:===== Convolution Transpose Layer 2
DEBUG:tensorflow:upconv shape: (?, 32, 32, 128)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:===== Convolution Transpose Layer 1
DEBUG:tensorflow:upconv shape: (?, 64, 64, 64)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:===== Final Convolution Layer 1
DEBUG:tensorflow:feature shape: (?, 64, 64, 2)
DEBUG:tensorflow:=====
DEBUG:tensorflow:Model output layer shape = (?, 64, 64, 2)
INFO:tensorflow:Total number of trainable model parameters = 7,699,712
DEBUG:tensorflow:Labels shape = (?, 64, 64, 1)
INFO:tensorflow:Preparing loss function metric: CrossEntropy
INFO:tensorflow:Creating AdamOptimizer with learning-rate = 0.001, and learning-rate decay rate = 1.0
DEBUG:tensorflow:num_iterations_per_epoch = 40.000000
DEBUG:tensorflow:opt_decay_steps = 40.000000
DEBUG:tensorflow:opt_moving_average = 1.000000
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Create CheckpointSaverHook.
INFO:tensorflow:Graph was finalized.
INFO:tensorflow:Restoring parameters from /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt-1960
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
INFO:tensorflow:Saving checkpoints for 1960 into /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt.
DEBUG:tensorflow:Training iteration 1960 / 4000 (49.00%)
INFO:tensorflow:loss = 0.04574018, step = 1960
DEBUG:tensorflow:Training iteration 1970 / 4000 (49.25%)
DEBUG:tensorflow:Training iteration 1980 / 4000 (49.50%)
DEBUG:tensorflow:Training iteration 1990 / 4000 (49.75%)
DEBUG:tensorflow:Training iteration 2000 / 4000 (50.00%)
INFO:tensorflow:Saving checkpoints for 2000 into /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt.
INFO:tensorflow:Loss for final step: 0.05112703.
INFO:tensorflow:
-----------------------------------------
-----
---- Training model...
-----
DEBUG:tensorflow:Train data: epoch size = 5120
DEBUG:tensorflow:Train data: batch size = 128
DEBUG:tensorflow:Train data: num_epochs = 100
DEBUG:tensorflow:Train data: patch_size: [64, 64, 7]
DEBUG:tensorflow:Train data: feature[0].shape: (5120, 64, 64, 7)
DEBUG:tensorflow:Train data: target[0].shape: (5120, 64, 64, 1)
INFO:tensorflow:Augmenting training data
INFO:tensorflow:Peformed 2554 flips
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:Creating model...
DEBUG:tensorflow:Stacked data shape: (?, 64, 64, 7)
DEBUG:tensorflow:Input data shape: (64, 64, 7)
DEBUG:tensorflow:Rectified input data shape: (?, 64, 64, 7)
DEBUG:tensorflow:===== Creating U-Net model: U-Net
DEBUG:tensorflow:Training: True
DEBUG:tensorflow:Apply dropout: True
DEBUG:tensorflow:==== Convolution Layer 1
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:==== Convolution Layer 2
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:==== Convolution Layer 3
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:==== Middle Convolution Layer 
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 8, 8, 512)
DEBUG:tensorflow:Using dropout_rate=0.150000
DEBUG:tensorflow:feature shape: (?, 8, 8, 512)
DEBUG:tensorflow:Using dropout_rate=0.150000
DEBUG:tensorflow:===== Convolution Transpose Layer 3
DEBUG:tensorflow:upconv shape: (?, 16, 16, 256)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:===== Convolution Transpose Layer 2
DEBUG:tensorflow:upconv shape: (?, 32, 32, 128)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:===== Convolution Transpose Layer 1
DEBUG:tensorflow:upconv shape: (?, 64, 64, 64)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:===== Final Convolution Layer 1
DEBUG:tensorflow:feature shape: (?, 64, 64, 2)
DEBUG:tensorflow:=====
DEBUG:tensorflow:Model output layer shape = (?, 64, 64, 2)
INFO:tensorflow:Total number of trainable model parameters = 7,699,712
DEBUG:tensorflow:Labels shape = (?, 64, 64, 1)
INFO:tensorflow:Preparing loss function metric: CrossEntropy
INFO:tensorflow:Creating AdamOptimizer with learning-rate = 0.001, and learning-rate decay rate = 1.0
DEBUG:tensorflow:num_iterations_per_epoch = 40.000000
DEBUG:tensorflow:opt_decay_steps = 40.000000
DEBUG:tensorflow:opt_moving_average = 1.000000
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Create CheckpointSaverHook.
INFO:tensorflow:Graph was finalized.
INFO:tensorflow:Restoring parameters from /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt-2000
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
INFO:tensorflow:Saving checkpoints for 2000 into /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt.
DEBUG:tensorflow:Training iteration 2000 / 4000 (50.00%)
INFO:tensorflow:loss = 0.043899372, step = 2000
DEBUG:tensorflow:Training iteration 2010 / 4000 (50.25%)
DEBUG:tensorflow:Training iteration 2020 / 4000 (50.50%)
DEBUG:tensorflow:Training iteration 2030 / 4000 (50.75%)
DEBUG:tensorflow:Training iteration 2040 / 4000 (51.00%)
INFO:tensorflow:Saving checkpoints for 2040 into /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt.
INFO:tensorflow:Loss for final step: 0.037970766.
INFO:tensorflow:
-----------------------------------------
-----
---- Training model...
-----
DEBUG:tensorflow:Train data: epoch size = 5120
DEBUG:tensorflow:Train data: batch size = 128
DEBUG:tensorflow:Train data: num_epochs = 100
DEBUG:tensorflow:Train data: patch_size: [64, 64, 7]
DEBUG:tensorflow:Train data: feature[0].shape: (5120, 64, 64, 7)
DEBUG:tensorflow:Train data: target[0].shape: (5120, 64, 64, 1)
INFO:tensorflow:Augmenting training data
INFO:tensorflow:Peformed 2506 flips
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:Creating model...
DEBUG:tensorflow:Stacked data shape: (?, 64, 64, 7)
DEBUG:tensorflow:Input data shape: (64, 64, 7)
DEBUG:tensorflow:Rectified input data shape: (?, 64, 64, 7)
DEBUG:tensorflow:===== Creating U-Net model: U-Net
DEBUG:tensorflow:Training: True
DEBUG:tensorflow:Apply dropout: True
DEBUG:tensorflow:==== Convolution Layer 1
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:==== Convolution Layer 2
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:==== Convolution Layer 3
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:==== Middle Convolution Layer 
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 8, 8, 512)
DEBUG:tensorflow:Using dropout_rate=0.150000
DEBUG:tensorflow:feature shape: (?, 8, 8, 512)
DEBUG:tensorflow:Using dropout_rate=0.150000
DEBUG:tensorflow:===== Convolution Transpose Layer 3
DEBUG:tensorflow:upconv shape: (?, 16, 16, 256)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:===== Convolution Transpose Layer 2
DEBUG:tensorflow:upconv shape: (?, 32, 32, 128)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:===== Convolution Transpose Layer 1
DEBUG:tensorflow:upconv shape: (?, 64, 64, 64)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:===== Final Convolution Layer 1
DEBUG:tensorflow:feature shape: (?, 64, 64, 2)
DEBUG:tensorflow:=====
DEBUG:tensorflow:Model output layer shape = (?, 64, 64, 2)
INFO:tensorflow:Total number of trainable model parameters = 7,699,712
DEBUG:tensorflow:Labels shape = (?, 64, 64, 1)
INFO:tensorflow:Preparing loss function metric: CrossEntropy
INFO:tensorflow:Creating AdamOptimizer with learning-rate = 0.001, and learning-rate decay rate = 1.0
DEBUG:tensorflow:num_iterations_per_epoch = 40.000000
DEBUG:tensorflow:opt_decay_steps = 40.000000
DEBUG:tensorflow:opt_moving_average = 1.000000
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Create CheckpointSaverHook.
INFO:tensorflow:Graph was finalized.
INFO:tensorflow:Restoring parameters from /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt-2040
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
INFO:tensorflow:Saving checkpoints for 2040 into /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt.
DEBUG:tensorflow:Training iteration 2040 / 4000 (51.00%)
INFO:tensorflow:loss = 0.060329296, step = 2040
DEBUG:tensorflow:Training iteration 2050 / 4000 (51.25%)
DEBUG:tensorflow:Training iteration 2060 / 4000 (51.50%)
DEBUG:tensorflow:Training iteration 2070 / 4000 (51.75%)
DEBUG:tensorflow:Training iteration 2080 / 4000 (52.00%)
INFO:tensorflow:Saving checkpoints for 2080 into /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt.
INFO:tensorflow:Loss for final step: 0.03828126.
INFO:tensorflow:
-----------------------------------------
-----
---- Training model...
-----
DEBUG:tensorflow:Train data: epoch size = 5120
DEBUG:tensorflow:Train data: batch size = 128
DEBUG:tensorflow:Train data: num_epochs = 100
DEBUG:tensorflow:Train data: patch_size: [64, 64, 7]
DEBUG:tensorflow:Train data: feature[0].shape: (5120, 64, 64, 7)
DEBUG:tensorflow:Train data: target[0].shape: (5120, 64, 64, 1)
INFO:tensorflow:Augmenting training data
INFO:tensorflow:Peformed 2592 flips
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:Creating model...
DEBUG:tensorflow:Stacked data shape: (?, 64, 64, 7)
DEBUG:tensorflow:Input data shape: (64, 64, 7)
DEBUG:tensorflow:Rectified input data shape: (?, 64, 64, 7)
DEBUG:tensorflow:===== Creating U-Net model: U-Net
DEBUG:tensorflow:Training: True
DEBUG:tensorflow:Apply dropout: True
DEBUG:tensorflow:==== Convolution Layer 1
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:==== Convolution Layer 2
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:==== Convolution Layer 3
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:==== Middle Convolution Layer 
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 8, 8, 512)
DEBUG:tensorflow:Using dropout_rate=0.150000
DEBUG:tensorflow:feature shape: (?, 8, 8, 512)
DEBUG:tensorflow:Using dropout_rate=0.150000
DEBUG:tensorflow:===== Convolution Transpose Layer 3
DEBUG:tensorflow:upconv shape: (?, 16, 16, 256)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:===== Convolution Transpose Layer 2
DEBUG:tensorflow:upconv shape: (?, 32, 32, 128)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:===== Convolution Transpose Layer 1
DEBUG:tensorflow:upconv shape: (?, 64, 64, 64)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:===== Final Convolution Layer 1
DEBUG:tensorflow:feature shape: (?, 64, 64, 2)
DEBUG:tensorflow:=====
DEBUG:tensorflow:Model output layer shape = (?, 64, 64, 2)
INFO:tensorflow:Total number of trainable model parameters = 7,699,712
DEBUG:tensorflow:Labels shape = (?, 64, 64, 1)
INFO:tensorflow:Preparing loss function metric: CrossEntropy
INFO:tensorflow:Creating AdamOptimizer with learning-rate = 0.001, and learning-rate decay rate = 1.0
DEBUG:tensorflow:num_iterations_per_epoch = 40.000000
DEBUG:tensorflow:opt_decay_steps = 40.000000
DEBUG:tensorflow:opt_moving_average = 1.000000
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Create CheckpointSaverHook.
INFO:tensorflow:Graph was finalized.
INFO:tensorflow:Restoring parameters from /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt-2080
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
INFO:tensorflow:Saving checkpoints for 2080 into /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt.
DEBUG:tensorflow:Training iteration 2080 / 4000 (52.00%)
INFO:tensorflow:loss = 0.073827, step = 2080
DEBUG:tensorflow:Training iteration 2090 / 4000 (52.25%)
DEBUG:tensorflow:Training iteration 2100 / 4000 (52.50%)
DEBUG:tensorflow:Training iteration 2110 / 4000 (52.75%)
DEBUG:tensorflow:Training iteration 2120 / 4000 (53.00%)
INFO:tensorflow:Saving checkpoints for 2120 into /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt.
INFO:tensorflow:Loss for final step: 0.044938788.
INFO:tensorflow:
-----------------------------------------
-----
---- Training model...
-----
DEBUG:tensorflow:Train data: epoch size = 5120
DEBUG:tensorflow:Train data: batch size = 128
DEBUG:tensorflow:Train data: num_epochs = 100
DEBUG:tensorflow:Train data: patch_size: [64, 64, 7]
DEBUG:tensorflow:Train data: feature[0].shape: (5120, 64, 64, 7)
DEBUG:tensorflow:Train data: target[0].shape: (5120, 64, 64, 1)
INFO:tensorflow:Augmenting training data
INFO:tensorflow:Peformed 2490 flips
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:Creating model...
DEBUG:tensorflow:Stacked data shape: (?, 64, 64, 7)
DEBUG:tensorflow:Input data shape: (64, 64, 7)
DEBUG:tensorflow:Rectified input data shape: (?, 64, 64, 7)
DEBUG:tensorflow:===== Creating U-Net model: U-Net
DEBUG:tensorflow:Training: True
DEBUG:tensorflow:Apply dropout: True
DEBUG:tensorflow:==== Convolution Layer 1
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:==== Convolution Layer 2
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:==== Convolution Layer 3
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:==== Middle Convolution Layer 
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 8, 8, 512)
DEBUG:tensorflow:Using dropout_rate=0.150000
DEBUG:tensorflow:feature shape: (?, 8, 8, 512)
DEBUG:tensorflow:Using dropout_rate=0.150000
DEBUG:tensorflow:===== Convolution Transpose Layer 3
DEBUG:tensorflow:upconv shape: (?, 16, 16, 256)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:===== Convolution Transpose Layer 2
DEBUG:tensorflow:upconv shape: (?, 32, 32, 128)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:===== Convolution Transpose Layer 1
DEBUG:tensorflow:upconv shape: (?, 64, 64, 64)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:===== Final Convolution Layer 1
DEBUG:tensorflow:feature shape: (?, 64, 64, 2)
DEBUG:tensorflow:=====
DEBUG:tensorflow:Model output layer shape = (?, 64, 64, 2)
INFO:tensorflow:Total number of trainable model parameters = 7,699,712
DEBUG:tensorflow:Labels shape = (?, 64, 64, 1)
INFO:tensorflow:Preparing loss function metric: CrossEntropy
INFO:tensorflow:Creating AdamOptimizer with learning-rate = 0.001, and learning-rate decay rate = 1.0
DEBUG:tensorflow:num_iterations_per_epoch = 40.000000
DEBUG:tensorflow:opt_decay_steps = 40.000000
DEBUG:tensorflow:opt_moving_average = 1.000000
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Create CheckpointSaverHook.
INFO:tensorflow:Graph was finalized.
INFO:tensorflow:Restoring parameters from /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt-2120
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
INFO:tensorflow:Saving checkpoints for 2120 into /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt.
DEBUG:tensorflow:Training iteration 2120 / 4000 (53.00%)
INFO:tensorflow:loss = 0.05401603, step = 2120
DEBUG:tensorflow:Training iteration 2130 / 4000 (53.25%)
DEBUG:tensorflow:Training iteration 2140 / 4000 (53.50%)
DEBUG:tensorflow:Training iteration 2150 / 4000 (53.75%)
DEBUG:tensorflow:Training iteration 2160 / 4000 (54.00%)
INFO:tensorflow:Saving checkpoints for 2160 into /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt.
INFO:tensorflow:Loss for final step: 0.05772095.
INFO:tensorflow:
-----------------------------------------
-----
---- Training model...
-----
DEBUG:tensorflow:Train data: epoch size = 5120
DEBUG:tensorflow:Train data: batch size = 128
DEBUG:tensorflow:Train data: num_epochs = 100
DEBUG:tensorflow:Train data: patch_size: [64, 64, 7]
DEBUG:tensorflow:Train data: feature[0].shape: (5120, 64, 64, 7)
DEBUG:tensorflow:Train data: target[0].shape: (5120, 64, 64, 1)
INFO:tensorflow:Augmenting training data
INFO:tensorflow:Peformed 2540 flips
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:Creating model...
DEBUG:tensorflow:Stacked data shape: (?, 64, 64, 7)
DEBUG:tensorflow:Input data shape: (64, 64, 7)
DEBUG:tensorflow:Rectified input data shape: (?, 64, 64, 7)
DEBUG:tensorflow:===== Creating U-Net model: U-Net
DEBUG:tensorflow:Training: True
DEBUG:tensorflow:Apply dropout: True
DEBUG:tensorflow:==== Convolution Layer 1
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:==== Convolution Layer 2
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:==== Convolution Layer 3
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:==== Middle Convolution Layer 
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 8, 8, 512)
DEBUG:tensorflow:Using dropout_rate=0.150000
DEBUG:tensorflow:feature shape: (?, 8, 8, 512)
DEBUG:tensorflow:Using dropout_rate=0.150000
DEBUG:tensorflow:===== Convolution Transpose Layer 3
DEBUG:tensorflow:upconv shape: (?, 16, 16, 256)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:===== Convolution Transpose Layer 2
DEBUG:tensorflow:upconv shape: (?, 32, 32, 128)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:===== Convolution Transpose Layer 1
DEBUG:tensorflow:upconv shape: (?, 64, 64, 64)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:===== Final Convolution Layer 1
DEBUG:tensorflow:feature shape: (?, 64, 64, 2)
DEBUG:tensorflow:=====
DEBUG:tensorflow:Model output layer shape = (?, 64, 64, 2)
INFO:tensorflow:Total number of trainable model parameters = 7,699,712
DEBUG:tensorflow:Labels shape = (?, 64, 64, 1)
INFO:tensorflow:Preparing loss function metric: CrossEntropy
INFO:tensorflow:Creating AdamOptimizer with learning-rate = 0.001, and learning-rate decay rate = 1.0
DEBUG:tensorflow:num_iterations_per_epoch = 40.000000
DEBUG:tensorflow:opt_decay_steps = 40.000000
DEBUG:tensorflow:opt_moving_average = 1.000000
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Create CheckpointSaverHook.
INFO:tensorflow:Graph was finalized.
INFO:tensorflow:Restoring parameters from /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt-2160
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
INFO:tensorflow:Saving checkpoints for 2160 into /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt.
DEBUG:tensorflow:Training iteration 2160 / 4000 (54.00%)
INFO:tensorflow:loss = 0.04000703, step = 2160
DEBUG:tensorflow:Training iteration 2170 / 4000 (54.25%)
DEBUG:tensorflow:Training iteration 2180 / 4000 (54.50%)
DEBUG:tensorflow:Training iteration 2190 / 4000 (54.75%)
DEBUG:tensorflow:Training iteration 2200 / 4000 (55.00%)
INFO:tensorflow:Saving checkpoints for 2200 into /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt.
INFO:tensorflow:Loss for final step: 0.04473769.
INFO:tensorflow:
-----------------------------------------
-----
---- Training model...
-----
DEBUG:tensorflow:Train data: epoch size = 5120
DEBUG:tensorflow:Train data: batch size = 128
DEBUG:tensorflow:Train data: num_epochs = 100
DEBUG:tensorflow:Train data: patch_size: [64, 64, 7]
DEBUG:tensorflow:Train data: feature[0].shape: (5120, 64, 64, 7)
DEBUG:tensorflow:Train data: target[0].shape: (5120, 64, 64, 1)
INFO:tensorflow:Augmenting training data
INFO:tensorflow:Peformed 2510 flips
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:Creating model...
DEBUG:tensorflow:Stacked data shape: (?, 64, 64, 7)
DEBUG:tensorflow:Input data shape: (64, 64, 7)
DEBUG:tensorflow:Rectified input data shape: (?, 64, 64, 7)
DEBUG:tensorflow:===== Creating U-Net model: U-Net
DEBUG:tensorflow:Training: True
DEBUG:tensorflow:Apply dropout: True
DEBUG:tensorflow:==== Convolution Layer 1
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:==== Convolution Layer 2
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:==== Convolution Layer 3
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:==== Middle Convolution Layer 
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 8, 8, 512)
DEBUG:tensorflow:Using dropout_rate=0.150000
DEBUG:tensorflow:feature shape: (?, 8, 8, 512)
DEBUG:tensorflow:Using dropout_rate=0.150000
DEBUG:tensorflow:===== Convolution Transpose Layer 3
DEBUG:tensorflow:upconv shape: (?, 16, 16, 256)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:===== Convolution Transpose Layer 2
DEBUG:tensorflow:upconv shape: (?, 32, 32, 128)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:===== Convolution Transpose Layer 1
DEBUG:tensorflow:upconv shape: (?, 64, 64, 64)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:===== Final Convolution Layer 1
DEBUG:tensorflow:feature shape: (?, 64, 64, 2)
DEBUG:tensorflow:=====
DEBUG:tensorflow:Model output layer shape = (?, 64, 64, 2)
INFO:tensorflow:Total number of trainable model parameters = 7,699,712
DEBUG:tensorflow:Labels shape = (?, 64, 64, 1)
INFO:tensorflow:Preparing loss function metric: CrossEntropy
INFO:tensorflow:Creating AdamOptimizer with learning-rate = 0.001, and learning-rate decay rate = 1.0
DEBUG:tensorflow:num_iterations_per_epoch = 40.000000
DEBUG:tensorflow:opt_decay_steps = 40.000000
DEBUG:tensorflow:opt_moving_average = 1.000000
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Create CheckpointSaverHook.
INFO:tensorflow:Graph was finalized.
INFO:tensorflow:Restoring parameters from /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt-2200
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
INFO:tensorflow:Saving checkpoints for 2200 into /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt.
DEBUG:tensorflow:Training iteration 2200 / 4000 (55.00%)
INFO:tensorflow:loss = 0.051441584, step = 2200
DEBUG:tensorflow:Training iteration 2210 / 4000 (55.25%)
DEBUG:tensorflow:Training iteration 2220 / 4000 (55.50%)
DEBUG:tensorflow:Training iteration 2230 / 4000 (55.75%)
DEBUG:tensorflow:Training iteration 2240 / 4000 (56.00%)
INFO:tensorflow:Saving checkpoints for 2240 into /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt.
INFO:tensorflow:Loss for final step: 0.048758827.
INFO:tensorflow:
-----------------------------------------
-----
---- Training model...
-----
DEBUG:tensorflow:Train data: epoch size = 5120
DEBUG:tensorflow:Train data: batch size = 128
DEBUG:tensorflow:Train data: num_epochs = 100
DEBUG:tensorflow:Train data: patch_size: [64, 64, 7]
DEBUG:tensorflow:Train data: feature[0].shape: (5120, 64, 64, 7)
DEBUG:tensorflow:Train data: target[0].shape: (5120, 64, 64, 1)
INFO:tensorflow:Augmenting training data
INFO:tensorflow:Peformed 2582 flips
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:Creating model...
DEBUG:tensorflow:Stacked data shape: (?, 64, 64, 7)
DEBUG:tensorflow:Input data shape: (64, 64, 7)
DEBUG:tensorflow:Rectified input data shape: (?, 64, 64, 7)
DEBUG:tensorflow:===== Creating U-Net model: U-Net
DEBUG:tensorflow:Training: True
DEBUG:tensorflow:Apply dropout: True
DEBUG:tensorflow:==== Convolution Layer 1
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:==== Convolution Layer 2
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:==== Convolution Layer 3
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:==== Middle Convolution Layer 
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 8, 8, 512)
DEBUG:tensorflow:Using dropout_rate=0.150000
DEBUG:tensorflow:feature shape: (?, 8, 8, 512)
DEBUG:tensorflow:Using dropout_rate=0.150000
DEBUG:tensorflow:===== Convolution Transpose Layer 3
DEBUG:tensorflow:upconv shape: (?, 16, 16, 256)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:===== Convolution Transpose Layer 2
DEBUG:tensorflow:upconv shape: (?, 32, 32, 128)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:===== Convolution Transpose Layer 1
DEBUG:tensorflow:upconv shape: (?, 64, 64, 64)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:===== Final Convolution Layer 1
DEBUG:tensorflow:feature shape: (?, 64, 64, 2)
DEBUG:tensorflow:=====
DEBUG:tensorflow:Model output layer shape = (?, 64, 64, 2)
INFO:tensorflow:Total number of trainable model parameters = 7,699,712
DEBUG:tensorflow:Labels shape = (?, 64, 64, 1)
INFO:tensorflow:Preparing loss function metric: CrossEntropy
INFO:tensorflow:Creating AdamOptimizer with learning-rate = 0.001, and learning-rate decay rate = 1.0
DEBUG:tensorflow:num_iterations_per_epoch = 40.000000
DEBUG:tensorflow:opt_decay_steps = 40.000000
DEBUG:tensorflow:opt_moving_average = 1.000000
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Create CheckpointSaverHook.
INFO:tensorflow:Graph was finalized.
INFO:tensorflow:Restoring parameters from /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt-2240
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
INFO:tensorflow:Saving checkpoints for 2240 into /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt.
DEBUG:tensorflow:Training iteration 2240 / 4000 (56.00%)
INFO:tensorflow:loss = 0.048682433, step = 2240
DEBUG:tensorflow:Training iteration 2250 / 4000 (56.25%)
DEBUG:tensorflow:Training iteration 2260 / 4000 (56.50%)
DEBUG:tensorflow:Training iteration 2270 / 4000 (56.75%)
DEBUG:tensorflow:Training iteration 2280 / 4000 (57.00%)
INFO:tensorflow:Saving checkpoints for 2280 into /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt.
INFO:tensorflow:Loss for final step: 0.04729817.
INFO:tensorflow:
-----------------------------------------
-----
---- Training model...
-----
DEBUG:tensorflow:Train data: epoch size = 5120
DEBUG:tensorflow:Train data: batch size = 128
DEBUG:tensorflow:Train data: num_epochs = 100
DEBUG:tensorflow:Train data: patch_size: [64, 64, 7]
DEBUG:tensorflow:Train data: feature[0].shape: (5120, 64, 64, 7)
DEBUG:tensorflow:Train data: target[0].shape: (5120, 64, 64, 1)
INFO:tensorflow:Augmenting training data
INFO:tensorflow:Peformed 2615 flips
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:Creating model...
DEBUG:tensorflow:Stacked data shape: (?, 64, 64, 7)
DEBUG:tensorflow:Input data shape: (64, 64, 7)
DEBUG:tensorflow:Rectified input data shape: (?, 64, 64, 7)
DEBUG:tensorflow:===== Creating U-Net model: U-Net
DEBUG:tensorflow:Training: True
DEBUG:tensorflow:Apply dropout: True
DEBUG:tensorflow:==== Convolution Layer 1
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:==== Convolution Layer 2
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:==== Convolution Layer 3
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:==== Middle Convolution Layer 
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 8, 8, 512)
DEBUG:tensorflow:Using dropout_rate=0.150000
DEBUG:tensorflow:feature shape: (?, 8, 8, 512)
DEBUG:tensorflow:Using dropout_rate=0.150000
DEBUG:tensorflow:===== Convolution Transpose Layer 3
DEBUG:tensorflow:upconv shape: (?, 16, 16, 256)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:===== Convolution Transpose Layer 2
DEBUG:tensorflow:upconv shape: (?, 32, 32, 128)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:===== Convolution Transpose Layer 1
DEBUG:tensorflow:upconv shape: (?, 64, 64, 64)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:===== Final Convolution Layer 1
DEBUG:tensorflow:feature shape: (?, 64, 64, 2)
DEBUG:tensorflow:=====
DEBUG:tensorflow:Model output layer shape = (?, 64, 64, 2)
INFO:tensorflow:Total number of trainable model parameters = 7,699,712
DEBUG:tensorflow:Labels shape = (?, 64, 64, 1)
INFO:tensorflow:Preparing loss function metric: CrossEntropy
INFO:tensorflow:Creating AdamOptimizer with learning-rate = 0.001, and learning-rate decay rate = 1.0
DEBUG:tensorflow:num_iterations_per_epoch = 40.000000
DEBUG:tensorflow:opt_decay_steps = 40.000000
DEBUG:tensorflow:opt_moving_average = 1.000000
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Create CheckpointSaverHook.
INFO:tensorflow:Graph was finalized.
INFO:tensorflow:Restoring parameters from /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt-2280
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
INFO:tensorflow:Saving checkpoints for 2280 into /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt.
DEBUG:tensorflow:Training iteration 2280 / 4000 (57.00%)
INFO:tensorflow:loss = 0.054294407, step = 2280
DEBUG:tensorflow:Training iteration 2290 / 4000 (57.25%)
DEBUG:tensorflow:Training iteration 2300 / 4000 (57.50%)
DEBUG:tensorflow:Training iteration 2310 / 4000 (57.75%)
DEBUG:tensorflow:Training iteration 2320 / 4000 (58.00%)
INFO:tensorflow:Saving checkpoints for 2320 into /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt.
INFO:tensorflow:Loss for final step: 0.027827296.
INFO:tensorflow:
-----------------------------------------
-----
---- Training model...
-----
DEBUG:tensorflow:Train data: epoch size = 5120
DEBUG:tensorflow:Train data: batch size = 128
DEBUG:tensorflow:Train data: num_epochs = 100
DEBUG:tensorflow:Train data: patch_size: [64, 64, 7]
DEBUG:tensorflow:Train data: feature[0].shape: (5120, 64, 64, 7)
DEBUG:tensorflow:Train data: target[0].shape: (5120, 64, 64, 1)
INFO:tensorflow:Augmenting training data
INFO:tensorflow:Peformed 2551 flips
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:Creating model...
DEBUG:tensorflow:Stacked data shape: (?, 64, 64, 7)
DEBUG:tensorflow:Input data shape: (64, 64, 7)
DEBUG:tensorflow:Rectified input data shape: (?, 64, 64, 7)
DEBUG:tensorflow:===== Creating U-Net model: U-Net
DEBUG:tensorflow:Training: True
DEBUG:tensorflow:Apply dropout: True
DEBUG:tensorflow:==== Convolution Layer 1
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:==== Convolution Layer 2
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:==== Convolution Layer 3
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:==== Middle Convolution Layer 
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 8, 8, 512)
DEBUG:tensorflow:Using dropout_rate=0.150000
DEBUG:tensorflow:feature shape: (?, 8, 8, 512)
DEBUG:tensorflow:Using dropout_rate=0.150000
DEBUG:tensorflow:===== Convolution Transpose Layer 3
DEBUG:tensorflow:upconv shape: (?, 16, 16, 256)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:===== Convolution Transpose Layer 2
DEBUG:tensorflow:upconv shape: (?, 32, 32, 128)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:===== Convolution Transpose Layer 1
DEBUG:tensorflow:upconv shape: (?, 64, 64, 64)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:===== Final Convolution Layer 1
DEBUG:tensorflow:feature shape: (?, 64, 64, 2)
DEBUG:tensorflow:=====
DEBUG:tensorflow:Model output layer shape = (?, 64, 64, 2)
INFO:tensorflow:Total number of trainable model parameters = 7,699,712
DEBUG:tensorflow:Labels shape = (?, 64, 64, 1)
INFO:tensorflow:Preparing loss function metric: CrossEntropy
INFO:tensorflow:Creating AdamOptimizer with learning-rate = 0.001, and learning-rate decay rate = 1.0
DEBUG:tensorflow:num_iterations_per_epoch = 40.000000
DEBUG:tensorflow:opt_decay_steps = 40.000000
DEBUG:tensorflow:opt_moving_average = 1.000000
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Create CheckpointSaverHook.
INFO:tensorflow:Graph was finalized.
INFO:tensorflow:Restoring parameters from /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt-2320
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
INFO:tensorflow:Saving checkpoints for 2320 into /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt.
DEBUG:tensorflow:Training iteration 2320 / 4000 (58.00%)
INFO:tensorflow:loss = 0.03705895, step = 2320
DEBUG:tensorflow:Training iteration 2330 / 4000 (58.25%)
DEBUG:tensorflow:Training iteration 2340 / 4000 (58.50%)
DEBUG:tensorflow:Training iteration 2350 / 4000 (58.75%)
DEBUG:tensorflow:Training iteration 2360 / 4000 (59.00%)
INFO:tensorflow:Saving checkpoints for 2360 into /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt.
INFO:tensorflow:Loss for final step: 0.040407754.
INFO:tensorflow:
-----------------------------------------
-----
---- Training model...
-----
DEBUG:tensorflow:Train data: epoch size = 5120
DEBUG:tensorflow:Train data: batch size = 128
DEBUG:tensorflow:Train data: num_epochs = 100
DEBUG:tensorflow:Train data: patch_size: [64, 64, 7]
DEBUG:tensorflow:Train data: feature[0].shape: (5120, 64, 64, 7)
DEBUG:tensorflow:Train data: target[0].shape: (5120, 64, 64, 1)
INFO:tensorflow:Augmenting training data
INFO:tensorflow:Peformed 2567 flips
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:Creating model...
DEBUG:tensorflow:Stacked data shape: (?, 64, 64, 7)
DEBUG:tensorflow:Input data shape: (64, 64, 7)
DEBUG:tensorflow:Rectified input data shape: (?, 64, 64, 7)
DEBUG:tensorflow:===== Creating U-Net model: U-Net
DEBUG:tensorflow:Training: True
DEBUG:tensorflow:Apply dropout: True
DEBUG:tensorflow:==== Convolution Layer 1
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:==== Convolution Layer 2
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:==== Convolution Layer 3
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:==== Middle Convolution Layer 
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 8, 8, 512)
DEBUG:tensorflow:Using dropout_rate=0.150000
DEBUG:tensorflow:feature shape: (?, 8, 8, 512)
DEBUG:tensorflow:Using dropout_rate=0.150000
DEBUG:tensorflow:===== Convolution Transpose Layer 3
DEBUG:tensorflow:upconv shape: (?, 16, 16, 256)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:===== Convolution Transpose Layer 2
DEBUG:tensorflow:upconv shape: (?, 32, 32, 128)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:===== Convolution Transpose Layer 1
DEBUG:tensorflow:upconv shape: (?, 64, 64, 64)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:===== Final Convolution Layer 1
DEBUG:tensorflow:feature shape: (?, 64, 64, 2)
DEBUG:tensorflow:=====
DEBUG:tensorflow:Model output layer shape = (?, 64, 64, 2)
INFO:tensorflow:Total number of trainable model parameters = 7,699,712
DEBUG:tensorflow:Labels shape = (?, 64, 64, 1)
INFO:tensorflow:Preparing loss function metric: CrossEntropy
INFO:tensorflow:Creating AdamOptimizer with learning-rate = 0.001, and learning-rate decay rate = 1.0
DEBUG:tensorflow:num_iterations_per_epoch = 40.000000
DEBUG:tensorflow:opt_decay_steps = 40.000000
DEBUG:tensorflow:opt_moving_average = 1.000000
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Create CheckpointSaverHook.
INFO:tensorflow:Graph was finalized.
INFO:tensorflow:Restoring parameters from /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt-2360
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
INFO:tensorflow:Saving checkpoints for 2360 into /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt.
DEBUG:tensorflow:Training iteration 2360 / 4000 (59.00%)
INFO:tensorflow:loss = 0.03648469, step = 2360
DEBUG:tensorflow:Training iteration 2370 / 4000 (59.25%)
DEBUG:tensorflow:Training iteration 2380 / 4000 (59.50%)
DEBUG:tensorflow:Training iteration 2390 / 4000 (59.75%)
DEBUG:tensorflow:Training iteration 2400 / 4000 (60.00%)
INFO:tensorflow:Saving checkpoints for 2400 into /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt.
INFO:tensorflow:Loss for final step: 0.05654567.
INFO:tensorflow:
-----------------------------------------
-----
---- Training model...
-----
DEBUG:tensorflow:Train data: epoch size = 5120
DEBUG:tensorflow:Train data: batch size = 128
DEBUG:tensorflow:Train data: num_epochs = 100
DEBUG:tensorflow:Train data: patch_size: [64, 64, 7]
DEBUG:tensorflow:Train data: feature[0].shape: (5120, 64, 64, 7)
DEBUG:tensorflow:Train data: target[0].shape: (5120, 64, 64, 1)
INFO:tensorflow:Augmenting training data
INFO:tensorflow:Peformed 2507 flips
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:Creating model...
DEBUG:tensorflow:Stacked data shape: (?, 64, 64, 7)
DEBUG:tensorflow:Input data shape: (64, 64, 7)
DEBUG:tensorflow:Rectified input data shape: (?, 64, 64, 7)
DEBUG:tensorflow:===== Creating U-Net model: U-Net
DEBUG:tensorflow:Training: True
DEBUG:tensorflow:Apply dropout: True
DEBUG:tensorflow:==== Convolution Layer 1
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:==== Convolution Layer 2
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:==== Convolution Layer 3
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:==== Middle Convolution Layer 
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 8, 8, 512)
DEBUG:tensorflow:Using dropout_rate=0.150000
DEBUG:tensorflow:feature shape: (?, 8, 8, 512)
DEBUG:tensorflow:Using dropout_rate=0.150000
DEBUG:tensorflow:===== Convolution Transpose Layer 3
DEBUG:tensorflow:upconv shape: (?, 16, 16, 256)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:===== Convolution Transpose Layer 2
DEBUG:tensorflow:upconv shape: (?, 32, 32, 128)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:===== Convolution Transpose Layer 1
DEBUG:tensorflow:upconv shape: (?, 64, 64, 64)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:===== Final Convolution Layer 1
DEBUG:tensorflow:feature shape: (?, 64, 64, 2)
DEBUG:tensorflow:=====
DEBUG:tensorflow:Model output layer shape = (?, 64, 64, 2)
INFO:tensorflow:Total number of trainable model parameters = 7,699,712
DEBUG:tensorflow:Labels shape = (?, 64, 64, 1)
INFO:tensorflow:Preparing loss function metric: CrossEntropy
INFO:tensorflow:Creating AdamOptimizer with learning-rate = 0.001, and learning-rate decay rate = 1.0
DEBUG:tensorflow:num_iterations_per_epoch = 40.000000
DEBUG:tensorflow:opt_decay_steps = 40.000000
DEBUG:tensorflow:opt_moving_average = 1.000000
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Create CheckpointSaverHook.
INFO:tensorflow:Graph was finalized.
INFO:tensorflow:Restoring parameters from /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt-2400
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
INFO:tensorflow:Saving checkpoints for 2400 into /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt.
DEBUG:tensorflow:Training iteration 2400 / 4000 (60.00%)
INFO:tensorflow:loss = 0.04700332, step = 2400
DEBUG:tensorflow:Training iteration 2410 / 4000 (60.25%)
DEBUG:tensorflow:Training iteration 2420 / 4000 (60.50%)
DEBUG:tensorflow:Training iteration 2430 / 4000 (60.75%)
DEBUG:tensorflow:Training iteration 2440 / 4000 (61.00%)
INFO:tensorflow:Saving checkpoints for 2440 into /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt.
INFO:tensorflow:Loss for final step: 0.06276356.
INFO:tensorflow:
-----------------------------------------
-----
---- Training model...
-----
DEBUG:tensorflow:Train data: epoch size = 5120
DEBUG:tensorflow:Train data: batch size = 128
DEBUG:tensorflow:Train data: num_epochs = 100
DEBUG:tensorflow:Train data: patch_size: [64, 64, 7]
DEBUG:tensorflow:Train data: feature[0].shape: (5120, 64, 64, 7)
DEBUG:tensorflow:Train data: target[0].shape: (5120, 64, 64, 1)
INFO:tensorflow:Augmenting training data
INFO:tensorflow:Peformed 2554 flips
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:Creating model...
DEBUG:tensorflow:Stacked data shape: (?, 64, 64, 7)
DEBUG:tensorflow:Input data shape: (64, 64, 7)
DEBUG:tensorflow:Rectified input data shape: (?, 64, 64, 7)
DEBUG:tensorflow:===== Creating U-Net model: U-Net
DEBUG:tensorflow:Training: True
DEBUG:tensorflow:Apply dropout: True
DEBUG:tensorflow:==== Convolution Layer 1
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:==== Convolution Layer 2
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:==== Convolution Layer 3
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:==== Middle Convolution Layer 
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 8, 8, 512)
DEBUG:tensorflow:Using dropout_rate=0.150000
DEBUG:tensorflow:feature shape: (?, 8, 8, 512)
DEBUG:tensorflow:Using dropout_rate=0.150000
DEBUG:tensorflow:===== Convolution Transpose Layer 3
DEBUG:tensorflow:upconv shape: (?, 16, 16, 256)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:===== Convolution Transpose Layer 2
DEBUG:tensorflow:upconv shape: (?, 32, 32, 128)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:===== Convolution Transpose Layer 1
DEBUG:tensorflow:upconv shape: (?, 64, 64, 64)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:===== Final Convolution Layer 1
DEBUG:tensorflow:feature shape: (?, 64, 64, 2)
DEBUG:tensorflow:=====
DEBUG:tensorflow:Model output layer shape = (?, 64, 64, 2)
INFO:tensorflow:Total number of trainable model parameters = 7,699,712
DEBUG:tensorflow:Labels shape = (?, 64, 64, 1)
INFO:tensorflow:Preparing loss function metric: CrossEntropy
INFO:tensorflow:Creating AdamOptimizer with learning-rate = 0.001, and learning-rate decay rate = 1.0
DEBUG:tensorflow:num_iterations_per_epoch = 40.000000
DEBUG:tensorflow:opt_decay_steps = 40.000000
DEBUG:tensorflow:opt_moving_average = 1.000000
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Create CheckpointSaverHook.
INFO:tensorflow:Graph was finalized.
INFO:tensorflow:Restoring parameters from /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt-2440
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
INFO:tensorflow:Saving checkpoints for 2440 into /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt.
DEBUG:tensorflow:Training iteration 2440 / 4000 (61.00%)
INFO:tensorflow:loss = 0.04766486, step = 2440
DEBUG:tensorflow:Training iteration 2450 / 4000 (61.25%)
DEBUG:tensorflow:Training iteration 2460 / 4000 (61.50%)
DEBUG:tensorflow:Training iteration 2470 / 4000 (61.75%)
DEBUG:tensorflow:Training iteration 2480 / 4000 (62.00%)
INFO:tensorflow:Saving checkpoints for 2480 into /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt.
INFO:tensorflow:Loss for final step: 0.054736134.
INFO:tensorflow:
-----------------------------------------
-----
---- Training model...
-----
DEBUG:tensorflow:Train data: epoch size = 5120
DEBUG:tensorflow:Train data: batch size = 128
DEBUG:tensorflow:Train data: num_epochs = 100
DEBUG:tensorflow:Train data: patch_size: [64, 64, 7]
DEBUG:tensorflow:Train data: feature[0].shape: (5120, 64, 64, 7)
DEBUG:tensorflow:Train data: target[0].shape: (5120, 64, 64, 1)
INFO:tensorflow:Augmenting training data
INFO:tensorflow:Peformed 2460 flips
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:Creating model...
DEBUG:tensorflow:Stacked data shape: (?, 64, 64, 7)
DEBUG:tensorflow:Input data shape: (64, 64, 7)
DEBUG:tensorflow:Rectified input data shape: (?, 64, 64, 7)
DEBUG:tensorflow:===== Creating U-Net model: U-Net
DEBUG:tensorflow:Training: True
DEBUG:tensorflow:Apply dropout: True
DEBUG:tensorflow:==== Convolution Layer 1
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:==== Convolution Layer 2
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:==== Convolution Layer 3
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:==== Middle Convolution Layer 
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 8, 8, 512)
DEBUG:tensorflow:Using dropout_rate=0.150000
DEBUG:tensorflow:feature shape: (?, 8, 8, 512)
DEBUG:tensorflow:Using dropout_rate=0.150000
DEBUG:tensorflow:===== Convolution Transpose Layer 3
DEBUG:tensorflow:upconv shape: (?, 16, 16, 256)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:===== Convolution Transpose Layer 2
DEBUG:tensorflow:upconv shape: (?, 32, 32, 128)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:===== Convolution Transpose Layer 1
DEBUG:tensorflow:upconv shape: (?, 64, 64, 64)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:===== Final Convolution Layer 1
DEBUG:tensorflow:feature shape: (?, 64, 64, 2)
DEBUG:tensorflow:=====
DEBUG:tensorflow:Model output layer shape = (?, 64, 64, 2)
INFO:tensorflow:Total number of trainable model parameters = 7,699,712
DEBUG:tensorflow:Labels shape = (?, 64, 64, 1)
INFO:tensorflow:Preparing loss function metric: CrossEntropy
INFO:tensorflow:Creating AdamOptimizer with learning-rate = 0.001, and learning-rate decay rate = 1.0
DEBUG:tensorflow:num_iterations_per_epoch = 40.000000
DEBUG:tensorflow:opt_decay_steps = 40.000000
DEBUG:tensorflow:opt_moving_average = 1.000000
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Create CheckpointSaverHook.
INFO:tensorflow:Graph was finalized.
INFO:tensorflow:Restoring parameters from /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt-2480
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
INFO:tensorflow:Saving checkpoints for 2480 into /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt.
DEBUG:tensorflow:Training iteration 2480 / 4000 (62.00%)
INFO:tensorflow:loss = 0.041790865, step = 2480
DEBUG:tensorflow:Training iteration 2490 / 4000 (62.25%)
DEBUG:tensorflow:Training iteration 2500 / 4000 (62.50%)
DEBUG:tensorflow:Training iteration 2510 / 4000 (62.75%)
DEBUG:tensorflow:Training iteration 2520 / 4000 (63.00%)
INFO:tensorflow:Saving checkpoints for 2520 into /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt.
INFO:tensorflow:Loss for final step: 0.030212067.
INFO:tensorflow:
-----------------------------------------
-----
---- Training model...
-----
DEBUG:tensorflow:Train data: epoch size = 5120
DEBUG:tensorflow:Train data: batch size = 128
DEBUG:tensorflow:Train data: num_epochs = 100
DEBUG:tensorflow:Train data: patch_size: [64, 64, 7]
DEBUG:tensorflow:Train data: feature[0].shape: (5120, 64, 64, 7)
DEBUG:tensorflow:Train data: target[0].shape: (5120, 64, 64, 1)
INFO:tensorflow:Augmenting training data
INFO:tensorflow:Peformed 2535 flips
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:Creating model...
DEBUG:tensorflow:Stacked data shape: (?, 64, 64, 7)
DEBUG:tensorflow:Input data shape: (64, 64, 7)
DEBUG:tensorflow:Rectified input data shape: (?, 64, 64, 7)
DEBUG:tensorflow:===== Creating U-Net model: U-Net
DEBUG:tensorflow:Training: True
DEBUG:tensorflow:Apply dropout: True
DEBUG:tensorflow:==== Convolution Layer 1
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:==== Convolution Layer 2
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:==== Convolution Layer 3
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:==== Middle Convolution Layer 
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 8, 8, 512)
DEBUG:tensorflow:Using dropout_rate=0.150000
DEBUG:tensorflow:feature shape: (?, 8, 8, 512)
DEBUG:tensorflow:Using dropout_rate=0.150000
DEBUG:tensorflow:===== Convolution Transpose Layer 3
DEBUG:tensorflow:upconv shape: (?, 16, 16, 256)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:===== Convolution Transpose Layer 2
DEBUG:tensorflow:upconv shape: (?, 32, 32, 128)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:===== Convolution Transpose Layer 1
DEBUG:tensorflow:upconv shape: (?, 64, 64, 64)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:===== Final Convolution Layer 1
DEBUG:tensorflow:feature shape: (?, 64, 64, 2)
DEBUG:tensorflow:=====
DEBUG:tensorflow:Model output layer shape = (?, 64, 64, 2)
INFO:tensorflow:Total number of trainable model parameters = 7,699,712
DEBUG:tensorflow:Labels shape = (?, 64, 64, 1)
INFO:tensorflow:Preparing loss function metric: CrossEntropy
INFO:tensorflow:Creating AdamOptimizer with learning-rate = 0.001, and learning-rate decay rate = 1.0
DEBUG:tensorflow:num_iterations_per_epoch = 40.000000
DEBUG:tensorflow:opt_decay_steps = 40.000000
DEBUG:tensorflow:opt_moving_average = 1.000000
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Create CheckpointSaverHook.
INFO:tensorflow:Graph was finalized.
INFO:tensorflow:Restoring parameters from /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt-2520
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
INFO:tensorflow:Saving checkpoints for 2520 into /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt.
DEBUG:tensorflow:Training iteration 2520 / 4000 (63.00%)
INFO:tensorflow:loss = 0.05722443, step = 2520
DEBUG:tensorflow:Training iteration 2530 / 4000 (63.25%)
DEBUG:tensorflow:Training iteration 2540 / 4000 (63.50%)
DEBUG:tensorflow:Training iteration 2550 / 4000 (63.75%)
DEBUG:tensorflow:Training iteration 2560 / 4000 (64.00%)
INFO:tensorflow:Saving checkpoints for 2560 into /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt.
INFO:tensorflow:Loss for final step: 0.047090046.
INFO:tensorflow:
-----------------------------------------
-----
---- Training model...
-----
DEBUG:tensorflow:Train data: epoch size = 5120
DEBUG:tensorflow:Train data: batch size = 128
DEBUG:tensorflow:Train data: num_epochs = 100
DEBUG:tensorflow:Train data: patch_size: [64, 64, 7]
DEBUG:tensorflow:Train data: feature[0].shape: (5120, 64, 64, 7)
DEBUG:tensorflow:Train data: target[0].shape: (5120, 64, 64, 1)
INFO:tensorflow:Augmenting training data
INFO:tensorflow:Peformed 2533 flips
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:Creating model...
DEBUG:tensorflow:Stacked data shape: (?, 64, 64, 7)
DEBUG:tensorflow:Input data shape: (64, 64, 7)
DEBUG:tensorflow:Rectified input data shape: (?, 64, 64, 7)
DEBUG:tensorflow:===== Creating U-Net model: U-Net
DEBUG:tensorflow:Training: True
DEBUG:tensorflow:Apply dropout: True
DEBUG:tensorflow:==== Convolution Layer 1
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:==== Convolution Layer 2
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:==== Convolution Layer 3
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:==== Middle Convolution Layer 
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 8, 8, 512)
DEBUG:tensorflow:Using dropout_rate=0.150000
DEBUG:tensorflow:feature shape: (?, 8, 8, 512)
DEBUG:tensorflow:Using dropout_rate=0.150000
DEBUG:tensorflow:===== Convolution Transpose Layer 3
DEBUG:tensorflow:upconv shape: (?, 16, 16, 256)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:===== Convolution Transpose Layer 2
DEBUG:tensorflow:upconv shape: (?, 32, 32, 128)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:===== Convolution Transpose Layer 1
DEBUG:tensorflow:upconv shape: (?, 64, 64, 64)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:===== Final Convolution Layer 1
DEBUG:tensorflow:feature shape: (?, 64, 64, 2)
DEBUG:tensorflow:=====
DEBUG:tensorflow:Model output layer shape = (?, 64, 64, 2)
INFO:tensorflow:Total number of trainable model parameters = 7,699,712
DEBUG:tensorflow:Labels shape = (?, 64, 64, 1)
INFO:tensorflow:Preparing loss function metric: CrossEntropy
INFO:tensorflow:Creating AdamOptimizer with learning-rate = 0.001, and learning-rate decay rate = 1.0
DEBUG:tensorflow:num_iterations_per_epoch = 40.000000
DEBUG:tensorflow:opt_decay_steps = 40.000000
DEBUG:tensorflow:opt_moving_average = 1.000000
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Create CheckpointSaverHook.
INFO:tensorflow:Graph was finalized.
INFO:tensorflow:Restoring parameters from /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt-2560
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
INFO:tensorflow:Saving checkpoints for 2560 into /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt.
DEBUG:tensorflow:Training iteration 2560 / 4000 (64.00%)
INFO:tensorflow:loss = 0.05253613, step = 2560
DEBUG:tensorflow:Training iteration 2570 / 4000 (64.25%)
DEBUG:tensorflow:Training iteration 2580 / 4000 (64.50%)
DEBUG:tensorflow:Training iteration 2590 / 4000 (64.75%)
DEBUG:tensorflow:Training iteration 2600 / 4000 (65.00%)
INFO:tensorflow:Saving checkpoints for 2600 into /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt.
INFO:tensorflow:Loss for final step: 0.042834155.
INFO:tensorflow:
-----------------------------------------
-----
---- Training model...
-----
DEBUG:tensorflow:Train data: epoch size = 5120
DEBUG:tensorflow:Train data: batch size = 128
DEBUG:tensorflow:Train data: num_epochs = 100
DEBUG:tensorflow:Train data: patch_size: [64, 64, 7]
DEBUG:tensorflow:Train data: feature[0].shape: (5120, 64, 64, 7)
DEBUG:tensorflow:Train data: target[0].shape: (5120, 64, 64, 1)
INFO:tensorflow:Augmenting training data
INFO:tensorflow:Peformed 2572 flips
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:Creating model...
DEBUG:tensorflow:Stacked data shape: (?, 64, 64, 7)
DEBUG:tensorflow:Input data shape: (64, 64, 7)
DEBUG:tensorflow:Rectified input data shape: (?, 64, 64, 7)
DEBUG:tensorflow:===== Creating U-Net model: U-Net
DEBUG:tensorflow:Training: True
DEBUG:tensorflow:Apply dropout: True
DEBUG:tensorflow:==== Convolution Layer 1
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:==== Convolution Layer 2
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:==== Convolution Layer 3
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:==== Middle Convolution Layer 
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 8, 8, 512)
DEBUG:tensorflow:Using dropout_rate=0.150000
DEBUG:tensorflow:feature shape: (?, 8, 8, 512)
DEBUG:tensorflow:Using dropout_rate=0.150000
DEBUG:tensorflow:===== Convolution Transpose Layer 3
DEBUG:tensorflow:upconv shape: (?, 16, 16, 256)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:===== Convolution Transpose Layer 2
DEBUG:tensorflow:upconv shape: (?, 32, 32, 128)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:===== Convolution Transpose Layer 1
DEBUG:tensorflow:upconv shape: (?, 64, 64, 64)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:===== Final Convolution Layer 1
DEBUG:tensorflow:feature shape: (?, 64, 64, 2)
DEBUG:tensorflow:=====
DEBUG:tensorflow:Model output layer shape = (?, 64, 64, 2)
INFO:tensorflow:Total number of trainable model parameters = 7,699,712
DEBUG:tensorflow:Labels shape = (?, 64, 64, 1)
INFO:tensorflow:Preparing loss function metric: CrossEntropy
INFO:tensorflow:Creating AdamOptimizer with learning-rate = 0.001, and learning-rate decay rate = 1.0
DEBUG:tensorflow:num_iterations_per_epoch = 40.000000
DEBUG:tensorflow:opt_decay_steps = 40.000000
DEBUG:tensorflow:opt_moving_average = 1.000000
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Create CheckpointSaverHook.
INFO:tensorflow:Graph was finalized.
INFO:tensorflow:Restoring parameters from /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt-2600
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
INFO:tensorflow:Saving checkpoints for 2600 into /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt.
DEBUG:tensorflow:Training iteration 2600 / 4000 (65.00%)
INFO:tensorflow:loss = 0.060353473, step = 2600
DEBUG:tensorflow:Training iteration 2610 / 4000 (65.25%)
DEBUG:tensorflow:Training iteration 2620 / 4000 (65.50%)
DEBUG:tensorflow:Training iteration 2630 / 4000 (65.75%)
DEBUG:tensorflow:Training iteration 2640 / 4000 (66.00%)
INFO:tensorflow:Saving checkpoints for 2640 into /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt.
INFO:tensorflow:Loss for final step: 0.053873934.
INFO:tensorflow:
-----------------------------------------
-----
---- Training model...
-----
DEBUG:tensorflow:Train data: epoch size = 5120
DEBUG:tensorflow:Train data: batch size = 128
DEBUG:tensorflow:Train data: num_epochs = 100
DEBUG:tensorflow:Train data: patch_size: [64, 64, 7]
DEBUG:tensorflow:Train data: feature[0].shape: (5120, 64, 64, 7)
DEBUG:tensorflow:Train data: target[0].shape: (5120, 64, 64, 1)
INFO:tensorflow:Augmenting training data
INFO:tensorflow:Peformed 2589 flips
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:Creating model...
DEBUG:tensorflow:Stacked data shape: (?, 64, 64, 7)
DEBUG:tensorflow:Input data shape: (64, 64, 7)
DEBUG:tensorflow:Rectified input data shape: (?, 64, 64, 7)
DEBUG:tensorflow:===== Creating U-Net model: U-Net
DEBUG:tensorflow:Training: True
DEBUG:tensorflow:Apply dropout: True
DEBUG:tensorflow:==== Convolution Layer 1
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:==== Convolution Layer 2
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:==== Convolution Layer 3
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:==== Middle Convolution Layer 
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 8, 8, 512)
DEBUG:tensorflow:Using dropout_rate=0.150000
DEBUG:tensorflow:feature shape: (?, 8, 8, 512)
DEBUG:tensorflow:Using dropout_rate=0.150000
DEBUG:tensorflow:===== Convolution Transpose Layer 3
DEBUG:tensorflow:upconv shape: (?, 16, 16, 256)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:===== Convolution Transpose Layer 2
DEBUG:tensorflow:upconv shape: (?, 32, 32, 128)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:===== Convolution Transpose Layer 1
DEBUG:tensorflow:upconv shape: (?, 64, 64, 64)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:===== Final Convolution Layer 1
DEBUG:tensorflow:feature shape: (?, 64, 64, 2)
DEBUG:tensorflow:=====
DEBUG:tensorflow:Model output layer shape = (?, 64, 64, 2)
INFO:tensorflow:Total number of trainable model parameters = 7,699,712
DEBUG:tensorflow:Labels shape = (?, 64, 64, 1)
INFO:tensorflow:Preparing loss function metric: CrossEntropy
INFO:tensorflow:Creating AdamOptimizer with learning-rate = 0.001, and learning-rate decay rate = 1.0
DEBUG:tensorflow:num_iterations_per_epoch = 40.000000
DEBUG:tensorflow:opt_decay_steps = 40.000000
DEBUG:tensorflow:opt_moving_average = 1.000000
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Create CheckpointSaverHook.
INFO:tensorflow:Graph was finalized.
INFO:tensorflow:Restoring parameters from /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt-2640
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
INFO:tensorflow:Saving checkpoints for 2640 into /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt.
DEBUG:tensorflow:Training iteration 2640 / 4000 (66.00%)
INFO:tensorflow:loss = 0.060832277, step = 2640
DEBUG:tensorflow:Training iteration 2650 / 4000 (66.25%)
DEBUG:tensorflow:Training iteration 2660 / 4000 (66.50%)
DEBUG:tensorflow:Training iteration 2670 / 4000 (66.75%)
DEBUG:tensorflow:Training iteration 2680 / 4000 (67.00%)
INFO:tensorflow:Saving checkpoints for 2680 into /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt.
INFO:tensorflow:Loss for final step: 0.040186055.
INFO:tensorflow:
-----------------------------------------
-----
---- Training model...
-----
DEBUG:tensorflow:Train data: epoch size = 5120
DEBUG:tensorflow:Train data: batch size = 128
DEBUG:tensorflow:Train data: num_epochs = 100
DEBUG:tensorflow:Train data: patch_size: [64, 64, 7]
DEBUG:tensorflow:Train data: feature[0].shape: (5120, 64, 64, 7)
DEBUG:tensorflow:Train data: target[0].shape: (5120, 64, 64, 1)
INFO:tensorflow:Augmenting training data
INFO:tensorflow:Peformed 2605 flips
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:Creating model...
DEBUG:tensorflow:Stacked data shape: (?, 64, 64, 7)
DEBUG:tensorflow:Input data shape: (64, 64, 7)
DEBUG:tensorflow:Rectified input data shape: (?, 64, 64, 7)
DEBUG:tensorflow:===== Creating U-Net model: U-Net
DEBUG:tensorflow:Training: True
DEBUG:tensorflow:Apply dropout: True
DEBUG:tensorflow:==== Convolution Layer 1
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:==== Convolution Layer 2
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:==== Convolution Layer 3
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:==== Middle Convolution Layer 
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 8, 8, 512)
DEBUG:tensorflow:Using dropout_rate=0.150000
DEBUG:tensorflow:feature shape: (?, 8, 8, 512)
DEBUG:tensorflow:Using dropout_rate=0.150000
DEBUG:tensorflow:===== Convolution Transpose Layer 3
DEBUG:tensorflow:upconv shape: (?, 16, 16, 256)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:===== Convolution Transpose Layer 2
DEBUG:tensorflow:upconv shape: (?, 32, 32, 128)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:===== Convolution Transpose Layer 1
DEBUG:tensorflow:upconv shape: (?, 64, 64, 64)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:===== Final Convolution Layer 1
DEBUG:tensorflow:feature shape: (?, 64, 64, 2)
DEBUG:tensorflow:=====
DEBUG:tensorflow:Model output layer shape = (?, 64, 64, 2)
INFO:tensorflow:Total number of trainable model parameters = 7,699,712
DEBUG:tensorflow:Labels shape = (?, 64, 64, 1)
INFO:tensorflow:Preparing loss function metric: CrossEntropy
INFO:tensorflow:Creating AdamOptimizer with learning-rate = 0.001, and learning-rate decay rate = 1.0
DEBUG:tensorflow:num_iterations_per_epoch = 40.000000
DEBUG:tensorflow:opt_decay_steps = 40.000000
DEBUG:tensorflow:opt_moving_average = 1.000000
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Create CheckpointSaverHook.
INFO:tensorflow:Graph was finalized.
INFO:tensorflow:Restoring parameters from /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt-2680
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
INFO:tensorflow:Saving checkpoints for 2680 into /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt.
DEBUG:tensorflow:Training iteration 2680 / 4000 (67.00%)
INFO:tensorflow:loss = 0.040333122, step = 2680
DEBUG:tensorflow:Training iteration 2690 / 4000 (67.25%)
DEBUG:tensorflow:Training iteration 2700 / 4000 (67.50%)
DEBUG:tensorflow:Training iteration 2710 / 4000 (67.75%)
DEBUG:tensorflow:Training iteration 2720 / 4000 (68.00%)
INFO:tensorflow:Saving checkpoints for 2720 into /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt.
INFO:tensorflow:Loss for final step: 0.03258141.
INFO:tensorflow:
-----------------------------------------
-----
---- Training model...
-----
DEBUG:tensorflow:Train data: epoch size = 5120
DEBUG:tensorflow:Train data: batch size = 128
DEBUG:tensorflow:Train data: num_epochs = 100
DEBUG:tensorflow:Train data: patch_size: [64, 64, 7]
DEBUG:tensorflow:Train data: feature[0].shape: (5120, 64, 64, 7)
DEBUG:tensorflow:Train data: target[0].shape: (5120, 64, 64, 1)
INFO:tensorflow:Augmenting training data
INFO:tensorflow:Peformed 2523 flips
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:Creating model...
DEBUG:tensorflow:Stacked data shape: (?, 64, 64, 7)
DEBUG:tensorflow:Input data shape: (64, 64, 7)
DEBUG:tensorflow:Rectified input data shape: (?, 64, 64, 7)
DEBUG:tensorflow:===== Creating U-Net model: U-Net
DEBUG:tensorflow:Training: True
DEBUG:tensorflow:Apply dropout: True
DEBUG:tensorflow:==== Convolution Layer 1
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:==== Convolution Layer 2
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:==== Convolution Layer 3
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:==== Middle Convolution Layer 
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 8, 8, 512)
DEBUG:tensorflow:Using dropout_rate=0.150000
DEBUG:tensorflow:feature shape: (?, 8, 8, 512)
DEBUG:tensorflow:Using dropout_rate=0.150000
DEBUG:tensorflow:===== Convolution Transpose Layer 3
DEBUG:tensorflow:upconv shape: (?, 16, 16, 256)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:===== Convolution Transpose Layer 2
DEBUG:tensorflow:upconv shape: (?, 32, 32, 128)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:===== Convolution Transpose Layer 1
DEBUG:tensorflow:upconv shape: (?, 64, 64, 64)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:===== Final Convolution Layer 1
DEBUG:tensorflow:feature shape: (?, 64, 64, 2)
DEBUG:tensorflow:=====
DEBUG:tensorflow:Model output layer shape = (?, 64, 64, 2)
INFO:tensorflow:Total number of trainable model parameters = 7,699,712
DEBUG:tensorflow:Labels shape = (?, 64, 64, 1)
INFO:tensorflow:Preparing loss function metric: CrossEntropy
INFO:tensorflow:Creating AdamOptimizer with learning-rate = 0.001, and learning-rate decay rate = 1.0
DEBUG:tensorflow:num_iterations_per_epoch = 40.000000
DEBUG:tensorflow:opt_decay_steps = 40.000000
DEBUG:tensorflow:opt_moving_average = 1.000000
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Create CheckpointSaverHook.
INFO:tensorflow:Graph was finalized.
INFO:tensorflow:Restoring parameters from /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt-2720
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
INFO:tensorflow:Saving checkpoints for 2720 into /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt.
DEBUG:tensorflow:Training iteration 2720 / 4000 (68.00%)
INFO:tensorflow:loss = 0.025245527, step = 2720
DEBUG:tensorflow:Training iteration 2730 / 4000 (68.25%)
DEBUG:tensorflow:Training iteration 2740 / 4000 (68.50%)
DEBUG:tensorflow:Training iteration 2750 / 4000 (68.75%)
DEBUG:tensorflow:Training iteration 2760 / 4000 (69.00%)
INFO:tensorflow:Saving checkpoints for 2760 into /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt.
INFO:tensorflow:Loss for final step: 0.046490528.
INFO:tensorflow:
-----------------------------------------
-----
---- Training model...
-----
DEBUG:tensorflow:Train data: epoch size = 5120
DEBUG:tensorflow:Train data: batch size = 128
DEBUG:tensorflow:Train data: num_epochs = 100
DEBUG:tensorflow:Train data: patch_size: [64, 64, 7]
DEBUG:tensorflow:Train data: feature[0].shape: (5120, 64, 64, 7)
DEBUG:tensorflow:Train data: target[0].shape: (5120, 64, 64, 1)
INFO:tensorflow:Augmenting training data
INFO:tensorflow:Peformed 2535 flips
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:Creating model...
DEBUG:tensorflow:Stacked data shape: (?, 64, 64, 7)
DEBUG:tensorflow:Input data shape: (64, 64, 7)
DEBUG:tensorflow:Rectified input data shape: (?, 64, 64, 7)
DEBUG:tensorflow:===== Creating U-Net model: U-Net
DEBUG:tensorflow:Training: True
DEBUG:tensorflow:Apply dropout: True
DEBUG:tensorflow:==== Convolution Layer 1
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:==== Convolution Layer 2
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:==== Convolution Layer 3
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:==== Middle Convolution Layer 
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 8, 8, 512)
DEBUG:tensorflow:Using dropout_rate=0.150000
DEBUG:tensorflow:feature shape: (?, 8, 8, 512)
DEBUG:tensorflow:Using dropout_rate=0.150000
DEBUG:tensorflow:===== Convolution Transpose Layer 3
DEBUG:tensorflow:upconv shape: (?, 16, 16, 256)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:===== Convolution Transpose Layer 2
DEBUG:tensorflow:upconv shape: (?, 32, 32, 128)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:===== Convolution Transpose Layer 1
DEBUG:tensorflow:upconv shape: (?, 64, 64, 64)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:===== Final Convolution Layer 1
DEBUG:tensorflow:feature shape: (?, 64, 64, 2)
DEBUG:tensorflow:=====
DEBUG:tensorflow:Model output layer shape = (?, 64, 64, 2)
INFO:tensorflow:Total number of trainable model parameters = 7,699,712
DEBUG:tensorflow:Labels shape = (?, 64, 64, 1)
INFO:tensorflow:Preparing loss function metric: CrossEntropy
INFO:tensorflow:Creating AdamOptimizer with learning-rate = 0.001, and learning-rate decay rate = 1.0
DEBUG:tensorflow:num_iterations_per_epoch = 40.000000
DEBUG:tensorflow:opt_decay_steps = 40.000000
DEBUG:tensorflow:opt_moving_average = 1.000000
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Create CheckpointSaverHook.
INFO:tensorflow:Graph was finalized.
INFO:tensorflow:Restoring parameters from /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt-2760
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
INFO:tensorflow:Saving checkpoints for 2760 into /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt.
DEBUG:tensorflow:Training iteration 2760 / 4000 (69.00%)
INFO:tensorflow:loss = 0.048554823, step = 2760
DEBUG:tensorflow:Training iteration 2770 / 4000 (69.25%)
DEBUG:tensorflow:Training iteration 2780 / 4000 (69.50%)
DEBUG:tensorflow:Training iteration 2790 / 4000 (69.75%)
DEBUG:tensorflow:Training iteration 2800 / 4000 (70.00%)
INFO:tensorflow:Saving checkpoints for 2800 into /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt.
INFO:tensorflow:Loss for final step: 0.04571489.
INFO:tensorflow:
-----------------------------------------
-----
---- Training model...
-----
DEBUG:tensorflow:Train data: epoch size = 5120
DEBUG:tensorflow:Train data: batch size = 128
DEBUG:tensorflow:Train data: num_epochs = 100
DEBUG:tensorflow:Train data: patch_size: [64, 64, 7]
DEBUG:tensorflow:Train data: feature[0].shape: (5120, 64, 64, 7)
DEBUG:tensorflow:Train data: target[0].shape: (5120, 64, 64, 1)
INFO:tensorflow:Augmenting training data
INFO:tensorflow:Peformed 2511 flips
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:Creating model...
DEBUG:tensorflow:Stacked data shape: (?, 64, 64, 7)
DEBUG:tensorflow:Input data shape: (64, 64, 7)
DEBUG:tensorflow:Rectified input data shape: (?, 64, 64, 7)
DEBUG:tensorflow:===== Creating U-Net model: U-Net
DEBUG:tensorflow:Training: True
DEBUG:tensorflow:Apply dropout: True
DEBUG:tensorflow:==== Convolution Layer 1
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:==== Convolution Layer 2
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:==== Convolution Layer 3
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:==== Middle Convolution Layer 
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 8, 8, 512)
DEBUG:tensorflow:Using dropout_rate=0.150000
DEBUG:tensorflow:feature shape: (?, 8, 8, 512)
DEBUG:tensorflow:Using dropout_rate=0.150000
DEBUG:tensorflow:===== Convolution Transpose Layer 3
DEBUG:tensorflow:upconv shape: (?, 16, 16, 256)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:===== Convolution Transpose Layer 2
DEBUG:tensorflow:upconv shape: (?, 32, 32, 128)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:===== Convolution Transpose Layer 1
DEBUG:tensorflow:upconv shape: (?, 64, 64, 64)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:===== Final Convolution Layer 1
DEBUG:tensorflow:feature shape: (?, 64, 64, 2)
DEBUG:tensorflow:=====
DEBUG:tensorflow:Model output layer shape = (?, 64, 64, 2)
INFO:tensorflow:Total number of trainable model parameters = 7,699,712
DEBUG:tensorflow:Labels shape = (?, 64, 64, 1)
INFO:tensorflow:Preparing loss function metric: CrossEntropy
INFO:tensorflow:Creating AdamOptimizer with learning-rate = 0.001, and learning-rate decay rate = 1.0
DEBUG:tensorflow:num_iterations_per_epoch = 40.000000
DEBUG:tensorflow:opt_decay_steps = 40.000000
DEBUG:tensorflow:opt_moving_average = 1.000000
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Create CheckpointSaverHook.
INFO:tensorflow:Graph was finalized.
INFO:tensorflow:Restoring parameters from /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt-2800
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
INFO:tensorflow:Saving checkpoints for 2800 into /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt.
DEBUG:tensorflow:Training iteration 2800 / 4000 (70.00%)
INFO:tensorflow:loss = 0.05598379, step = 2800
DEBUG:tensorflow:Training iteration 2810 / 4000 (70.25%)
DEBUG:tensorflow:Training iteration 2820 / 4000 (70.50%)
DEBUG:tensorflow:Training iteration 2830 / 4000 (70.75%)
DEBUG:tensorflow:Training iteration 2840 / 4000 (71.00%)
INFO:tensorflow:Saving checkpoints for 2840 into /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt.
INFO:tensorflow:Loss for final step: 0.036987893.
INFO:tensorflow:
-----------------------------------------
-----
---- Training model...
-----
DEBUG:tensorflow:Train data: epoch size = 5120
DEBUG:tensorflow:Train data: batch size = 128
DEBUG:tensorflow:Train data: num_epochs = 100
DEBUG:tensorflow:Train data: patch_size: [64, 64, 7]
DEBUG:tensorflow:Train data: feature[0].shape: (5120, 64, 64, 7)
DEBUG:tensorflow:Train data: target[0].shape: (5120, 64, 64, 1)
INFO:tensorflow:Augmenting training data
INFO:tensorflow:Peformed 2639 flips
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:Creating model...
DEBUG:tensorflow:Stacked data shape: (?, 64, 64, 7)
DEBUG:tensorflow:Input data shape: (64, 64, 7)
DEBUG:tensorflow:Rectified input data shape: (?, 64, 64, 7)
DEBUG:tensorflow:===== Creating U-Net model: U-Net
DEBUG:tensorflow:Training: True
DEBUG:tensorflow:Apply dropout: True
DEBUG:tensorflow:==== Convolution Layer 1
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:==== Convolution Layer 2
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:==== Convolution Layer 3
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:==== Middle Convolution Layer 
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 8, 8, 512)
DEBUG:tensorflow:Using dropout_rate=0.150000
DEBUG:tensorflow:feature shape: (?, 8, 8, 512)
DEBUG:tensorflow:Using dropout_rate=0.150000
DEBUG:tensorflow:===== Convolution Transpose Layer 3
DEBUG:tensorflow:upconv shape: (?, 16, 16, 256)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:===== Convolution Transpose Layer 2
DEBUG:tensorflow:upconv shape: (?, 32, 32, 128)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:===== Convolution Transpose Layer 1
DEBUG:tensorflow:upconv shape: (?, 64, 64, 64)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:===== Final Convolution Layer 1
DEBUG:tensorflow:feature shape: (?, 64, 64, 2)
DEBUG:tensorflow:=====
DEBUG:tensorflow:Model output layer shape = (?, 64, 64, 2)
INFO:tensorflow:Total number of trainable model parameters = 7,699,712
DEBUG:tensorflow:Labels shape = (?, 64, 64, 1)
INFO:tensorflow:Preparing loss function metric: CrossEntropy
INFO:tensorflow:Creating AdamOptimizer with learning-rate = 0.001, and learning-rate decay rate = 1.0
DEBUG:tensorflow:num_iterations_per_epoch = 40.000000
DEBUG:tensorflow:opt_decay_steps = 40.000000
DEBUG:tensorflow:opt_moving_average = 1.000000
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Create CheckpointSaverHook.
INFO:tensorflow:Graph was finalized.
INFO:tensorflow:Restoring parameters from /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt-2840
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
INFO:tensorflow:Saving checkpoints for 2840 into /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt.
DEBUG:tensorflow:Training iteration 2840 / 4000 (71.00%)
INFO:tensorflow:loss = 0.03839857, step = 2840
DEBUG:tensorflow:Training iteration 2850 / 4000 (71.25%)
DEBUG:tensorflow:Training iteration 2860 / 4000 (71.50%)
DEBUG:tensorflow:Training iteration 2870 / 4000 (71.75%)
DEBUG:tensorflow:Training iteration 2880 / 4000 (72.00%)
INFO:tensorflow:Saving checkpoints for 2880 into /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt.
INFO:tensorflow:Loss for final step: 0.044218875.
INFO:tensorflow:
-----------------------------------------
-----
---- Training model...
-----
DEBUG:tensorflow:Train data: epoch size = 5120
DEBUG:tensorflow:Train data: batch size = 128
DEBUG:tensorflow:Train data: num_epochs = 100
DEBUG:tensorflow:Train data: patch_size: [64, 64, 7]
DEBUG:tensorflow:Train data: feature[0].shape: (5120, 64, 64, 7)
DEBUG:tensorflow:Train data: target[0].shape: (5120, 64, 64, 1)
INFO:tensorflow:Augmenting training data
INFO:tensorflow:Peformed 2547 flips
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:Creating model...
DEBUG:tensorflow:Stacked data shape: (?, 64, 64, 7)
DEBUG:tensorflow:Input data shape: (64, 64, 7)
DEBUG:tensorflow:Rectified input data shape: (?, 64, 64, 7)
DEBUG:tensorflow:===== Creating U-Net model: U-Net
DEBUG:tensorflow:Training: True
DEBUG:tensorflow:Apply dropout: True
DEBUG:tensorflow:==== Convolution Layer 1
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:==== Convolution Layer 2
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:==== Convolution Layer 3
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:==== Middle Convolution Layer 
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 8, 8, 512)
DEBUG:tensorflow:Using dropout_rate=0.150000
DEBUG:tensorflow:feature shape: (?, 8, 8, 512)
DEBUG:tensorflow:Using dropout_rate=0.150000
DEBUG:tensorflow:===== Convolution Transpose Layer 3
DEBUG:tensorflow:upconv shape: (?, 16, 16, 256)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:===== Convolution Transpose Layer 2
DEBUG:tensorflow:upconv shape: (?, 32, 32, 128)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:===== Convolution Transpose Layer 1
DEBUG:tensorflow:upconv shape: (?, 64, 64, 64)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:===== Final Convolution Layer 1
DEBUG:tensorflow:feature shape: (?, 64, 64, 2)
DEBUG:tensorflow:=====
DEBUG:tensorflow:Model output layer shape = (?, 64, 64, 2)
INFO:tensorflow:Total number of trainable model parameters = 7,699,712
DEBUG:tensorflow:Labels shape = (?, 64, 64, 1)
INFO:tensorflow:Preparing loss function metric: CrossEntropy
INFO:tensorflow:Creating AdamOptimizer with learning-rate = 0.001, and learning-rate decay rate = 1.0
DEBUG:tensorflow:num_iterations_per_epoch = 40.000000
DEBUG:tensorflow:opt_decay_steps = 40.000000
DEBUG:tensorflow:opt_moving_average = 1.000000
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Create CheckpointSaverHook.
INFO:tensorflow:Graph was finalized.
INFO:tensorflow:Restoring parameters from /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt-2880
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
INFO:tensorflow:Saving checkpoints for 2880 into /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt.
DEBUG:tensorflow:Training iteration 2880 / 4000 (72.00%)
INFO:tensorflow:loss = 0.049474366, step = 2880
DEBUG:tensorflow:Training iteration 2890 / 4000 (72.25%)
DEBUG:tensorflow:Training iteration 2900 / 4000 (72.50%)
DEBUG:tensorflow:Training iteration 2910 / 4000 (72.75%)
DEBUG:tensorflow:Training iteration 2920 / 4000 (73.00%)
INFO:tensorflow:Saving checkpoints for 2920 into /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt.
INFO:tensorflow:Loss for final step: 0.05495921.
INFO:tensorflow:
-----------------------------------------
-----
---- Training model...
-----
DEBUG:tensorflow:Train data: epoch size = 5120
DEBUG:tensorflow:Train data: batch size = 128
DEBUG:tensorflow:Train data: num_epochs = 100
DEBUG:tensorflow:Train data: patch_size: [64, 64, 7]
DEBUG:tensorflow:Train data: feature[0].shape: (5120, 64, 64, 7)
DEBUG:tensorflow:Train data: target[0].shape: (5120, 64, 64, 1)
INFO:tensorflow:Augmenting training data
INFO:tensorflow:Peformed 2540 flips
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:Creating model...
DEBUG:tensorflow:Stacked data shape: (?, 64, 64, 7)
DEBUG:tensorflow:Input data shape: (64, 64, 7)
DEBUG:tensorflow:Rectified input data shape: (?, 64, 64, 7)
DEBUG:tensorflow:===== Creating U-Net model: U-Net
DEBUG:tensorflow:Training: True
DEBUG:tensorflow:Apply dropout: True
DEBUG:tensorflow:==== Convolution Layer 1
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:==== Convolution Layer 2
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:==== Convolution Layer 3
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:==== Middle Convolution Layer 
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 8, 8, 512)
DEBUG:tensorflow:Using dropout_rate=0.150000
DEBUG:tensorflow:feature shape: (?, 8, 8, 512)
DEBUG:tensorflow:Using dropout_rate=0.150000
DEBUG:tensorflow:===== Convolution Transpose Layer 3
DEBUG:tensorflow:upconv shape: (?, 16, 16, 256)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:===== Convolution Transpose Layer 2
DEBUG:tensorflow:upconv shape: (?, 32, 32, 128)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:===== Convolution Transpose Layer 1
DEBUG:tensorflow:upconv shape: (?, 64, 64, 64)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:===== Final Convolution Layer 1
DEBUG:tensorflow:feature shape: (?, 64, 64, 2)
DEBUG:tensorflow:=====
DEBUG:tensorflow:Model output layer shape = (?, 64, 64, 2)
INFO:tensorflow:Total number of trainable model parameters = 7,699,712
DEBUG:tensorflow:Labels shape = (?, 64, 64, 1)
INFO:tensorflow:Preparing loss function metric: CrossEntropy
INFO:tensorflow:Creating AdamOptimizer with learning-rate = 0.001, and learning-rate decay rate = 1.0
DEBUG:tensorflow:num_iterations_per_epoch = 40.000000
DEBUG:tensorflow:opt_decay_steps = 40.000000
DEBUG:tensorflow:opt_moving_average = 1.000000
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Create CheckpointSaverHook.
INFO:tensorflow:Graph was finalized.
INFO:tensorflow:Restoring parameters from /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt-2920
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
INFO:tensorflow:Saving checkpoints for 2920 into /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt.
DEBUG:tensorflow:Training iteration 2920 / 4000 (73.00%)
INFO:tensorflow:loss = 0.03920222, step = 2920
DEBUG:tensorflow:Training iteration 2930 / 4000 (73.25%)
DEBUG:tensorflow:Training iteration 2940 / 4000 (73.50%)
DEBUG:tensorflow:Training iteration 2950 / 4000 (73.75%)
DEBUG:tensorflow:Training iteration 2960 / 4000 (74.00%)
INFO:tensorflow:Saving checkpoints for 2960 into /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt.
INFO:tensorflow:Loss for final step: 0.05070547.
INFO:tensorflow:
-----------------------------------------
-----
---- Training model...
-----
DEBUG:tensorflow:Train data: epoch size = 5120
DEBUG:tensorflow:Train data: batch size = 128
DEBUG:tensorflow:Train data: num_epochs = 100
DEBUG:tensorflow:Train data: patch_size: [64, 64, 7]
DEBUG:tensorflow:Train data: feature[0].shape: (5120, 64, 64, 7)
DEBUG:tensorflow:Train data: target[0].shape: (5120, 64, 64, 1)
INFO:tensorflow:Augmenting training data
INFO:tensorflow:Peformed 2515 flips
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:Creating model...
DEBUG:tensorflow:Stacked data shape: (?, 64, 64, 7)
DEBUG:tensorflow:Input data shape: (64, 64, 7)
DEBUG:tensorflow:Rectified input data shape: (?, 64, 64, 7)
DEBUG:tensorflow:===== Creating U-Net model: U-Net
DEBUG:tensorflow:Training: True
DEBUG:tensorflow:Apply dropout: True
DEBUG:tensorflow:==== Convolution Layer 1
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:==== Convolution Layer 2
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:==== Convolution Layer 3
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:==== Middle Convolution Layer 
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 8, 8, 512)
DEBUG:tensorflow:Using dropout_rate=0.150000
DEBUG:tensorflow:feature shape: (?, 8, 8, 512)
DEBUG:tensorflow:Using dropout_rate=0.150000
DEBUG:tensorflow:===== Convolution Transpose Layer 3
DEBUG:tensorflow:upconv shape: (?, 16, 16, 256)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:===== Convolution Transpose Layer 2
DEBUG:tensorflow:upconv shape: (?, 32, 32, 128)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:===== Convolution Transpose Layer 1
DEBUG:tensorflow:upconv shape: (?, 64, 64, 64)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:===== Final Convolution Layer 1
DEBUG:tensorflow:feature shape: (?, 64, 64, 2)
DEBUG:tensorflow:=====
DEBUG:tensorflow:Model output layer shape = (?, 64, 64, 2)
INFO:tensorflow:Total number of trainable model parameters = 7,699,712
DEBUG:tensorflow:Labels shape = (?, 64, 64, 1)
INFO:tensorflow:Preparing loss function metric: CrossEntropy
INFO:tensorflow:Creating AdamOptimizer with learning-rate = 0.001, and learning-rate decay rate = 1.0
DEBUG:tensorflow:num_iterations_per_epoch = 40.000000
DEBUG:tensorflow:opt_decay_steps = 40.000000
DEBUG:tensorflow:opt_moving_average = 1.000000
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Create CheckpointSaverHook.
INFO:tensorflow:Graph was finalized.
INFO:tensorflow:Restoring parameters from /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt-2960
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
INFO:tensorflow:Saving checkpoints for 2960 into /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt.
DEBUG:tensorflow:Training iteration 2960 / 4000 (74.00%)
INFO:tensorflow:loss = 0.060761776, step = 2960
DEBUG:tensorflow:Training iteration 2970 / 4000 (74.25%)
DEBUG:tensorflow:Training iteration 2980 / 4000 (74.50%)
DEBUG:tensorflow:Training iteration 2990 / 4000 (74.75%)
DEBUG:tensorflow:Training iteration 3000 / 4000 (75.00%)
INFO:tensorflow:Saving checkpoints for 3000 into /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt.
INFO:tensorflow:Loss for final step: 0.04247539.
INFO:tensorflow:
-----------------------------------------
-----
---- Training model...
-----
DEBUG:tensorflow:Train data: epoch size = 5120
DEBUG:tensorflow:Train data: batch size = 128
DEBUG:tensorflow:Train data: num_epochs = 100
DEBUG:tensorflow:Train data: patch_size: [64, 64, 7]
DEBUG:tensorflow:Train data: feature[0].shape: (5120, 64, 64, 7)
DEBUG:tensorflow:Train data: target[0].shape: (5120, 64, 64, 1)
INFO:tensorflow:Augmenting training data
INFO:tensorflow:Peformed 2638 flips
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:Creating model...
DEBUG:tensorflow:Stacked data shape: (?, 64, 64, 7)
DEBUG:tensorflow:Input data shape: (64, 64, 7)
DEBUG:tensorflow:Rectified input data shape: (?, 64, 64, 7)
DEBUG:tensorflow:===== Creating U-Net model: U-Net
DEBUG:tensorflow:Training: True
DEBUG:tensorflow:Apply dropout: True
DEBUG:tensorflow:==== Convolution Layer 1
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:==== Convolution Layer 2
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:==== Convolution Layer 3
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:==== Middle Convolution Layer 
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 8, 8, 512)
DEBUG:tensorflow:Using dropout_rate=0.150000
DEBUG:tensorflow:feature shape: (?, 8, 8, 512)
DEBUG:tensorflow:Using dropout_rate=0.150000
DEBUG:tensorflow:===== Convolution Transpose Layer 3
DEBUG:tensorflow:upconv shape: (?, 16, 16, 256)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:===== Convolution Transpose Layer 2
DEBUG:tensorflow:upconv shape: (?, 32, 32, 128)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:===== Convolution Transpose Layer 1
DEBUG:tensorflow:upconv shape: (?, 64, 64, 64)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:===== Final Convolution Layer 1
DEBUG:tensorflow:feature shape: (?, 64, 64, 2)
DEBUG:tensorflow:=====
DEBUG:tensorflow:Model output layer shape = (?, 64, 64, 2)
INFO:tensorflow:Total number of trainable model parameters = 7,699,712
DEBUG:tensorflow:Labels shape = (?, 64, 64, 1)
INFO:tensorflow:Preparing loss function metric: CrossEntropy
INFO:tensorflow:Creating AdamOptimizer with learning-rate = 0.001, and learning-rate decay rate = 1.0
DEBUG:tensorflow:num_iterations_per_epoch = 40.000000
DEBUG:tensorflow:opt_decay_steps = 40.000000
DEBUG:tensorflow:opt_moving_average = 1.000000
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Create CheckpointSaverHook.
INFO:tensorflow:Graph was finalized.
INFO:tensorflow:Restoring parameters from /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt-3000
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
INFO:tensorflow:Saving checkpoints for 3000 into /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt.
DEBUG:tensorflow:Training iteration 3000 / 4000 (75.00%)
INFO:tensorflow:loss = 0.042393014, step = 3000
DEBUG:tensorflow:Training iteration 3010 / 4000 (75.25%)
DEBUG:tensorflow:Training iteration 3020 / 4000 (75.50%)
DEBUG:tensorflow:Training iteration 3030 / 4000 (75.75%)
DEBUG:tensorflow:Training iteration 3040 / 4000 (76.00%)
INFO:tensorflow:Saving checkpoints for 3040 into /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt.
INFO:tensorflow:Loss for final step: 0.032840118.
INFO:tensorflow:
-----------------------------------------
-----
---- Training model...
-----
DEBUG:tensorflow:Train data: epoch size = 5120
DEBUG:tensorflow:Train data: batch size = 128
DEBUG:tensorflow:Train data: num_epochs = 100
DEBUG:tensorflow:Train data: patch_size: [64, 64, 7]
DEBUG:tensorflow:Train data: feature[0].shape: (5120, 64, 64, 7)
DEBUG:tensorflow:Train data: target[0].shape: (5120, 64, 64, 1)
INFO:tensorflow:Augmenting training data
INFO:tensorflow:Peformed 2561 flips
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:Creating model...
DEBUG:tensorflow:Stacked data shape: (?, 64, 64, 7)
DEBUG:tensorflow:Input data shape: (64, 64, 7)
DEBUG:tensorflow:Rectified input data shape: (?, 64, 64, 7)
DEBUG:tensorflow:===== Creating U-Net model: U-Net
DEBUG:tensorflow:Training: True
DEBUG:tensorflow:Apply dropout: True
DEBUG:tensorflow:==== Convolution Layer 1
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:==== Convolution Layer 2
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:==== Convolution Layer 3
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:==== Middle Convolution Layer 
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 8, 8, 512)
DEBUG:tensorflow:Using dropout_rate=0.150000
DEBUG:tensorflow:feature shape: (?, 8, 8, 512)
DEBUG:tensorflow:Using dropout_rate=0.150000
DEBUG:tensorflow:===== Convolution Transpose Layer 3
DEBUG:tensorflow:upconv shape: (?, 16, 16, 256)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:===== Convolution Transpose Layer 2
DEBUG:tensorflow:upconv shape: (?, 32, 32, 128)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:===== Convolution Transpose Layer 1
DEBUG:tensorflow:upconv shape: (?, 64, 64, 64)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:===== Final Convolution Layer 1
DEBUG:tensorflow:feature shape: (?, 64, 64, 2)
DEBUG:tensorflow:=====
DEBUG:tensorflow:Model output layer shape = (?, 64, 64, 2)
INFO:tensorflow:Total number of trainable model parameters = 7,699,712
DEBUG:tensorflow:Labels shape = (?, 64, 64, 1)
INFO:tensorflow:Preparing loss function metric: CrossEntropy
INFO:tensorflow:Creating AdamOptimizer with learning-rate = 0.001, and learning-rate decay rate = 1.0
DEBUG:tensorflow:num_iterations_per_epoch = 40.000000
DEBUG:tensorflow:opt_decay_steps = 40.000000
DEBUG:tensorflow:opt_moving_average = 1.000000
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Create CheckpointSaverHook.
INFO:tensorflow:Graph was finalized.
INFO:tensorflow:Restoring parameters from /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt-3040
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
INFO:tensorflow:Saving checkpoints for 3040 into /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt.
DEBUG:tensorflow:Training iteration 3040 / 4000 (76.00%)
INFO:tensorflow:loss = 0.045919694, step = 3040
DEBUG:tensorflow:Training iteration 3050 / 4000 (76.25%)
DEBUG:tensorflow:Training iteration 3060 / 4000 (76.50%)
DEBUG:tensorflow:Training iteration 3070 / 4000 (76.75%)
DEBUG:tensorflow:Training iteration 3080 / 4000 (77.00%)
INFO:tensorflow:Saving checkpoints for 3080 into /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt.
INFO:tensorflow:Loss for final step: 0.044619642.
INFO:tensorflow:
-----------------------------------------
-----
---- Training model...
-----
DEBUG:tensorflow:Train data: epoch size = 5120
DEBUG:tensorflow:Train data: batch size = 128
DEBUG:tensorflow:Train data: num_epochs = 100
DEBUG:tensorflow:Train data: patch_size: [64, 64, 7]
DEBUG:tensorflow:Train data: feature[0].shape: (5120, 64, 64, 7)
DEBUG:tensorflow:Train data: target[0].shape: (5120, 64, 64, 1)
INFO:tensorflow:Augmenting training data
INFO:tensorflow:Peformed 2538 flips
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:Creating model...
DEBUG:tensorflow:Stacked data shape: (?, 64, 64, 7)
DEBUG:tensorflow:Input data shape: (64, 64, 7)
DEBUG:tensorflow:Rectified input data shape: (?, 64, 64, 7)
DEBUG:tensorflow:===== Creating U-Net model: U-Net
DEBUG:tensorflow:Training: True
DEBUG:tensorflow:Apply dropout: True
DEBUG:tensorflow:==== Convolution Layer 1
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:==== Convolution Layer 2
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:==== Convolution Layer 3
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:==== Middle Convolution Layer 
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 8, 8, 512)
DEBUG:tensorflow:Using dropout_rate=0.150000
DEBUG:tensorflow:feature shape: (?, 8, 8, 512)
DEBUG:tensorflow:Using dropout_rate=0.150000
DEBUG:tensorflow:===== Convolution Transpose Layer 3
DEBUG:tensorflow:upconv shape: (?, 16, 16, 256)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:===== Convolution Transpose Layer 2
DEBUG:tensorflow:upconv shape: (?, 32, 32, 128)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:===== Convolution Transpose Layer 1
DEBUG:tensorflow:upconv shape: (?, 64, 64, 64)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:===== Final Convolution Layer 1
DEBUG:tensorflow:feature shape: (?, 64, 64, 2)
DEBUG:tensorflow:=====
DEBUG:tensorflow:Model output layer shape = (?, 64, 64, 2)
INFO:tensorflow:Total number of trainable model parameters = 7,699,712
DEBUG:tensorflow:Labels shape = (?, 64, 64, 1)
INFO:tensorflow:Preparing loss function metric: CrossEntropy
INFO:tensorflow:Creating AdamOptimizer with learning-rate = 0.001, and learning-rate decay rate = 1.0
DEBUG:tensorflow:num_iterations_per_epoch = 40.000000
DEBUG:tensorflow:opt_decay_steps = 40.000000
DEBUG:tensorflow:opt_moving_average = 1.000000
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Create CheckpointSaverHook.
INFO:tensorflow:Graph was finalized.
INFO:tensorflow:Restoring parameters from /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt-3080
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
INFO:tensorflow:Saving checkpoints for 3080 into /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt.
DEBUG:tensorflow:Training iteration 3080 / 4000 (77.00%)
INFO:tensorflow:loss = 0.053302035, step = 3080
DEBUG:tensorflow:Training iteration 3090 / 4000 (77.25%)
DEBUG:tensorflow:Training iteration 3100 / 4000 (77.50%)
DEBUG:tensorflow:Training iteration 3110 / 4000 (77.75%)
DEBUG:tensorflow:Training iteration 3120 / 4000 (78.00%)
INFO:tensorflow:Saving checkpoints for 3120 into /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt.
INFO:tensorflow:Loss for final step: 0.046777997.
INFO:tensorflow:
-----------------------------------------
-----
---- Training model...
-----
DEBUG:tensorflow:Train data: epoch size = 5120
DEBUG:tensorflow:Train data: batch size = 128
DEBUG:tensorflow:Train data: num_epochs = 100
DEBUG:tensorflow:Train data: patch_size: [64, 64, 7]
DEBUG:tensorflow:Train data: feature[0].shape: (5120, 64, 64, 7)
DEBUG:tensorflow:Train data: target[0].shape: (5120, 64, 64, 1)
INFO:tensorflow:Augmenting training data
INFO:tensorflow:Peformed 2541 flips
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:Creating model...
DEBUG:tensorflow:Stacked data shape: (?, 64, 64, 7)
DEBUG:tensorflow:Input data shape: (64, 64, 7)
DEBUG:tensorflow:Rectified input data shape: (?, 64, 64, 7)
DEBUG:tensorflow:===== Creating U-Net model: U-Net
DEBUG:tensorflow:Training: True
DEBUG:tensorflow:Apply dropout: True
DEBUG:tensorflow:==== Convolution Layer 1
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:==== Convolution Layer 2
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:==== Convolution Layer 3
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:==== Middle Convolution Layer 
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 8, 8, 512)
DEBUG:tensorflow:Using dropout_rate=0.150000
DEBUG:tensorflow:feature shape: (?, 8, 8, 512)
DEBUG:tensorflow:Using dropout_rate=0.150000
DEBUG:tensorflow:===== Convolution Transpose Layer 3
DEBUG:tensorflow:upconv shape: (?, 16, 16, 256)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:===== Convolution Transpose Layer 2
DEBUG:tensorflow:upconv shape: (?, 32, 32, 128)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:===== Convolution Transpose Layer 1
DEBUG:tensorflow:upconv shape: (?, 64, 64, 64)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:===== Final Convolution Layer 1
DEBUG:tensorflow:feature shape: (?, 64, 64, 2)
DEBUG:tensorflow:=====
DEBUG:tensorflow:Model output layer shape = (?, 64, 64, 2)
INFO:tensorflow:Total number of trainable model parameters = 7,699,712
DEBUG:tensorflow:Labels shape = (?, 64, 64, 1)
INFO:tensorflow:Preparing loss function metric: CrossEntropy
INFO:tensorflow:Creating AdamOptimizer with learning-rate = 0.001, and learning-rate decay rate = 1.0
DEBUG:tensorflow:num_iterations_per_epoch = 40.000000
DEBUG:tensorflow:opt_decay_steps = 40.000000
DEBUG:tensorflow:opt_moving_average = 1.000000
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Create CheckpointSaverHook.
INFO:tensorflow:Graph was finalized.
INFO:tensorflow:Restoring parameters from /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt-3120
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
INFO:tensorflow:Saving checkpoints for 3120 into /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt.
DEBUG:tensorflow:Training iteration 3120 / 4000 (78.00%)
INFO:tensorflow:loss = 0.048720527, step = 3120
DEBUG:tensorflow:Training iteration 3130 / 4000 (78.25%)
DEBUG:tensorflow:Training iteration 3140 / 4000 (78.50%)
DEBUG:tensorflow:Training iteration 3150 / 4000 (78.75%)
DEBUG:tensorflow:Training iteration 3160 / 4000 (79.00%)
INFO:tensorflow:Saving checkpoints for 3160 into /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt.
INFO:tensorflow:Loss for final step: 0.03693659.
INFO:tensorflow:
-----------------------------------------
-----
---- Training model...
-----
DEBUG:tensorflow:Train data: epoch size = 5120
DEBUG:tensorflow:Train data: batch size = 128
DEBUG:tensorflow:Train data: num_epochs = 100
DEBUG:tensorflow:Train data: patch_size: [64, 64, 7]
DEBUG:tensorflow:Train data: feature[0].shape: (5120, 64, 64, 7)
DEBUG:tensorflow:Train data: target[0].shape: (5120, 64, 64, 1)
INFO:tensorflow:Augmenting training data
INFO:tensorflow:Peformed 2508 flips
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:Creating model...
DEBUG:tensorflow:Stacked data shape: (?, 64, 64, 7)
DEBUG:tensorflow:Input data shape: (64, 64, 7)
DEBUG:tensorflow:Rectified input data shape: (?, 64, 64, 7)
DEBUG:tensorflow:===== Creating U-Net model: U-Net
DEBUG:tensorflow:Training: True
DEBUG:tensorflow:Apply dropout: True
DEBUG:tensorflow:==== Convolution Layer 1
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:==== Convolution Layer 2
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:==== Convolution Layer 3
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:==== Middle Convolution Layer 
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 8, 8, 512)
DEBUG:tensorflow:Using dropout_rate=0.150000
DEBUG:tensorflow:feature shape: (?, 8, 8, 512)
DEBUG:tensorflow:Using dropout_rate=0.150000
DEBUG:tensorflow:===== Convolution Transpose Layer 3
DEBUG:tensorflow:upconv shape: (?, 16, 16, 256)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:===== Convolution Transpose Layer 2
DEBUG:tensorflow:upconv shape: (?, 32, 32, 128)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:===== Convolution Transpose Layer 1
DEBUG:tensorflow:upconv shape: (?, 64, 64, 64)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:===== Final Convolution Layer 1
DEBUG:tensorflow:feature shape: (?, 64, 64, 2)
DEBUG:tensorflow:=====
DEBUG:tensorflow:Model output layer shape = (?, 64, 64, 2)
INFO:tensorflow:Total number of trainable model parameters = 7,699,712
DEBUG:tensorflow:Labels shape = (?, 64, 64, 1)
INFO:tensorflow:Preparing loss function metric: CrossEntropy
INFO:tensorflow:Creating AdamOptimizer with learning-rate = 0.001, and learning-rate decay rate = 1.0
DEBUG:tensorflow:num_iterations_per_epoch = 40.000000
DEBUG:tensorflow:opt_decay_steps = 40.000000
DEBUG:tensorflow:opt_moving_average = 1.000000
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Create CheckpointSaverHook.
INFO:tensorflow:Graph was finalized.
INFO:tensorflow:Restoring parameters from /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt-3160
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
INFO:tensorflow:Saving checkpoints for 3160 into /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt.
DEBUG:tensorflow:Training iteration 3160 / 4000 (79.00%)
INFO:tensorflow:loss = 0.048114516, step = 3160
DEBUG:tensorflow:Training iteration 3170 / 4000 (79.25%)
DEBUG:tensorflow:Training iteration 3180 / 4000 (79.50%)
DEBUG:tensorflow:Training iteration 3190 / 4000 (79.75%)
DEBUG:tensorflow:Training iteration 3200 / 4000 (80.00%)
INFO:tensorflow:Saving checkpoints for 3200 into /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt.
INFO:tensorflow:Loss for final step: 0.047376666.
INFO:tensorflow:
-----------------------------------------
-----
---- Training model...
-----
DEBUG:tensorflow:Train data: epoch size = 5120
DEBUG:tensorflow:Train data: batch size = 128
DEBUG:tensorflow:Train data: num_epochs = 100
DEBUG:tensorflow:Train data: patch_size: [64, 64, 7]
DEBUG:tensorflow:Train data: feature[0].shape: (5120, 64, 64, 7)
DEBUG:tensorflow:Train data: target[0].shape: (5120, 64, 64, 1)
INFO:tensorflow:Augmenting training data
INFO:tensorflow:Peformed 2557 flips
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:Creating model...
DEBUG:tensorflow:Stacked data shape: (?, 64, 64, 7)
DEBUG:tensorflow:Input data shape: (64, 64, 7)
DEBUG:tensorflow:Rectified input data shape: (?, 64, 64, 7)
DEBUG:tensorflow:===== Creating U-Net model: U-Net
DEBUG:tensorflow:Training: True
DEBUG:tensorflow:Apply dropout: True
DEBUG:tensorflow:==== Convolution Layer 1
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:==== Convolution Layer 2
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:==== Convolution Layer 3
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:==== Middle Convolution Layer 
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 8, 8, 512)
DEBUG:tensorflow:Using dropout_rate=0.150000
DEBUG:tensorflow:feature shape: (?, 8, 8, 512)
DEBUG:tensorflow:Using dropout_rate=0.150000
DEBUG:tensorflow:===== Convolution Transpose Layer 3
DEBUG:tensorflow:upconv shape: (?, 16, 16, 256)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:===== Convolution Transpose Layer 2
DEBUG:tensorflow:upconv shape: (?, 32, 32, 128)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:===== Convolution Transpose Layer 1
DEBUG:tensorflow:upconv shape: (?, 64, 64, 64)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:===== Final Convolution Layer 1
DEBUG:tensorflow:feature shape: (?, 64, 64, 2)
DEBUG:tensorflow:=====
DEBUG:tensorflow:Model output layer shape = (?, 64, 64, 2)
INFO:tensorflow:Total number of trainable model parameters = 7,699,712
DEBUG:tensorflow:Labels shape = (?, 64, 64, 1)
INFO:tensorflow:Preparing loss function metric: CrossEntropy
INFO:tensorflow:Creating AdamOptimizer with learning-rate = 0.001, and learning-rate decay rate = 1.0
DEBUG:tensorflow:num_iterations_per_epoch = 40.000000
DEBUG:tensorflow:opt_decay_steps = 40.000000
DEBUG:tensorflow:opt_moving_average = 1.000000
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Create CheckpointSaverHook.
INFO:tensorflow:Graph was finalized.
INFO:tensorflow:Restoring parameters from /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt-3200
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
INFO:tensorflow:Saving checkpoints for 3200 into /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt.
DEBUG:tensorflow:Training iteration 3200 / 4000 (80.00%)
INFO:tensorflow:loss = 0.04313732, step = 3200
DEBUG:tensorflow:Training iteration 3210 / 4000 (80.25%)
DEBUG:tensorflow:Training iteration 3220 / 4000 (80.50%)
DEBUG:tensorflow:Training iteration 3230 / 4000 (80.75%)
DEBUG:tensorflow:Training iteration 3240 / 4000 (81.00%)
INFO:tensorflow:Saving checkpoints for 3240 into /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt.
INFO:tensorflow:Loss for final step: 0.065139234.
INFO:tensorflow:
-----------------------------------------
-----
---- Training model...
-----
DEBUG:tensorflow:Train data: epoch size = 5120
DEBUG:tensorflow:Train data: batch size = 128
DEBUG:tensorflow:Train data: num_epochs = 100
DEBUG:tensorflow:Train data: patch_size: [64, 64, 7]
DEBUG:tensorflow:Train data: feature[0].shape: (5120, 64, 64, 7)
DEBUG:tensorflow:Train data: target[0].shape: (5120, 64, 64, 1)
INFO:tensorflow:Augmenting training data
INFO:tensorflow:Peformed 2597 flips
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:Creating model...
DEBUG:tensorflow:Stacked data shape: (?, 64, 64, 7)
DEBUG:tensorflow:Input data shape: (64, 64, 7)
DEBUG:tensorflow:Rectified input data shape: (?, 64, 64, 7)
DEBUG:tensorflow:===== Creating U-Net model: U-Net
DEBUG:tensorflow:Training: True
DEBUG:tensorflow:Apply dropout: True
DEBUG:tensorflow:==== Convolution Layer 1
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:==== Convolution Layer 2
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:==== Convolution Layer 3
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:==== Middle Convolution Layer 
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 8, 8, 512)
DEBUG:tensorflow:Using dropout_rate=0.150000
DEBUG:tensorflow:feature shape: (?, 8, 8, 512)
DEBUG:tensorflow:Using dropout_rate=0.150000
DEBUG:tensorflow:===== Convolution Transpose Layer 3
DEBUG:tensorflow:upconv shape: (?, 16, 16, 256)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:===== Convolution Transpose Layer 2
DEBUG:tensorflow:upconv shape: (?, 32, 32, 128)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:===== Convolution Transpose Layer 1
DEBUG:tensorflow:upconv shape: (?, 64, 64, 64)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:===== Final Convolution Layer 1
DEBUG:tensorflow:feature shape: (?, 64, 64, 2)
DEBUG:tensorflow:=====
DEBUG:tensorflow:Model output layer shape = (?, 64, 64, 2)
INFO:tensorflow:Total number of trainable model parameters = 7,699,712
DEBUG:tensorflow:Labels shape = (?, 64, 64, 1)
INFO:tensorflow:Preparing loss function metric: CrossEntropy
INFO:tensorflow:Creating AdamOptimizer with learning-rate = 0.001, and learning-rate decay rate = 1.0
DEBUG:tensorflow:num_iterations_per_epoch = 40.000000
DEBUG:tensorflow:opt_decay_steps = 40.000000
DEBUG:tensorflow:opt_moving_average = 1.000000
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Create CheckpointSaverHook.
INFO:tensorflow:Graph was finalized.
INFO:tensorflow:Restoring parameters from /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt-3240
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
INFO:tensorflow:Saving checkpoints for 3240 into /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt.
DEBUG:tensorflow:Training iteration 3240 / 4000 (81.00%)
INFO:tensorflow:loss = 0.035698686, step = 3240
DEBUG:tensorflow:Training iteration 3250 / 4000 (81.25%)
DEBUG:tensorflow:Training iteration 3260 / 4000 (81.50%)
DEBUG:tensorflow:Training iteration 3270 / 4000 (81.75%)
DEBUG:tensorflow:Training iteration 3280 / 4000 (82.00%)
INFO:tensorflow:Saving checkpoints for 3280 into /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt.
INFO:tensorflow:Loss for final step: 0.042324.
INFO:tensorflow:
-----------------------------------------
-----
---- Training model...
-----
DEBUG:tensorflow:Train data: epoch size = 5120
DEBUG:tensorflow:Train data: batch size = 128
DEBUG:tensorflow:Train data: num_epochs = 100
DEBUG:tensorflow:Train data: patch_size: [64, 64, 7]
DEBUG:tensorflow:Train data: feature[0].shape: (5120, 64, 64, 7)
DEBUG:tensorflow:Train data: target[0].shape: (5120, 64, 64, 1)
INFO:tensorflow:Augmenting training data
INFO:tensorflow:Peformed 2549 flips
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:Creating model...
DEBUG:tensorflow:Stacked data shape: (?, 64, 64, 7)
DEBUG:tensorflow:Input data shape: (64, 64, 7)
DEBUG:tensorflow:Rectified input data shape: (?, 64, 64, 7)
DEBUG:tensorflow:===== Creating U-Net model: U-Net
DEBUG:tensorflow:Training: True
DEBUG:tensorflow:Apply dropout: True
DEBUG:tensorflow:==== Convolution Layer 1
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:==== Convolution Layer 2
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:==== Convolution Layer 3
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:==== Middle Convolution Layer 
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 8, 8, 512)
DEBUG:tensorflow:Using dropout_rate=0.150000
DEBUG:tensorflow:feature shape: (?, 8, 8, 512)
DEBUG:tensorflow:Using dropout_rate=0.150000
DEBUG:tensorflow:===== Convolution Transpose Layer 3
DEBUG:tensorflow:upconv shape: (?, 16, 16, 256)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:===== Convolution Transpose Layer 2
DEBUG:tensorflow:upconv shape: (?, 32, 32, 128)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:===== Convolution Transpose Layer 1
DEBUG:tensorflow:upconv shape: (?, 64, 64, 64)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:===== Final Convolution Layer 1
DEBUG:tensorflow:feature shape: (?, 64, 64, 2)
DEBUG:tensorflow:=====
DEBUG:tensorflow:Model output layer shape = (?, 64, 64, 2)
INFO:tensorflow:Total number of trainable model parameters = 7,699,712
DEBUG:tensorflow:Labels shape = (?, 64, 64, 1)
INFO:tensorflow:Preparing loss function metric: CrossEntropy
INFO:tensorflow:Creating AdamOptimizer with learning-rate = 0.001, and learning-rate decay rate = 1.0
DEBUG:tensorflow:num_iterations_per_epoch = 40.000000
DEBUG:tensorflow:opt_decay_steps = 40.000000
DEBUG:tensorflow:opt_moving_average = 1.000000
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Create CheckpointSaverHook.
INFO:tensorflow:Graph was finalized.
INFO:tensorflow:Restoring parameters from /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt-3280
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
INFO:tensorflow:Saving checkpoints for 3280 into /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt.
DEBUG:tensorflow:Training iteration 3280 / 4000 (82.00%)
INFO:tensorflow:loss = 0.053517923, step = 3280
DEBUG:tensorflow:Training iteration 3290 / 4000 (82.25%)
DEBUG:tensorflow:Training iteration 3300 / 4000 (82.50%)
DEBUG:tensorflow:Training iteration 3310 / 4000 (82.75%)
DEBUG:tensorflow:Training iteration 3320 / 4000 (83.00%)
INFO:tensorflow:Saving checkpoints for 3320 into /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt.
INFO:tensorflow:Loss for final step: 0.049550705.
INFO:tensorflow:
-----------------------------------------
-----
---- Training model...
-----
DEBUG:tensorflow:Train data: epoch size = 5120
DEBUG:tensorflow:Train data: batch size = 128
DEBUG:tensorflow:Train data: num_epochs = 100
DEBUG:tensorflow:Train data: patch_size: [64, 64, 7]
DEBUG:tensorflow:Train data: feature[0].shape: (5120, 64, 64, 7)
DEBUG:tensorflow:Train data: target[0].shape: (5120, 64, 64, 1)
INFO:tensorflow:Augmenting training data
INFO:tensorflow:Peformed 2601 flips
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:Creating model...
DEBUG:tensorflow:Stacked data shape: (?, 64, 64, 7)
DEBUG:tensorflow:Input data shape: (64, 64, 7)
DEBUG:tensorflow:Rectified input data shape: (?, 64, 64, 7)
DEBUG:tensorflow:===== Creating U-Net model: U-Net
DEBUG:tensorflow:Training: True
DEBUG:tensorflow:Apply dropout: True
DEBUG:tensorflow:==== Convolution Layer 1
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:==== Convolution Layer 2
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:==== Convolution Layer 3
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:==== Middle Convolution Layer 
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 8, 8, 512)
DEBUG:tensorflow:Using dropout_rate=0.150000
DEBUG:tensorflow:feature shape: (?, 8, 8, 512)
DEBUG:tensorflow:Using dropout_rate=0.150000
DEBUG:tensorflow:===== Convolution Transpose Layer 3
DEBUG:tensorflow:upconv shape: (?, 16, 16, 256)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:===== Convolution Transpose Layer 2
DEBUG:tensorflow:upconv shape: (?, 32, 32, 128)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:===== Convolution Transpose Layer 1
DEBUG:tensorflow:upconv shape: (?, 64, 64, 64)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:===== Final Convolution Layer 1
DEBUG:tensorflow:feature shape: (?, 64, 64, 2)
DEBUG:tensorflow:=====
DEBUG:tensorflow:Model output layer shape = (?, 64, 64, 2)
INFO:tensorflow:Total number of trainable model parameters = 7,699,712
DEBUG:tensorflow:Labels shape = (?, 64, 64, 1)
INFO:tensorflow:Preparing loss function metric: CrossEntropy
INFO:tensorflow:Creating AdamOptimizer with learning-rate = 0.001, and learning-rate decay rate = 1.0
DEBUG:tensorflow:num_iterations_per_epoch = 40.000000
DEBUG:tensorflow:opt_decay_steps = 40.000000
DEBUG:tensorflow:opt_moving_average = 1.000000
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Create CheckpointSaverHook.
INFO:tensorflow:Graph was finalized.
INFO:tensorflow:Restoring parameters from /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt-3320
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
INFO:tensorflow:Saving checkpoints for 3320 into /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt.
DEBUG:tensorflow:Training iteration 3320 / 4000 (83.00%)
INFO:tensorflow:loss = 0.04042361, step = 3320
DEBUG:tensorflow:Training iteration 3330 / 4000 (83.25%)
DEBUG:tensorflow:Training iteration 3340 / 4000 (83.50%)
DEBUG:tensorflow:Training iteration 3350 / 4000 (83.75%)
DEBUG:tensorflow:Training iteration 3360 / 4000 (84.00%)
INFO:tensorflow:Saving checkpoints for 3360 into /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt.
INFO:tensorflow:Loss for final step: 0.029310435.
INFO:tensorflow:
-----------------------------------------
-----
---- Training model...
-----
DEBUG:tensorflow:Train data: epoch size = 5120
DEBUG:tensorflow:Train data: batch size = 128
DEBUG:tensorflow:Train data: num_epochs = 100
DEBUG:tensorflow:Train data: patch_size: [64, 64, 7]
DEBUG:tensorflow:Train data: feature[0].shape: (5120, 64, 64, 7)
DEBUG:tensorflow:Train data: target[0].shape: (5120, 64, 64, 1)
INFO:tensorflow:Augmenting training data
INFO:tensorflow:Peformed 2511 flips
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:Creating model...
DEBUG:tensorflow:Stacked data shape: (?, 64, 64, 7)
DEBUG:tensorflow:Input data shape: (64, 64, 7)
DEBUG:tensorflow:Rectified input data shape: (?, 64, 64, 7)
DEBUG:tensorflow:===== Creating U-Net model: U-Net
DEBUG:tensorflow:Training: True
DEBUG:tensorflow:Apply dropout: True
DEBUG:tensorflow:==== Convolution Layer 1
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:==== Convolution Layer 2
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:==== Convolution Layer 3
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:==== Middle Convolution Layer 
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 8, 8, 512)
DEBUG:tensorflow:Using dropout_rate=0.150000
DEBUG:tensorflow:feature shape: (?, 8, 8, 512)
DEBUG:tensorflow:Using dropout_rate=0.150000
DEBUG:tensorflow:===== Convolution Transpose Layer 3
DEBUG:tensorflow:upconv shape: (?, 16, 16, 256)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:===== Convolution Transpose Layer 2
DEBUG:tensorflow:upconv shape: (?, 32, 32, 128)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:===== Convolution Transpose Layer 1
DEBUG:tensorflow:upconv shape: (?, 64, 64, 64)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:===== Final Convolution Layer 1
DEBUG:tensorflow:feature shape: (?, 64, 64, 2)
DEBUG:tensorflow:=====
DEBUG:tensorflow:Model output layer shape = (?, 64, 64, 2)
INFO:tensorflow:Total number of trainable model parameters = 7,699,712
DEBUG:tensorflow:Labels shape = (?, 64, 64, 1)
INFO:tensorflow:Preparing loss function metric: CrossEntropy
INFO:tensorflow:Creating AdamOptimizer with learning-rate = 0.001, and learning-rate decay rate = 1.0
DEBUG:tensorflow:num_iterations_per_epoch = 40.000000
DEBUG:tensorflow:opt_decay_steps = 40.000000
DEBUG:tensorflow:opt_moving_average = 1.000000
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Create CheckpointSaverHook.
INFO:tensorflow:Graph was finalized.
INFO:tensorflow:Restoring parameters from /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt-3360
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
INFO:tensorflow:Saving checkpoints for 3360 into /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt.
DEBUG:tensorflow:Training iteration 3360 / 4000 (84.00%)
INFO:tensorflow:loss = 0.04456997, step = 3360
DEBUG:tensorflow:Training iteration 3370 / 4000 (84.25%)
DEBUG:tensorflow:Training iteration 3380 / 4000 (84.50%)
DEBUG:tensorflow:Training iteration 3390 / 4000 (84.75%)
DEBUG:tensorflow:Training iteration 3400 / 4000 (85.00%)
INFO:tensorflow:Saving checkpoints for 3400 into /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt.
INFO:tensorflow:Loss for final step: 0.047125883.
INFO:tensorflow:
-----------------------------------------
-----
---- Training model...
-----
DEBUG:tensorflow:Train data: epoch size = 5120
DEBUG:tensorflow:Train data: batch size = 128
DEBUG:tensorflow:Train data: num_epochs = 100
DEBUG:tensorflow:Train data: patch_size: [64, 64, 7]
DEBUG:tensorflow:Train data: feature[0].shape: (5120, 64, 64, 7)
DEBUG:tensorflow:Train data: target[0].shape: (5120, 64, 64, 1)
INFO:tensorflow:Augmenting training data
INFO:tensorflow:Peformed 2578 flips
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:Creating model...
DEBUG:tensorflow:Stacked data shape: (?, 64, 64, 7)
DEBUG:tensorflow:Input data shape: (64, 64, 7)
DEBUG:tensorflow:Rectified input data shape: (?, 64, 64, 7)
DEBUG:tensorflow:===== Creating U-Net model: U-Net
DEBUG:tensorflow:Training: True
DEBUG:tensorflow:Apply dropout: True
DEBUG:tensorflow:==== Convolution Layer 1
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:==== Convolution Layer 2
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:==== Convolution Layer 3
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:==== Middle Convolution Layer 
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 8, 8, 512)
DEBUG:tensorflow:Using dropout_rate=0.150000
DEBUG:tensorflow:feature shape: (?, 8, 8, 512)
DEBUG:tensorflow:Using dropout_rate=0.150000
DEBUG:tensorflow:===== Convolution Transpose Layer 3
DEBUG:tensorflow:upconv shape: (?, 16, 16, 256)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:===== Convolution Transpose Layer 2
DEBUG:tensorflow:upconv shape: (?, 32, 32, 128)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:===== Convolution Transpose Layer 1
DEBUG:tensorflow:upconv shape: (?, 64, 64, 64)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:===== Final Convolution Layer 1
DEBUG:tensorflow:feature shape: (?, 64, 64, 2)
DEBUG:tensorflow:=====
DEBUG:tensorflow:Model output layer shape = (?, 64, 64, 2)
INFO:tensorflow:Total number of trainable model parameters = 7,699,712
DEBUG:tensorflow:Labels shape = (?, 64, 64, 1)
INFO:tensorflow:Preparing loss function metric: CrossEntropy
INFO:tensorflow:Creating AdamOptimizer with learning-rate = 0.001, and learning-rate decay rate = 1.0
DEBUG:tensorflow:num_iterations_per_epoch = 40.000000
DEBUG:tensorflow:opt_decay_steps = 40.000000
DEBUG:tensorflow:opt_moving_average = 1.000000
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Create CheckpointSaverHook.
INFO:tensorflow:Graph was finalized.
INFO:tensorflow:Restoring parameters from /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt-3400
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
INFO:tensorflow:Saving checkpoints for 3400 into /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt.
DEBUG:tensorflow:Training iteration 3400 / 4000 (85.00%)
INFO:tensorflow:loss = 0.037136044, step = 3400
DEBUG:tensorflow:Training iteration 3410 / 4000 (85.25%)
DEBUG:tensorflow:Training iteration 3420 / 4000 (85.50%)
DEBUG:tensorflow:Training iteration 3430 / 4000 (85.75%)
DEBUG:tensorflow:Training iteration 3440 / 4000 (86.00%)
INFO:tensorflow:Saving checkpoints for 3440 into /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt.
INFO:tensorflow:Loss for final step: 0.042899936.
INFO:tensorflow:
-----------------------------------------
-----
---- Training model...
-----
DEBUG:tensorflow:Train data: epoch size = 5120
DEBUG:tensorflow:Train data: batch size = 128
DEBUG:tensorflow:Train data: num_epochs = 100
DEBUG:tensorflow:Train data: patch_size: [64, 64, 7]
DEBUG:tensorflow:Train data: feature[0].shape: (5120, 64, 64, 7)
DEBUG:tensorflow:Train data: target[0].shape: (5120, 64, 64, 1)
INFO:tensorflow:Augmenting training data
INFO:tensorflow:Peformed 2564 flips
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:Creating model...
DEBUG:tensorflow:Stacked data shape: (?, 64, 64, 7)
DEBUG:tensorflow:Input data shape: (64, 64, 7)
DEBUG:tensorflow:Rectified input data shape: (?, 64, 64, 7)
DEBUG:tensorflow:===== Creating U-Net model: U-Net
DEBUG:tensorflow:Training: True
DEBUG:tensorflow:Apply dropout: True
DEBUG:tensorflow:==== Convolution Layer 1
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:==== Convolution Layer 2
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:==== Convolution Layer 3
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:==== Middle Convolution Layer 
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 8, 8, 512)
DEBUG:tensorflow:Using dropout_rate=0.150000
DEBUG:tensorflow:feature shape: (?, 8, 8, 512)
DEBUG:tensorflow:Using dropout_rate=0.150000
DEBUG:tensorflow:===== Convolution Transpose Layer 3
DEBUG:tensorflow:upconv shape: (?, 16, 16, 256)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:===== Convolution Transpose Layer 2
DEBUG:tensorflow:upconv shape: (?, 32, 32, 128)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:===== Convolution Transpose Layer 1
DEBUG:tensorflow:upconv shape: (?, 64, 64, 64)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:===== Final Convolution Layer 1
DEBUG:tensorflow:feature shape: (?, 64, 64, 2)
DEBUG:tensorflow:=====
DEBUG:tensorflow:Model output layer shape = (?, 64, 64, 2)
INFO:tensorflow:Total number of trainable model parameters = 7,699,712
DEBUG:tensorflow:Labels shape = (?, 64, 64, 1)
INFO:tensorflow:Preparing loss function metric: CrossEntropy
INFO:tensorflow:Creating AdamOptimizer with learning-rate = 0.001, and learning-rate decay rate = 1.0
DEBUG:tensorflow:num_iterations_per_epoch = 40.000000
DEBUG:tensorflow:opt_decay_steps = 40.000000
DEBUG:tensorflow:opt_moving_average = 1.000000
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Create CheckpointSaverHook.
INFO:tensorflow:Graph was finalized.
INFO:tensorflow:Restoring parameters from /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt-3440
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
INFO:tensorflow:Saving checkpoints for 3440 into /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt.
DEBUG:tensorflow:Training iteration 3440 / 4000 (86.00%)
INFO:tensorflow:loss = 0.042151995, step = 3440
DEBUG:tensorflow:Training iteration 3450 / 4000 (86.25%)
DEBUG:tensorflow:Training iteration 3460 / 4000 (86.50%)
DEBUG:tensorflow:Training iteration 3470 / 4000 (86.75%)
DEBUG:tensorflow:Training iteration 3480 / 4000 (87.00%)
INFO:tensorflow:Saving checkpoints for 3480 into /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt.
INFO:tensorflow:Loss for final step: 0.0355668.
INFO:tensorflow:
-----------------------------------------
-----
---- Training model...
-----
DEBUG:tensorflow:Train data: epoch size = 5120
DEBUG:tensorflow:Train data: batch size = 128
DEBUG:tensorflow:Train data: num_epochs = 100
DEBUG:tensorflow:Train data: patch_size: [64, 64, 7]
DEBUG:tensorflow:Train data: feature[0].shape: (5120, 64, 64, 7)
DEBUG:tensorflow:Train data: target[0].shape: (5120, 64, 64, 1)
INFO:tensorflow:Augmenting training data
INFO:tensorflow:Peformed 2491 flips
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:Creating model...
DEBUG:tensorflow:Stacked data shape: (?, 64, 64, 7)
DEBUG:tensorflow:Input data shape: (64, 64, 7)
DEBUG:tensorflow:Rectified input data shape: (?, 64, 64, 7)
DEBUG:tensorflow:===== Creating U-Net model: U-Net
DEBUG:tensorflow:Training: True
DEBUG:tensorflow:Apply dropout: True
DEBUG:tensorflow:==== Convolution Layer 1
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:==== Convolution Layer 2
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:==== Convolution Layer 3
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:==== Middle Convolution Layer 
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 8, 8, 512)
DEBUG:tensorflow:Using dropout_rate=0.150000
DEBUG:tensorflow:feature shape: (?, 8, 8, 512)
DEBUG:tensorflow:Using dropout_rate=0.150000
DEBUG:tensorflow:===== Convolution Transpose Layer 3
DEBUG:tensorflow:upconv shape: (?, 16, 16, 256)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:===== Convolution Transpose Layer 2
DEBUG:tensorflow:upconv shape: (?, 32, 32, 128)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:===== Convolution Transpose Layer 1
DEBUG:tensorflow:upconv shape: (?, 64, 64, 64)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:===== Final Convolution Layer 1
DEBUG:tensorflow:feature shape: (?, 64, 64, 2)
DEBUG:tensorflow:=====
DEBUG:tensorflow:Model output layer shape = (?, 64, 64, 2)
INFO:tensorflow:Total number of trainable model parameters = 7,699,712
DEBUG:tensorflow:Labels shape = (?, 64, 64, 1)
INFO:tensorflow:Preparing loss function metric: CrossEntropy
INFO:tensorflow:Creating AdamOptimizer with learning-rate = 0.001, and learning-rate decay rate = 1.0
DEBUG:tensorflow:num_iterations_per_epoch = 40.000000
DEBUG:tensorflow:opt_decay_steps = 40.000000
DEBUG:tensorflow:opt_moving_average = 1.000000
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Create CheckpointSaverHook.
INFO:tensorflow:Graph was finalized.
INFO:tensorflow:Restoring parameters from /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt-3480
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
INFO:tensorflow:Saving checkpoints for 3480 into /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt.
DEBUG:tensorflow:Training iteration 3480 / 4000 (87.00%)
INFO:tensorflow:loss = 0.033841584, step = 3480
DEBUG:tensorflow:Training iteration 3490 / 4000 (87.25%)
DEBUG:tensorflow:Training iteration 3500 / 4000 (87.50%)
DEBUG:tensorflow:Training iteration 3510 / 4000 (87.75%)
DEBUG:tensorflow:Training iteration 3520 / 4000 (88.00%)
INFO:tensorflow:Saving checkpoints for 3520 into /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt.
INFO:tensorflow:Loss for final step: 0.03522177.
INFO:tensorflow:
-----------------------------------------
-----
---- Training model...
-----
DEBUG:tensorflow:Train data: epoch size = 5120
DEBUG:tensorflow:Train data: batch size = 128
DEBUG:tensorflow:Train data: num_epochs = 100
DEBUG:tensorflow:Train data: patch_size: [64, 64, 7]
DEBUG:tensorflow:Train data: feature[0].shape: (5120, 64, 64, 7)
DEBUG:tensorflow:Train data: target[0].shape: (5120, 64, 64, 1)
INFO:tensorflow:Augmenting training data
INFO:tensorflow:Peformed 2608 flips
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:Creating model...
DEBUG:tensorflow:Stacked data shape: (?, 64, 64, 7)
DEBUG:tensorflow:Input data shape: (64, 64, 7)
DEBUG:tensorflow:Rectified input data shape: (?, 64, 64, 7)
DEBUG:tensorflow:===== Creating U-Net model: U-Net
DEBUG:tensorflow:Training: True
DEBUG:tensorflow:Apply dropout: True
DEBUG:tensorflow:==== Convolution Layer 1
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:==== Convolution Layer 2
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:==== Convolution Layer 3
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:==== Middle Convolution Layer 
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 8, 8, 512)
DEBUG:tensorflow:Using dropout_rate=0.150000
DEBUG:tensorflow:feature shape: (?, 8, 8, 512)
DEBUG:tensorflow:Using dropout_rate=0.150000
DEBUG:tensorflow:===== Convolution Transpose Layer 3
DEBUG:tensorflow:upconv shape: (?, 16, 16, 256)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:===== Convolution Transpose Layer 2
DEBUG:tensorflow:upconv shape: (?, 32, 32, 128)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:===== Convolution Transpose Layer 1
DEBUG:tensorflow:upconv shape: (?, 64, 64, 64)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:===== Final Convolution Layer 1
DEBUG:tensorflow:feature shape: (?, 64, 64, 2)
DEBUG:tensorflow:=====
DEBUG:tensorflow:Model output layer shape = (?, 64, 64, 2)
INFO:tensorflow:Total number of trainable model parameters = 7,699,712
DEBUG:tensorflow:Labels shape = (?, 64, 64, 1)
INFO:tensorflow:Preparing loss function metric: CrossEntropy
INFO:tensorflow:Creating AdamOptimizer with learning-rate = 0.001, and learning-rate decay rate = 1.0
DEBUG:tensorflow:num_iterations_per_epoch = 40.000000
DEBUG:tensorflow:opt_decay_steps = 40.000000
DEBUG:tensorflow:opt_moving_average = 1.000000
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Create CheckpointSaverHook.
INFO:tensorflow:Graph was finalized.
INFO:tensorflow:Restoring parameters from /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt-3520
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
INFO:tensorflow:Saving checkpoints for 3520 into /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt.
DEBUG:tensorflow:Training iteration 3520 / 4000 (88.00%)
INFO:tensorflow:loss = 0.042757794, step = 3520
DEBUG:tensorflow:Training iteration 3530 / 4000 (88.25%)
DEBUG:tensorflow:Training iteration 3540 / 4000 (88.50%)
DEBUG:tensorflow:Training iteration 3550 / 4000 (88.75%)
DEBUG:tensorflow:Training iteration 3560 / 4000 (89.00%)
INFO:tensorflow:Saving checkpoints for 3560 into /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt.
INFO:tensorflow:Loss for final step: 0.033474363.
INFO:tensorflow:
-----------------------------------------
-----
---- Training model...
-----
DEBUG:tensorflow:Train data: epoch size = 5120
DEBUG:tensorflow:Train data: batch size = 128
DEBUG:tensorflow:Train data: num_epochs = 100
DEBUG:tensorflow:Train data: patch_size: [64, 64, 7]
DEBUG:tensorflow:Train data: feature[0].shape: (5120, 64, 64, 7)
DEBUG:tensorflow:Train data: target[0].shape: (5120, 64, 64, 1)
INFO:tensorflow:Augmenting training data
INFO:tensorflow:Peformed 2568 flips
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:Creating model...
DEBUG:tensorflow:Stacked data shape: (?, 64, 64, 7)
DEBUG:tensorflow:Input data shape: (64, 64, 7)
DEBUG:tensorflow:Rectified input data shape: (?, 64, 64, 7)
DEBUG:tensorflow:===== Creating U-Net model: U-Net
DEBUG:tensorflow:Training: True
DEBUG:tensorflow:Apply dropout: True
DEBUG:tensorflow:==== Convolution Layer 1
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:==== Convolution Layer 2
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:==== Convolution Layer 3
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:==== Middle Convolution Layer 
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 8, 8, 512)
DEBUG:tensorflow:Using dropout_rate=0.150000
DEBUG:tensorflow:feature shape: (?, 8, 8, 512)
DEBUG:tensorflow:Using dropout_rate=0.150000
DEBUG:tensorflow:===== Convolution Transpose Layer 3
DEBUG:tensorflow:upconv shape: (?, 16, 16, 256)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:===== Convolution Transpose Layer 2
DEBUG:tensorflow:upconv shape: (?, 32, 32, 128)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:===== Convolution Transpose Layer 1
DEBUG:tensorflow:upconv shape: (?, 64, 64, 64)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:===== Final Convolution Layer 1
DEBUG:tensorflow:feature shape: (?, 64, 64, 2)
DEBUG:tensorflow:=====
DEBUG:tensorflow:Model output layer shape = (?, 64, 64, 2)
INFO:tensorflow:Total number of trainable model parameters = 7,699,712
DEBUG:tensorflow:Labels shape = (?, 64, 64, 1)
INFO:tensorflow:Preparing loss function metric: CrossEntropy
INFO:tensorflow:Creating AdamOptimizer with learning-rate = 0.001, and learning-rate decay rate = 1.0
DEBUG:tensorflow:num_iterations_per_epoch = 40.000000
DEBUG:tensorflow:opt_decay_steps = 40.000000
DEBUG:tensorflow:opt_moving_average = 1.000000
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Create CheckpointSaverHook.
INFO:tensorflow:Graph was finalized.
INFO:tensorflow:Restoring parameters from /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt-3560
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
INFO:tensorflow:Saving checkpoints for 3560 into /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt.
DEBUG:tensorflow:Training iteration 3560 / 4000 (89.00%)
INFO:tensorflow:loss = 0.035023034, step = 3560
DEBUG:tensorflow:Training iteration 3570 / 4000 (89.25%)
DEBUG:tensorflow:Training iteration 3580 / 4000 (89.50%)
DEBUG:tensorflow:Training iteration 3590 / 4000 (89.75%)
DEBUG:tensorflow:Training iteration 3600 / 4000 (90.00%)
INFO:tensorflow:Saving checkpoints for 3600 into /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt.
INFO:tensorflow:Loss for final step: 0.040958825.
INFO:tensorflow:
-----------------------------------------
-----
---- Training model...
-----
DEBUG:tensorflow:Train data: epoch size = 5120
DEBUG:tensorflow:Train data: batch size = 128
DEBUG:tensorflow:Train data: num_epochs = 100
DEBUG:tensorflow:Train data: patch_size: [64, 64, 7]
DEBUG:tensorflow:Train data: feature[0].shape: (5120, 64, 64, 7)
DEBUG:tensorflow:Train data: target[0].shape: (5120, 64, 64, 1)
INFO:tensorflow:Augmenting training data
INFO:tensorflow:Peformed 2564 flips
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:Creating model...
DEBUG:tensorflow:Stacked data shape: (?, 64, 64, 7)
DEBUG:tensorflow:Input data shape: (64, 64, 7)
DEBUG:tensorflow:Rectified input data shape: (?, 64, 64, 7)
DEBUG:tensorflow:===== Creating U-Net model: U-Net
DEBUG:tensorflow:Training: True
DEBUG:tensorflow:Apply dropout: True
DEBUG:tensorflow:==== Convolution Layer 1
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:==== Convolution Layer 2
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:==== Convolution Layer 3
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:==== Middle Convolution Layer 
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 8, 8, 512)
DEBUG:tensorflow:Using dropout_rate=0.150000
DEBUG:tensorflow:feature shape: (?, 8, 8, 512)
DEBUG:tensorflow:Using dropout_rate=0.150000
DEBUG:tensorflow:===== Convolution Transpose Layer 3
DEBUG:tensorflow:upconv shape: (?, 16, 16, 256)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:===== Convolution Transpose Layer 2
DEBUG:tensorflow:upconv shape: (?, 32, 32, 128)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:===== Convolution Transpose Layer 1
DEBUG:tensorflow:upconv shape: (?, 64, 64, 64)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:===== Final Convolution Layer 1
DEBUG:tensorflow:feature shape: (?, 64, 64, 2)
DEBUG:tensorflow:=====
DEBUG:tensorflow:Model output layer shape = (?, 64, 64, 2)
INFO:tensorflow:Total number of trainable model parameters = 7,699,712
DEBUG:tensorflow:Labels shape = (?, 64, 64, 1)
INFO:tensorflow:Preparing loss function metric: CrossEntropy
INFO:tensorflow:Creating AdamOptimizer with learning-rate = 0.001, and learning-rate decay rate = 1.0
DEBUG:tensorflow:num_iterations_per_epoch = 40.000000
DEBUG:tensorflow:opt_decay_steps = 40.000000
DEBUG:tensorflow:opt_moving_average = 1.000000
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Create CheckpointSaverHook.
INFO:tensorflow:Graph was finalized.
INFO:tensorflow:Restoring parameters from /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt-3600
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
INFO:tensorflow:Saving checkpoints for 3600 into /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt.
DEBUG:tensorflow:Training iteration 3600 / 4000 (90.00%)
INFO:tensorflow:loss = 0.050654612, step = 3600
DEBUG:tensorflow:Training iteration 3610 / 4000 (90.25%)
DEBUG:tensorflow:Training iteration 3620 / 4000 (90.50%)
DEBUG:tensorflow:Training iteration 3630 / 4000 (90.75%)
DEBUG:tensorflow:Training iteration 3640 / 4000 (91.00%)
INFO:tensorflow:Saving checkpoints for 3640 into /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt.
INFO:tensorflow:Loss for final step: 0.07227504.
INFO:tensorflow:
-----------------------------------------
-----
---- Training model...
-----
DEBUG:tensorflow:Train data: epoch size = 5120
DEBUG:tensorflow:Train data: batch size = 128
DEBUG:tensorflow:Train data: num_epochs = 100
DEBUG:tensorflow:Train data: patch_size: [64, 64, 7]
DEBUG:tensorflow:Train data: feature[0].shape: (5120, 64, 64, 7)
DEBUG:tensorflow:Train data: target[0].shape: (5120, 64, 64, 1)
INFO:tensorflow:Augmenting training data
INFO:tensorflow:Peformed 2620 flips
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:Creating model...
DEBUG:tensorflow:Stacked data shape: (?, 64, 64, 7)
DEBUG:tensorflow:Input data shape: (64, 64, 7)
DEBUG:tensorflow:Rectified input data shape: (?, 64, 64, 7)
DEBUG:tensorflow:===== Creating U-Net model: U-Net
DEBUG:tensorflow:Training: True
DEBUG:tensorflow:Apply dropout: True
DEBUG:tensorflow:==== Convolution Layer 1
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:==== Convolution Layer 2
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:==== Convolution Layer 3
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:==== Middle Convolution Layer 
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 8, 8, 512)
DEBUG:tensorflow:Using dropout_rate=0.150000
DEBUG:tensorflow:feature shape: (?, 8, 8, 512)
DEBUG:tensorflow:Using dropout_rate=0.150000
DEBUG:tensorflow:===== Convolution Transpose Layer 3
DEBUG:tensorflow:upconv shape: (?, 16, 16, 256)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:===== Convolution Transpose Layer 2
DEBUG:tensorflow:upconv shape: (?, 32, 32, 128)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:===== Convolution Transpose Layer 1
DEBUG:tensorflow:upconv shape: (?, 64, 64, 64)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:===== Final Convolution Layer 1
DEBUG:tensorflow:feature shape: (?, 64, 64, 2)
DEBUG:tensorflow:=====
DEBUG:tensorflow:Model output layer shape = (?, 64, 64, 2)
INFO:tensorflow:Total number of trainable model parameters = 7,699,712
DEBUG:tensorflow:Labels shape = (?, 64, 64, 1)
INFO:tensorflow:Preparing loss function metric: CrossEntropy
INFO:tensorflow:Creating AdamOptimizer with learning-rate = 0.001, and learning-rate decay rate = 1.0
DEBUG:tensorflow:num_iterations_per_epoch = 40.000000
DEBUG:tensorflow:opt_decay_steps = 40.000000
DEBUG:tensorflow:opt_moving_average = 1.000000
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Create CheckpointSaverHook.
INFO:tensorflow:Graph was finalized.
INFO:tensorflow:Restoring parameters from /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt-3640
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
INFO:tensorflow:Saving checkpoints for 3640 into /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt.
DEBUG:tensorflow:Training iteration 3640 / 4000 (91.00%)
INFO:tensorflow:loss = 0.051797237, step = 3640
DEBUG:tensorflow:Training iteration 3650 / 4000 (91.25%)
DEBUG:tensorflow:Training iteration 3660 / 4000 (91.50%)
DEBUG:tensorflow:Training iteration 3670 / 4000 (91.75%)
DEBUG:tensorflow:Training iteration 3680 / 4000 (92.00%)
INFO:tensorflow:Saving checkpoints for 3680 into /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt.
INFO:tensorflow:Loss for final step: 0.032815605.
INFO:tensorflow:
-----------------------------------------
-----
---- Training model...
-----
DEBUG:tensorflow:Train data: epoch size = 5120
DEBUG:tensorflow:Train data: batch size = 128
DEBUG:tensorflow:Train data: num_epochs = 100
DEBUG:tensorflow:Train data: patch_size: [64, 64, 7]
DEBUG:tensorflow:Train data: feature[0].shape: (5120, 64, 64, 7)
DEBUG:tensorflow:Train data: target[0].shape: (5120, 64, 64, 1)
INFO:tensorflow:Augmenting training data
INFO:tensorflow:Peformed 2539 flips
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:Creating model...
DEBUG:tensorflow:Stacked data shape: (?, 64, 64, 7)
DEBUG:tensorflow:Input data shape: (64, 64, 7)
DEBUG:tensorflow:Rectified input data shape: (?, 64, 64, 7)
DEBUG:tensorflow:===== Creating U-Net model: U-Net
DEBUG:tensorflow:Training: True
DEBUG:tensorflow:Apply dropout: True
DEBUG:tensorflow:==== Convolution Layer 1
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:==== Convolution Layer 2
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:==== Convolution Layer 3
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:==== Middle Convolution Layer 
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 8, 8, 512)
DEBUG:tensorflow:Using dropout_rate=0.150000
DEBUG:tensorflow:feature shape: (?, 8, 8, 512)
DEBUG:tensorflow:Using dropout_rate=0.150000
DEBUG:tensorflow:===== Convolution Transpose Layer 3
DEBUG:tensorflow:upconv shape: (?, 16, 16, 256)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:===== Convolution Transpose Layer 2
DEBUG:tensorflow:upconv shape: (?, 32, 32, 128)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:===== Convolution Transpose Layer 1
DEBUG:tensorflow:upconv shape: (?, 64, 64, 64)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:===== Final Convolution Layer 1
DEBUG:tensorflow:feature shape: (?, 64, 64, 2)
DEBUG:tensorflow:=====
DEBUG:tensorflow:Model output layer shape = (?, 64, 64, 2)
INFO:tensorflow:Total number of trainable model parameters = 7,699,712
DEBUG:tensorflow:Labels shape = (?, 64, 64, 1)
INFO:tensorflow:Preparing loss function metric: CrossEntropy
INFO:tensorflow:Creating AdamOptimizer with learning-rate = 0.001, and learning-rate decay rate = 1.0
DEBUG:tensorflow:num_iterations_per_epoch = 40.000000
DEBUG:tensorflow:opt_decay_steps = 40.000000
DEBUG:tensorflow:opt_moving_average = 1.000000
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Create CheckpointSaverHook.
INFO:tensorflow:Graph was finalized.
INFO:tensorflow:Restoring parameters from /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt-3680
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
INFO:tensorflow:Saving checkpoints for 3680 into /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt.
DEBUG:tensorflow:Training iteration 3680 / 4000 (92.00%)
INFO:tensorflow:loss = 0.064694256, step = 3680
DEBUG:tensorflow:Training iteration 3690 / 4000 (92.25%)
DEBUG:tensorflow:Training iteration 3700 / 4000 (92.50%)
DEBUG:tensorflow:Training iteration 3710 / 4000 (92.75%)
DEBUG:tensorflow:Training iteration 3720 / 4000 (93.00%)
INFO:tensorflow:Saving checkpoints for 3720 into /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt.
INFO:tensorflow:Loss for final step: 0.037462577.
INFO:tensorflow:
-----------------------------------------
-----
---- Training model...
-----
DEBUG:tensorflow:Train data: epoch size = 5120
DEBUG:tensorflow:Train data: batch size = 128
DEBUG:tensorflow:Train data: num_epochs = 100
DEBUG:tensorflow:Train data: patch_size: [64, 64, 7]
DEBUG:tensorflow:Train data: feature[0].shape: (5120, 64, 64, 7)
DEBUG:tensorflow:Train data: target[0].shape: (5120, 64, 64, 1)
INFO:tensorflow:Augmenting training data
INFO:tensorflow:Peformed 2616 flips
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:Creating model...
DEBUG:tensorflow:Stacked data shape: (?, 64, 64, 7)
DEBUG:tensorflow:Input data shape: (64, 64, 7)
DEBUG:tensorflow:Rectified input data shape: (?, 64, 64, 7)
DEBUG:tensorflow:===== Creating U-Net model: U-Net
DEBUG:tensorflow:Training: True
DEBUG:tensorflow:Apply dropout: True
DEBUG:tensorflow:==== Convolution Layer 1
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:==== Convolution Layer 2
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:==== Convolution Layer 3
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:==== Middle Convolution Layer 
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 8, 8, 512)
DEBUG:tensorflow:Using dropout_rate=0.150000
DEBUG:tensorflow:feature shape: (?, 8, 8, 512)
DEBUG:tensorflow:Using dropout_rate=0.150000
DEBUG:tensorflow:===== Convolution Transpose Layer 3
DEBUG:tensorflow:upconv shape: (?, 16, 16, 256)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:===== Convolution Transpose Layer 2
DEBUG:tensorflow:upconv shape: (?, 32, 32, 128)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:===== Convolution Transpose Layer 1
DEBUG:tensorflow:upconv shape: (?, 64, 64, 64)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:===== Final Convolution Layer 1
DEBUG:tensorflow:feature shape: (?, 64, 64, 2)
DEBUG:tensorflow:=====
DEBUG:tensorflow:Model output layer shape = (?, 64, 64, 2)
INFO:tensorflow:Total number of trainable model parameters = 7,699,712
DEBUG:tensorflow:Labels shape = (?, 64, 64, 1)
INFO:tensorflow:Preparing loss function metric: CrossEntropy
INFO:tensorflow:Creating AdamOptimizer with learning-rate = 0.001, and learning-rate decay rate = 1.0
DEBUG:tensorflow:num_iterations_per_epoch = 40.000000
DEBUG:tensorflow:opt_decay_steps = 40.000000
DEBUG:tensorflow:opt_moving_average = 1.000000
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Create CheckpointSaverHook.
INFO:tensorflow:Graph was finalized.
INFO:tensorflow:Restoring parameters from /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt-3720
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
INFO:tensorflow:Saving checkpoints for 3720 into /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt.
DEBUG:tensorflow:Training iteration 3720 / 4000 (93.00%)
INFO:tensorflow:loss = 0.04399521, step = 3720
DEBUG:tensorflow:Training iteration 3730 / 4000 (93.25%)
DEBUG:tensorflow:Training iteration 3740 / 4000 (93.50%)
DEBUG:tensorflow:Training iteration 3750 / 4000 (93.75%)
DEBUG:tensorflow:Training iteration 3760 / 4000 (94.00%)
INFO:tensorflow:Saving checkpoints for 3760 into /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt.
INFO:tensorflow:Loss for final step: 0.034148037.
INFO:tensorflow:
-----------------------------------------
-----
---- Training model...
-----
DEBUG:tensorflow:Train data: epoch size = 5120
DEBUG:tensorflow:Train data: batch size = 128
DEBUG:tensorflow:Train data: num_epochs = 100
DEBUG:tensorflow:Train data: patch_size: [64, 64, 7]
DEBUG:tensorflow:Train data: feature[0].shape: (5120, 64, 64, 7)
DEBUG:tensorflow:Train data: target[0].shape: (5120, 64, 64, 1)
INFO:tensorflow:Augmenting training data
INFO:tensorflow:Peformed 2595 flips
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:Creating model...
DEBUG:tensorflow:Stacked data shape: (?, 64, 64, 7)
DEBUG:tensorflow:Input data shape: (64, 64, 7)
DEBUG:tensorflow:Rectified input data shape: (?, 64, 64, 7)
DEBUG:tensorflow:===== Creating U-Net model: U-Net
DEBUG:tensorflow:Training: True
DEBUG:tensorflow:Apply dropout: True
DEBUG:tensorflow:==== Convolution Layer 1
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:==== Convolution Layer 2
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:==== Convolution Layer 3
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:==== Middle Convolution Layer 
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 8, 8, 512)
DEBUG:tensorflow:Using dropout_rate=0.150000
DEBUG:tensorflow:feature shape: (?, 8, 8, 512)
DEBUG:tensorflow:Using dropout_rate=0.150000
DEBUG:tensorflow:===== Convolution Transpose Layer 3
DEBUG:tensorflow:upconv shape: (?, 16, 16, 256)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:===== Convolution Transpose Layer 2
DEBUG:tensorflow:upconv shape: (?, 32, 32, 128)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:===== Convolution Transpose Layer 1
DEBUG:tensorflow:upconv shape: (?, 64, 64, 64)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:===== Final Convolution Layer 1
DEBUG:tensorflow:feature shape: (?, 64, 64, 2)
DEBUG:tensorflow:=====
DEBUG:tensorflow:Model output layer shape = (?, 64, 64, 2)
INFO:tensorflow:Total number of trainable model parameters = 7,699,712
DEBUG:tensorflow:Labels shape = (?, 64, 64, 1)
INFO:tensorflow:Preparing loss function metric: CrossEntropy
INFO:tensorflow:Creating AdamOptimizer with learning-rate = 0.001, and learning-rate decay rate = 1.0
DEBUG:tensorflow:num_iterations_per_epoch = 40.000000
DEBUG:tensorflow:opt_decay_steps = 40.000000
DEBUG:tensorflow:opt_moving_average = 1.000000
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Create CheckpointSaverHook.
INFO:tensorflow:Graph was finalized.
INFO:tensorflow:Restoring parameters from /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt-3760
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
INFO:tensorflow:Saving checkpoints for 3760 into /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt.
DEBUG:tensorflow:Training iteration 3760 / 4000 (94.00%)
INFO:tensorflow:loss = 0.028700996, step = 3760
DEBUG:tensorflow:Training iteration 3770 / 4000 (94.25%)
DEBUG:tensorflow:Training iteration 3780 / 4000 (94.50%)
DEBUG:tensorflow:Training iteration 3790 / 4000 (94.75%)
DEBUG:tensorflow:Training iteration 3800 / 4000 (95.00%)
INFO:tensorflow:Saving checkpoints for 3800 into /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt.
INFO:tensorflow:Loss for final step: 0.042979073.
INFO:tensorflow:
-----------------------------------------
-----
---- Training model...
-----
DEBUG:tensorflow:Train data: epoch size = 5120
DEBUG:tensorflow:Train data: batch size = 128
DEBUG:tensorflow:Train data: num_epochs = 100
DEBUG:tensorflow:Train data: patch_size: [64, 64, 7]
DEBUG:tensorflow:Train data: feature[0].shape: (5120, 64, 64, 7)
DEBUG:tensorflow:Train data: target[0].shape: (5120, 64, 64, 1)
INFO:tensorflow:Augmenting training data
INFO:tensorflow:Peformed 2577 flips
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:Creating model...
DEBUG:tensorflow:Stacked data shape: (?, 64, 64, 7)
DEBUG:tensorflow:Input data shape: (64, 64, 7)
DEBUG:tensorflow:Rectified input data shape: (?, 64, 64, 7)
DEBUG:tensorflow:===== Creating U-Net model: U-Net
DEBUG:tensorflow:Training: True
DEBUG:tensorflow:Apply dropout: True
DEBUG:tensorflow:==== Convolution Layer 1
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:==== Convolution Layer 2
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:==== Convolution Layer 3
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:==== Middle Convolution Layer 
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 8, 8, 512)
DEBUG:tensorflow:Using dropout_rate=0.150000
DEBUG:tensorflow:feature shape: (?, 8, 8, 512)
DEBUG:tensorflow:Using dropout_rate=0.150000
DEBUG:tensorflow:===== Convolution Transpose Layer 3
DEBUG:tensorflow:upconv shape: (?, 16, 16, 256)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:===== Convolution Transpose Layer 2
DEBUG:tensorflow:upconv shape: (?, 32, 32, 128)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:===== Convolution Transpose Layer 1
DEBUG:tensorflow:upconv shape: (?, 64, 64, 64)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:===== Final Convolution Layer 1
DEBUG:tensorflow:feature shape: (?, 64, 64, 2)
DEBUG:tensorflow:=====
DEBUG:tensorflow:Model output layer shape = (?, 64, 64, 2)
INFO:tensorflow:Total number of trainable model parameters = 7,699,712
DEBUG:tensorflow:Labels shape = (?, 64, 64, 1)
INFO:tensorflow:Preparing loss function metric: CrossEntropy
INFO:tensorflow:Creating AdamOptimizer with learning-rate = 0.001, and learning-rate decay rate = 1.0
DEBUG:tensorflow:num_iterations_per_epoch = 40.000000
DEBUG:tensorflow:opt_decay_steps = 40.000000
DEBUG:tensorflow:opt_moving_average = 1.000000
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Create CheckpointSaverHook.
INFO:tensorflow:Graph was finalized.
INFO:tensorflow:Restoring parameters from /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt-3800
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
INFO:tensorflow:Saving checkpoints for 3800 into /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt.
DEBUG:tensorflow:Training iteration 3800 / 4000 (95.00%)
INFO:tensorflow:loss = 0.04435467, step = 3800
DEBUG:tensorflow:Training iteration 3810 / 4000 (95.25%)
DEBUG:tensorflow:Training iteration 3820 / 4000 (95.50%)
DEBUG:tensorflow:Training iteration 3830 / 4000 (95.75%)
DEBUG:tensorflow:Training iteration 3840 / 4000 (96.00%)
INFO:tensorflow:Saving checkpoints for 3840 into /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt.
INFO:tensorflow:Loss for final step: 0.040167987.
INFO:tensorflow:
-----------------------------------------
-----
---- Training model...
-----
DEBUG:tensorflow:Train data: epoch size = 5120
DEBUG:tensorflow:Train data: batch size = 128
DEBUG:tensorflow:Train data: num_epochs = 100
DEBUG:tensorflow:Train data: patch_size: [64, 64, 7]
DEBUG:tensorflow:Train data: feature[0].shape: (5120, 64, 64, 7)
DEBUG:tensorflow:Train data: target[0].shape: (5120, 64, 64, 1)
INFO:tensorflow:Augmenting training data
INFO:tensorflow:Peformed 2506 flips
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:Creating model...
DEBUG:tensorflow:Stacked data shape: (?, 64, 64, 7)
DEBUG:tensorflow:Input data shape: (64, 64, 7)
DEBUG:tensorflow:Rectified input data shape: (?, 64, 64, 7)
DEBUG:tensorflow:===== Creating U-Net model: U-Net
DEBUG:tensorflow:Training: True
DEBUG:tensorflow:Apply dropout: True
DEBUG:tensorflow:==== Convolution Layer 1
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:==== Convolution Layer 2
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:==== Convolution Layer 3
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:==== Middle Convolution Layer 
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 8, 8, 512)
DEBUG:tensorflow:Using dropout_rate=0.150000
DEBUG:tensorflow:feature shape: (?, 8, 8, 512)
DEBUG:tensorflow:Using dropout_rate=0.150000
DEBUG:tensorflow:===== Convolution Transpose Layer 3
DEBUG:tensorflow:upconv shape: (?, 16, 16, 256)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:===== Convolution Transpose Layer 2
DEBUG:tensorflow:upconv shape: (?, 32, 32, 128)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:===== Convolution Transpose Layer 1
DEBUG:tensorflow:upconv shape: (?, 64, 64, 64)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:===== Final Convolution Layer 1
DEBUG:tensorflow:feature shape: (?, 64, 64, 2)
DEBUG:tensorflow:=====
DEBUG:tensorflow:Model output layer shape = (?, 64, 64, 2)
INFO:tensorflow:Total number of trainable model parameters = 7,699,712
DEBUG:tensorflow:Labels shape = (?, 64, 64, 1)
INFO:tensorflow:Preparing loss function metric: CrossEntropy
INFO:tensorflow:Creating AdamOptimizer with learning-rate = 0.001, and learning-rate decay rate = 1.0
DEBUG:tensorflow:num_iterations_per_epoch = 40.000000
DEBUG:tensorflow:opt_decay_steps = 40.000000
DEBUG:tensorflow:opt_moving_average = 1.000000
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Create CheckpointSaverHook.
INFO:tensorflow:Graph was finalized.
INFO:tensorflow:Restoring parameters from /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt-3840
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
INFO:tensorflow:Saving checkpoints for 3840 into /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt.
DEBUG:tensorflow:Training iteration 3840 / 4000 (96.00%)
INFO:tensorflow:loss = 0.05713484, step = 3840
DEBUG:tensorflow:Training iteration 3850 / 4000 (96.25%)
DEBUG:tensorflow:Training iteration 3860 / 4000 (96.50%)
DEBUG:tensorflow:Training iteration 3870 / 4000 (96.75%)
DEBUG:tensorflow:Training iteration 3880 / 4000 (97.00%)
INFO:tensorflow:Saving checkpoints for 3880 into /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt.
INFO:tensorflow:Loss for final step: 0.04598673.
INFO:tensorflow:
-----------------------------------------
-----
---- Training model...
-----
DEBUG:tensorflow:Train data: epoch size = 5120
DEBUG:tensorflow:Train data: batch size = 128
DEBUG:tensorflow:Train data: num_epochs = 100
DEBUG:tensorflow:Train data: patch_size: [64, 64, 7]
DEBUG:tensorflow:Train data: feature[0].shape: (5120, 64, 64, 7)
DEBUG:tensorflow:Train data: target[0].shape: (5120, 64, 64, 1)
INFO:tensorflow:Augmenting training data
INFO:tensorflow:Peformed 2582 flips
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:Creating model...
DEBUG:tensorflow:Stacked data shape: (?, 64, 64, 7)
DEBUG:tensorflow:Input data shape: (64, 64, 7)
DEBUG:tensorflow:Rectified input data shape: (?, 64, 64, 7)
DEBUG:tensorflow:===== Creating U-Net model: U-Net
DEBUG:tensorflow:Training: True
DEBUG:tensorflow:Apply dropout: True
DEBUG:tensorflow:==== Convolution Layer 1
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:==== Convolution Layer 2
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:==== Convolution Layer 3
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:==== Middle Convolution Layer 
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 8, 8, 512)
DEBUG:tensorflow:Using dropout_rate=0.150000
DEBUG:tensorflow:feature shape: (?, 8, 8, 512)
DEBUG:tensorflow:Using dropout_rate=0.150000
DEBUG:tensorflow:===== Convolution Transpose Layer 3
DEBUG:tensorflow:upconv shape: (?, 16, 16, 256)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:===== Convolution Transpose Layer 2
DEBUG:tensorflow:upconv shape: (?, 32, 32, 128)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:===== Convolution Transpose Layer 1
DEBUG:tensorflow:upconv shape: (?, 64, 64, 64)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:===== Final Convolution Layer 1
DEBUG:tensorflow:feature shape: (?, 64, 64, 2)
DEBUG:tensorflow:=====
DEBUG:tensorflow:Model output layer shape = (?, 64, 64, 2)
INFO:tensorflow:Total number of trainable model parameters = 7,699,712
DEBUG:tensorflow:Labels shape = (?, 64, 64, 1)
INFO:tensorflow:Preparing loss function metric: CrossEntropy
INFO:tensorflow:Creating AdamOptimizer with learning-rate = 0.001, and learning-rate decay rate = 1.0
DEBUG:tensorflow:num_iterations_per_epoch = 40.000000
DEBUG:tensorflow:opt_decay_steps = 40.000000
DEBUG:tensorflow:opt_moving_average = 1.000000
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Create CheckpointSaverHook.
INFO:tensorflow:Graph was finalized.
INFO:tensorflow:Restoring parameters from /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt-3880
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
INFO:tensorflow:Saving checkpoints for 3880 into /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt.
DEBUG:tensorflow:Training iteration 3880 / 4000 (97.00%)
INFO:tensorflow:loss = 0.052744858, step = 3880
DEBUG:tensorflow:Training iteration 3890 / 4000 (97.25%)
DEBUG:tensorflow:Training iteration 3900 / 4000 (97.50%)
DEBUG:tensorflow:Training iteration 3910 / 4000 (97.75%)
DEBUG:tensorflow:Training iteration 3920 / 4000 (98.00%)
INFO:tensorflow:Saving checkpoints for 3920 into /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt.
INFO:tensorflow:Loss for final step: 0.05767616.
INFO:tensorflow:
-----------------------------------------
-----
---- Training model...
-----
DEBUG:tensorflow:Train data: epoch size = 5120
DEBUG:tensorflow:Train data: batch size = 128
DEBUG:tensorflow:Train data: num_epochs = 100
DEBUG:tensorflow:Train data: patch_size: [64, 64, 7]
DEBUG:tensorflow:Train data: feature[0].shape: (5120, 64, 64, 7)
DEBUG:tensorflow:Train data: target[0].shape: (5120, 64, 64, 1)
INFO:tensorflow:Augmenting training data
INFO:tensorflow:Peformed 2584 flips
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:Creating model...
DEBUG:tensorflow:Stacked data shape: (?, 64, 64, 7)
DEBUG:tensorflow:Input data shape: (64, 64, 7)
DEBUG:tensorflow:Rectified input data shape: (?, 64, 64, 7)
DEBUG:tensorflow:===== Creating U-Net model: U-Net
DEBUG:tensorflow:Training: True
DEBUG:tensorflow:Apply dropout: True
DEBUG:tensorflow:==== Convolution Layer 1
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:==== Convolution Layer 2
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:==== Convolution Layer 3
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:==== Middle Convolution Layer 
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 8, 8, 512)
DEBUG:tensorflow:Using dropout_rate=0.150000
DEBUG:tensorflow:feature shape: (?, 8, 8, 512)
DEBUG:tensorflow:Using dropout_rate=0.150000
DEBUG:tensorflow:===== Convolution Transpose Layer 3
DEBUG:tensorflow:upconv shape: (?, 16, 16, 256)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:===== Convolution Transpose Layer 2
DEBUG:tensorflow:upconv shape: (?, 32, 32, 128)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:===== Convolution Transpose Layer 1
DEBUG:tensorflow:upconv shape: (?, 64, 64, 64)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:===== Final Convolution Layer 1
DEBUG:tensorflow:feature shape: (?, 64, 64, 2)
DEBUG:tensorflow:=====
DEBUG:tensorflow:Model output layer shape = (?, 64, 64, 2)
INFO:tensorflow:Total number of trainable model parameters = 7,699,712
DEBUG:tensorflow:Labels shape = (?, 64, 64, 1)
INFO:tensorflow:Preparing loss function metric: CrossEntropy
INFO:tensorflow:Creating AdamOptimizer with learning-rate = 0.001, and learning-rate decay rate = 1.0
DEBUG:tensorflow:num_iterations_per_epoch = 40.000000
DEBUG:tensorflow:opt_decay_steps = 40.000000
DEBUG:tensorflow:opt_moving_average = 1.000000
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Create CheckpointSaverHook.
INFO:tensorflow:Graph was finalized.
INFO:tensorflow:Restoring parameters from /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt-3920
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
INFO:tensorflow:Saving checkpoints for 3920 into /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt.
DEBUG:tensorflow:Training iteration 3920 / 4000 (98.00%)
INFO:tensorflow:loss = 0.03160318, step = 3920
DEBUG:tensorflow:Training iteration 3930 / 4000 (98.25%)
DEBUG:tensorflow:Training iteration 3940 / 4000 (98.50%)
DEBUG:tensorflow:Training iteration 3950 / 4000 (98.75%)
DEBUG:tensorflow:Training iteration 3960 / 4000 (99.00%)
INFO:tensorflow:Saving checkpoints for 3960 into /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt.
INFO:tensorflow:Loss for final step: 0.04828936.
INFO:tensorflow:
-----------------------------------------
-----
---- Training model...
-----
DEBUG:tensorflow:Train data: epoch size = 5120
DEBUG:tensorflow:Train data: batch size = 128
DEBUG:tensorflow:Train data: num_epochs = 100
DEBUG:tensorflow:Train data: patch_size: [64, 64, 7]
DEBUG:tensorflow:Train data: feature[0].shape: (5120, 64, 64, 7)
DEBUG:tensorflow:Train data: target[0].shape: (5120, 64, 64, 1)
INFO:tensorflow:Augmenting training data
INFO:tensorflow:Peformed 2530 flips
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:Creating model...
DEBUG:tensorflow:Stacked data shape: (?, 64, 64, 7)
DEBUG:tensorflow:Input data shape: (64, 64, 7)
DEBUG:tensorflow:Rectified input data shape: (?, 64, 64, 7)
DEBUG:tensorflow:===== Creating U-Net model: U-Net
DEBUG:tensorflow:Training: True
DEBUG:tensorflow:Apply dropout: True
DEBUG:tensorflow:==== Convolution Layer 1
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:==== Convolution Layer 2
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:==== Convolution Layer 3
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:==== Middle Convolution Layer 
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 8, 8, 512)
DEBUG:tensorflow:Using dropout_rate=0.150000
DEBUG:tensorflow:feature shape: (?, 8, 8, 512)
DEBUG:tensorflow:Using dropout_rate=0.150000
DEBUG:tensorflow:===== Convolution Transpose Layer 3
DEBUG:tensorflow:upconv shape: (?, 16, 16, 256)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:feature shape: (?, 16, 16, 256)
DEBUG:tensorflow:===== Convolution Transpose Layer 2
DEBUG:tensorflow:upconv shape: (?, 32, 32, 128)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:feature shape: (?, 32, 32, 128)
DEBUG:tensorflow:===== Convolution Transpose Layer 1
DEBUG:tensorflow:upconv shape: (?, 64, 64, 64)
DEBUG:tensorflow:Adding padding: [[0, 0], [1, 1], [1, 1], [0, 0]]
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:feature shape: (?, 64, 64, 64)
DEBUG:tensorflow:===== Final Convolution Layer 1
DEBUG:tensorflow:feature shape: (?, 64, 64, 2)
DEBUG:tensorflow:=====
DEBUG:tensorflow:Model output layer shape = (?, 64, 64, 2)
INFO:tensorflow:Total number of trainable model parameters = 7,699,712
DEBUG:tensorflow:Labels shape = (?, 64, 64, 1)
INFO:tensorflow:Preparing loss function metric: CrossEntropy
INFO:tensorflow:Creating AdamOptimizer with learning-rate = 0.001, and learning-rate decay rate = 1.0
DEBUG:tensorflow:num_iterations_per_epoch = 40.000000
DEBUG:tensorflow:opt_decay_steps = 40.000000
DEBUG:tensorflow:opt_moving_average = 1.000000
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Create CheckpointSaverHook.
INFO:tensorflow:Graph was finalized.
INFO:tensorflow:Restoring parameters from /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt-3960
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
INFO:tensorflow:Saving checkpoints for 3960 into /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt.
DEBUG:tensorflow:Training iteration 3960 / 4000 (99.00%)
INFO:tensorflow:loss = 0.048822086, step = 3960
DEBUG:tensorflow:Training iteration 3970 / 4000 (99.25%)
DEBUG:tensorflow:Training iteration 3980 / 4000 (99.50%)
DEBUG:tensorflow:Training iteration 3990 / 4000 (99.75%)
DEBUG:tensorflow:Training iteration 4000 / 4000 (100.00%)
INFO:tensorflow:Saving checkpoints for 4000 into /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt.
INFO:tensorflow:Loss for final step: 0.04089795.
INFO:tensorflow:+++++ S t o r e d  p a r a m e t e r s  in /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt-4000.json
INFO:tensorflow:+++++ S t o r i n g  l o g  f i l e  in /data3/johnkim/kim-papademetris-lab/lv_masking/models/5-13-20_script_unet2d/trained_model/model.ckpt-4000.json
INFO:tensorflow:+++++ E x e c u t i o n  c o m p l e t e d +++++
Normalizing input data: ['quantile']
DynamicDataSet: current cache = [ 28  43   3  76  65  37  11  85  56  33  82  19  83   1  78   6  31  87
  71 111  10  92  46  41  26 113   4  48 105   7  67  36]
DynamicDataSet: current cache = [ 27  24 100  15  17  64  26  70  86  11   0  48  79   8  40 108  20  25
 112  73  96  60  72  66  94  22  67  69  59  44  18   9]
DynamicDataSet: current cache = [ 81 110  25  13 102  95  12  21 104  42 109 113 103  43  50  35  62  58
  52 101  98  41  63  57 111  55  32  83 106  47  22  56]
DynamicDataSet: current cache = [ 84  54  97  61  14  69 107  32  99  51  49   6  77  34  36  93  89  88
  68   4  98  91  39 104  23  75  16   5  63  30  74 108]
DynamicDataSet: current cache = [ 65 107  29  86  57   3  19  38  80  74  99 101   2  84  81  93  54  30
  82  12  45  53  97  90  24  92  35  37  62  18  14  55]
DynamicDataSet: current cache = [ 46  77  53 102 105  78  94  31  40  66  71  87  47  13  56  72  52  58
  59  44   2  15   1  64  96  41   7  76  70  89  20   9]
DynamicDataSet: current cache = [ 91  38 112  61  51  80  28  39  45  49   8 100  34  50   5  19  33 111
  16  68   2  29 109  60  42  79 106  23  52 103  85  21]
DynamicDataSet: current cache = [ 95  88  89  54 102  90  17  27  10  20   9  40   4  44  11  68  66  78
 106  64  57  26   6  51  75  84  70  46  14  47  93  73]
DynamicDataSet: current cache = [  3  88 109  94  36 110  75  81  41  74  87  58 103  83  33  45  26   0
  13  53  29 107  97  96  39  18  95   8 101  99  93  60]
DynamicDataSet: current cache = [108  43  67  35  65  73  79 105  24  77  87  21  17   6 104  55  57 113
  50  88  16  58 110  10   0  34  62  22  97 100  48  25]
DynamicDataSet: current cache = [ 98  90  59  94  69  12  33  80  30  32   7  91  42  27 112  83  82   1
  10  49 109  23  25  29  55  79   4  76   5  38  86  63]
DynamicDataSet: current cache = [ 53 100  61  31  72  47  85  93  99  67  78  74  92  28  86 105  29  71
  45  37  84  15  73   5   0  24  63  66 110 104 112  81]
DynamicDataSet: current cache = [ 69  34  72  48 111  55  52  38  13   2  39  31  49  80  62  16 103  90
  60  64 102  77  95  18  32  15   9  85  89  96  61  75]
DynamicDataSet: current cache = [ 66  23   3  54  65 106  38  46  59   1  92  56  22  98   7  88  30  49
  42  70  20  27  47  60  43  14  35 107  76  28  36  91]
DynamicDataSet: current cache = [111  58  11  82  50  57  68   8 113  19  35   5  37  59  71 101  44  51
  89  20  30  32  10  33  17  83  70  63  42  53 108  79]
DynamicDataSet: current cache = [107  41  80  85   1  84  90  16  28  82  12  98  37 102  27  24 109  36
  95 112  14  21  67  91  40   0 103  44 100  96   9  81]
DynamicDataSet: current cache = [ 68   9 101  97  86 112  31   7  48  40  77 105  71  26  74  18  62   2
 106  12  50 110  21 113  54  92   8  87  75  56  34  99]
DynamicDataSet: current cache = [ 51  76   6  97  44  39  92  86  45  73  13  35  61  98  29  43 104  30
  11  23  65   4  46  25  78  64  15  32  19  52   3  72]
DynamicDataSet: current cache = [ 43  90  38  94  53 108  10   2  28 113  40  47  19  22  75  71  93  95
  83  69 109  31 110 101  17   1  66   6  84  96  82  68]
DynamicDataSet: current cache = [100  91  21  77  81 105  89  88  15  94  99   0  16  32  65  78 107  60
  73  67  87   3  58  59  34  13   8 104  37  97 108  18]
DynamicDataSet: current cache = [ 80  25  88  63  33   5  76 102 103  57  36  74  12  61  70  34  66  11
   4 111  27  48  51  22 110 106  85  72  56  69  26  14]
DynamicDataSet: current cache = [113  55  76  39  62 102  54  19  24   4  17  45  16  83  59  73  50 100
  84 109  52  10  44  69  30  65  53   0  63  46  72  71]
DynamicDataSet: current cache = [ 36  31  98  99  20  64  79  47 111  23   1 106   7  60   5  78 108 105
  42  49  90  15  87 110  41 107  86  95  14  68  37   4]
DynamicDataSet: current cache = [112  52   2   9 104  22  46  33  51  17  67  48  40  42   7  80  50  88
 106  64  74  27  55  96  54 101   6  25  49  43   8  20]
DynamicDataSet: current cache = [ 91  82  39  18  75   3  56 103  11   5  48  79  94  24  81  21  89  13
 100  93  86  41  85  77  58  45 102  35 113  67  59  62]
DynamicDataSet: current cache = [ 77  62  70  74  29  56  92  26  63  28  61  54  66  23 104 110  50  98
  38  34  43  73  52  12  57  91  45  49 103  85  14  22]
DynamicDataSet: current cache = [ 46  92  24  60  94  19  32   6  95  54  37  33  78  68  29  18  35  70
   2   9   7  76  36  99 112  55  61  26  30  45  28  87]
DynamicDataSet: current cache = [ 39  12  47  58  38  44  97  79  11  96 105  37  95  40  53  80  13  87
  70  16   3  21  90  25  20  43  78  42  64  89  27 101]
DynamicDataSet: current cache = [ 19  75  69  15 108  10  65  93  66  84   0  51  34   8  83  17  82  41
  23  72  57  63 107   3  58  76  20  36  86  14 112  71]
DynamicDataSet: current cache = [ 28 109 111  49  46   1  41  67  88  25 106   2  84  83   8  35  10  85
  81  39  31  52  78  90  66  72  17  82  18  73  71  91]
DynamicDataSet: current cache = [ 30 104  44  80  27 113  74  94  38   1  12  99  60  65  86  89  64   9
  48 102 107  50  92  61  29  13 109   5  33  15  31  47]
DynamicDataSet: current cache = [ 68 108  62 100  57  34  51 101   7  75  22   3  59  58  72 111 103   6
  16  93  97  33  77  30 105  53 106 113   4  76  11  24]
DynamicDataSet: current cache = [ 38  79  60   1  26  98  56 112  99  96  32  67  23  42  18  21  55 100
  22  40  54  57  68  83  89  17  39 111  37  29  97  14]
DynamicDataSet: current cache = [ 52  31  13 104  81  19 105   4  79   0  63  74 109  87  69  48  53  15
  20  59 102  28  84   6   2  26  50  93  24  23  71  65]
DynamicDataSet: current cache = [ 80  91  40  88  94  35  90  26  36 108  95  96  42  15   7  85  41   5
  25  87  49  99  43  12  56  92  67  10   9  11  21   1]
DynamicDataSet: current cache = [ 61  44  55  77  74   8  13  70  64 103  75  38  95  71  45  16  51  46
  50  94 107  48  98  47  14  19  27  76   3  32  58  73]
DynamicDataSet: current cache = [ 81  34  23  72  69  84  88  47 112  82 110  28  20   0  45   6 101  85
  44   4   2  63  41  66 108  43 103  61  37  31  78  62]
DynamicDataSet: current cache = [ 64  30 102  46  41   0   5  82 101 112  42  79  77  25 107  86  83  49
  51 113  27  96  40   7  18  17  60  75  24  97  29  81]
DynamicDataSet: current cache = [ 60 109  61   0  55  22   8  17  90  65 111  10  81  56 106   9  93  52
  27  69  12  92  21  16  48  57  36  62  35  32  83  53]
DynamicDataSet: current cache = [ 47  39  12 110  49  85 105  91  54  21  68 100  11  98  70 103  33  80
  89  59   1  93  78 104  73 113  66  31  16  45  71  44]
DynamicDataSet: current cache = [ 25  53   5  84 100 109  54 105  50  74  60  80  35   4 101  15  57  40
  92  70 110  52  86  33 111   8  29  38   7  69  59  30]
DynamicDataSet: current cache = [ 79  72  46  67  22  11 100  64  63  23  18  42 106  89 109 104  99  95
  96  56  66  34  92  62  76  28 107  98  51   6  75  55]
DynamicDataSet: current cache = [  2  44   9  58  32   3  39  73   6  36  20 104  24  13  79 113  26  19
 108  87  51   0  68  10  37 103  14  88  59  43  65  94]
DynamicDataSet: current cache = [ 85  34  97  90  40  28  17  72  48 102  37  22  91  41  10 108  61  75
  77  12  89  39  64  82  94  19  27  14  57  93  87  71]
DynamicDataSet: current cache = [ 50  10  20  90  24  76   8  91  73  12  25  98  88   7  68  18  86 103
  99  82 112  70 102  39  42  55 111  21 109  31   9  66]
DynamicDataSet: current cache = [ 44  30  58   5  69  65  52  26  95  38  46  43 108  77  16 105  51  62
  56   3  84  83   4  49  11  78  33  97 101  29  13  54]
DynamicDataSet: current cache = [ 88  62   3  45  95  35  81  36  50 110 107  15  19  79  96  23  77  53
  91   1  47  72  20  67  60  13 106  74   5 113  93   4]
DynamicDataSet: current cache = [  9  23  28  63  60  80  76  52  98  32   2  54  94  58  82  97  85  47
  67 107  57 112  70  12  48  14  45 104   1 101  61  42]
DynamicDataSet: current cache = [ 17  99 102  61  26  68   0   2  43   8  86  89  83  36  65 101  15  88
  25  53  37  90  87  33  56  75  64  24  55 109  16  92]
DynamicDataSet: current cache = [ 50  62  78 106  29  71 110  69   6  34   4  73  84  80  63  31  40  11
   7  96  22  93  59  41  95  38 111  27  46   2 105 108]
DynamicDataSet: current cache = [ 17  78  35  18 100  40  74  23  56  58  55  81  52  16  68 105  45  32
  98  30  42  49  64  79  87  44  39  77  54  71  15  48]
DynamicDataSet: current cache = [  6 110   3  14   0  46  30  91 102  83  18  21  84 113   8 100  67  22
  81  89  19 104  41  26  28  27   5  74  70   9 106   1]
DynamicDataSet: current cache = [ 73  11  23 111  24  94  55  97  72  32  65  21  20  13  31  54  35  59
  69  51 109  66  40  82  86  78  61 107  76  10  43  25]
DynamicDataSet: current cache = [ 38  29  90  15  86  57 111   3  89  75  34  49 112  63  85   5  10  92
  80  37  23  82  33  35  14  50  79  31   8 103   7  96]
DynamicDataSet: current cache = [108  73  36   7  22  99  28  46  35  83  13  53  47  59  11   0  56 101
  38  30  70  98  77 107  65  81  93 105  72 100  52  64]
DynamicDataSet: current cache = [ 80  37  74  32  27  95  39  49  96  48  69   9   1  84 106   2   4  62
  24  58  91 103  41  53  21  68  99  87  63  45  12  25]
DynamicDataSet: current cache = [ 94  44  49  85   6  88 102  66  16  51 112  60  97  92  19  52  18  28
  75  26  47  90  42  43  67  65  29  58 113  25 109  34]
DynamicDataSet: current cache = [ 30 104  57  50  81  76  54 110 113  17  71  20  36  96  33  80  84  93
  32  65  99  89  66  92  94  23  44  64  56  67 112  47]
DynamicDataSet: current cache = [ 73  41   0  13  69  39  71  43  88  76  29   5 102  48  37  17  21  99
  18  33 110   1   7  91  51  10  42 108  46  78 111  79]
DynamicDataSet: current cache = [ 22  36  88  98  40  19   9 104  70  11 103  27  75  74  82  15 100  59
  17  61   1  60  38  68  53  20  45  77  57  89   4 106]
DynamicDataSet: current cache = [ 12   3  19  47  95 105  51 107 101  83  55  34   8  46  93  16  92   2
  31  14  90  72  50  97  84  66  63  26   6  25  87 106]
DynamicDataSet: current cache = [  5  26  62   6  75  86  69  80  24  15  85  14  77 101 113  42  94  18
  98  58 100  20  63  28  79 103 109 110  90 104  32  45]
DynamicDataSet: current cache = [ 56  16  53  70  29  50   2  64  27  44  12  26  67  35  59 112  78 108
 102  85 111   7  65   9  74  11  49  21  30  40 107  97]
DynamicDataSet: current cache = [ 10  86  71   6 107  53  39  42  81  76   4  55  96  33  73  38  47 105
  48  34  37   3  63  91  31  22  36  15 100  61  35  82]
DynamicDataSet: current cache = [ 91  24  95  72  52 110  60  23  43   0  10  57  94  39  83  74  97  87
  62  49  27  54   5  68   4  84  55  51 108  89  93  41]
DynamicDataSet: current cache = [ 33  99  83  62  37  13 106  22   1  18  76   3  16 101  11 104   8  52
  87  45  64 109  92  51  68  59  78  28  98  73  41  14]
DynamicDataSet: current cache = [ 80   4 113  79  74  83  11  29  85 105   0  13  66  32   8  75  57  34
  15  96  72  95  48  16  19   9  60  12  82  81 102  67]
DynamicDataSet: current cache = [ 38  46  21  98 112 111  54   7  20  24  53  61  40  23  88 109  82  69
  28   0  77  44  71  62  36   8  32 103  34  89  25  90]
DynamicDataSet: current cache = [ 43   7  48  73 107  20  31 113  30  70  77  17  39  56  54  58  85  10
  65  93  11  27  41  64  32 101  34  49  38  78  86 111]
DynamicDataSet: current cache = [ 80  76  70   1  55 105  75  19   5  84  81  12  60  79   2  63  91  94
  72  52  22  66  68 102  42  87  18  46  71  97  56  67]
DynamicDataSet: current cache = [ 31  39 112  37  26  99  61  30   2  12  59   3 106  29  18  86  13  17
  49  56  66  55  21  58  96  60  45  33  44   6 100   9]
DynamicDataSet: current cache = [103   3  47  43  50  25  40  36  88  99 108  14  94  69 104  35  75  28
  20   1  24  61  16  26 110  23  67  90  87 100   4  77]
DynamicDataSet: current cache = [ 62  40   0  15  30  47  58  90  92  79  59  25  86 112  95   5  93  27
  45 105 104  51  69   2  74  52  63  17  57  97  68  10]
DynamicDataSet: current cache = [ 83  52 107  46  92  57  33 108  13  36 111  88   8  85 110  84  48  32
  24  50  91  76  14  39  71  35  68   7  70  78  53  28]
DynamicDataSet: current cache = [ 80   6  41 109  29  13   0  50  65  12  35 102 101 106  64  73  37  78
   2   9  82  76  88  22  38 113  89  45  96  55  21  61]
DynamicDataSet: current cache = [103   1   4  31  72  44  91  95  29  53  21   8  54  43  60  81  58 113
  69  98  96  42 110  66 102  74 101  19  26  46  18  86]
DynamicDataSet: current cache = [ 22  94  49  82  20  47  16  63  71  79  24  38  40  48  93  51  73  37
  65  92 100  75 106 112   3  87  95  27  44  99  56 108]
DynamicDataSet: current cache = [ 41  57  67  64 109  98  62  59  66 104  11  23  15   6  54  78  30  88
  43  14  80  36  97  17  27  40   9 111  85  21   7  72]
DynamicDataSet: current cache = [ 25  34  18  84  77  81  80  87  37  39  73  19 109  42  31  91 107  10
  70  75 103 105  60  47  90 100   0  15  64 106  33  38]
DynamicDataSet: current cache = [111  81   5   1 107  33 113  42  14  38  25  24  89  83  22  23  32  13
 104  96  77  50  76  84  46  16  58 101  10 102  65  74]
DynamicDataSet: current cache = [110  48   6  83   2  70 108  56  85  99  26 111  28  55   9  69  12  88
  41  29  45 107  54  94  49  71  93  36  11  61  97  30]
DynamicDataSet: current cache = [ 68  92  59   8  20  84 105  31  63  95  89  49  66   5  51  35  19  86
  61  44  27  16  90  34  14  97  91  67  65   9 108  62]
DynamicDataSet: current cache = [ 74  71  81  82  31 105  43  62  85  94  90 112  19  17 106  72  41  60
  24  79  18   6   4  57  53  29   7   5  68  93 113 103]
DynamicDataSet: current cache = [ 56  57   3  30  87  12  98  58  20  36  52  92  25  45  76  21  46  69
  34  64  95  96   8  15  40  61  22   1  72  28   2 103]
DynamicDataSet: current cache = [ 48  37   7  43  59 110  10  86  77  55  17  11  99  51 112  39  44 109
  82  98  80   4 104  78  47  23  52  42  63  53  64  73]
DynamicDataSet: current cache = [ 37  50  98   3  67  83  71 108  26  89  66 101   2  72 100  19 104  85
   0  35  33  75  53  13  78  54  77  70 102   8  79  32]
DynamicDataSet: current cache = [ 38  77 105  69  79 113  95  43  29  48  63  84  12 103  62  28  92  68
  96  18  40 106  70  97  30  93 107  10  17  74   7  14]
DynamicDataSet: current cache = [ 32  45   5  59  52  89  72  57  49  75 102  65  46  26  33  87 103  36
 112  85  76  24  31  55  35 101  83  47   6   3 111  84]
DynamicDataSet: current cache = [ 83  88 109   4  99  11  21  39  22  27  65  16  91  86  15  51  48  60
  42  94  20  25  80  81  34  54  56  63  13  73   9   0]
DynamicDataSet: current cache = [107  47  19   0   1  86  82  50 110  67  90  16  89  66  71  41  56   6
 102  79   9  20  92  25  55  33  58  37  99 101 103  40]
DynamicDataSet: current cache = [100  62  76  44  88  52  15  96  43  23   4  46 102  98  27 109 110  78
  53   8  61  71  95 113  45  28  50  13   2  60  64  74]
DynamicDataSet: current cache = [ 67  90  39 111 108  54  59  26   1  61  23 100  31  18  21  32  38  36
  14  93  12  69  97 105  25   3  10 104  51  24  70 112]
DynamicDataSet: current cache = [ 49  87  75  30  94  58  12  42  57  70  98   7  88  44  22  41  81  86
  63  11  35   5   8  34  91  96  82  73 105  97  62 106]
DynamicDataSet: current cache = [ 17  75  80  27  68  85  41 113  37  66  24  83  43  51  91  78 108 100
  58  92  15  23  29  99  52   4  47  20  67  77 109  94]
DynamicDataSet: current cache = [101  64  81  89  68  65  95  53  35  73  90  72  19  28 104  45  59  74
  40   1   3  80  21  16  17  34  50  84  42  39  99   2]
DynamicDataSet: current cache = [ 38  36   7  69  60  32  95  35  57  39  26   9  18  76 105 110  37  94
   6  79  10  49  31 111  22  48  44  55   0  90  33  13]
DynamicDataSet: current cache = [ 91  11  79  54  29  46   5  87  14 109 106  83  12 112  67  56  73  30
   6  32   8  82  93  78 107  71  48  16  65 110 108 111]
DynamicDataSet: current cache = [  6  56  71  25  58  82  97 100  89  92  88  17  77  50 103 112  45  63
   7  98  53  60  69 107  20  68  31  93 102  66  55  14]
DynamicDataSet: current cache = [ 44  30  29  62  57  13  80  64  19  28  86  40  49  81  34  51  59   3
  96  26  43  52  76  46  63   2  99  75  72 113 101  10]
DynamicDataSet: current cache = [  4  13   9  48  24  27  83  15  11 104  81  21 106  33  85  38  87  34
 113  19  18  54  42  22  74  26  70  59  75  44  84  23]
